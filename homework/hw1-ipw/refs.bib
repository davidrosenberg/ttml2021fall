% mode is org-ref
                  
@inbook{amir-2008-discr-learn,
  DATE_ADDED =   {Sat Jun 6 20:23:20 2020},
  author =       {Bickel Amir and Br{\"u}ckner Michael and Scheffer Tobias},
  booktitle =    {Dataset Shift in Machine Learning},
  doi =          {10.7551/mitpress/9780262170055.003.0009},
  pages =        {161-177},
  publisher =    {The MIT Press},
  series =       {Dataset Shift in Machine Learning},
  title =        {Discriminative Learning under Covariate Shift with a Single
                  Optimization Problem},
  url =          {https://doi.org/10.7551/mitpress/9780262170055.003.0009},
  year =         {2008},
}

@article{gerber-2008-social-press,
  author =       {Alan S. Gerber and Donald P. Green and Christopher W. Larimer},
  title =        {Social Pressure and Voter Turnout: Evidence From a Large-Scale
                  Field Experiment},
  journal =      {American Political Science Review},
  volume =       102,
  number =       1,
  pages =        {33-48},
  year =         2008,
  doi =          {10.1017/s000305540808009x},
  url =          {https://doi.org/10.1017/s000305540808009x},
  DATE_ADDED =   {Mon Jun 15 14:01:42 2020},
}

@article{kuenzel-2017-meta-learn,
  author =       {K{\"u}nzel, S{\"o}ren R. and Sekhon, Jasjeet S. and Bickel,
                  Peter J. and Yu, Bin},
  title =        {Meta-Learners for Estimating Heterogeneous Treatment Effects
                  Using Machine Learning},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1706.03461v6},
  abstract =     {There is growing interest in estimating and analyzing
                  heterogeneous treatment effects in experimental and
                  observational studies. We describe a number of meta-algorithms
                  that can take advantage of any supervised learning or
                  regression method in machine learning and statistics to
                  estimate the Conditional Average Treatment Effect (CATE)
                  function. Meta-algorithms build on base algorithms---such as
                  Random Forests (RF), Bayesian Additive Regression Trees (BART)
                  or neural networks---to estimate the CATE, a function that the
                  base algorithms are not designed to estimate directly. We
                  introduce a new meta-algorithm, the X-learner, that is
                  provably efficient when the number of units in one treatment
                  group is much larger than in the other, and can exploit
                  structural properties of the CATE function. For example, if
                  the CATE function is linear and the response functions in
                  treatment and control are Lipschitz continuous, the X-learner
                  can still achieve the parametric rate under regularity
                  conditions. We then introduce versions of the X-learner that
                  use RF and BART as base learners. In extensive simulation
                  studies, the X-learner performs favorably, although none of
                  the meta-learners is uniformly the best. In two persuasion
                  field experiments from political science, we demonstrate how
                  our new X-learner can be used to target treatment regimes and
                  to shed light on underlying mechanisms. A software package is
                  provided that implements our methods.},
  archivePrefix ={arXiv},
  eprint =       {1706.03461},
  primaryClass = {math.ST},
}

@article{kuenzel-2019-metal-estim,
  author =       {S{\"o}ren R. K{\"u}nzel and Jasjeet S. Sekhon and Peter J.
                  Bickel and Bin Yu},
  title =        {Metalearners for Estimating Heterogeneous Treatment Effects
                  Using Machine Learning},
  journal =      {Proceedings of the National Academy of Sciences},
  volume =       116,
  number =       10,
  pages =        {4156-4165},
  year =         2019,
  doi =          {10.1073/pnas.1804597116},
  url =          {https://doi.org/10.1073/pnas.1804597116},
  DATE_ADDED =   {Sat Jun 6 14:16:24 2020},
}

@article{knaus-2018-machin-learn,
  author =       {Knaus, Michael C. and Lechner, Michael and Strittmatter,
                  Anthony},
  title =        {Machine Learning Estimation of Heterogeneous Causal Effects:
                  Empirical Monte Carlo Evidence},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1810.13237v2},
  abstract =     {We investigate the finite sample performance of causal machine
                  learning estimators for heterogeneous causal effects at
                  different aggregation levels. We employ an Empirical Monte
                  Carlo Study that relies on arguably realistic data generation
                  processes (DGPs) based on actual data. We consider 24
                  different DGPs, eleven different causal machine learning
                  estimators, and three aggregation levels of the estimated
                  effects. In the main DGPs, we allow for selection into
                  treatment based on a rich set of observable covariates. We
                  provide evidence that the estimators can be categorized into
                  three groups. The first group performs consistently well
                  across all DGPs and aggregation levels. These estimators have
                  multiple steps to account for the selection into the treatment
                  and the outcome process. The second group shows competitive
                  performance only for particular DGPs. The third group is
                  clearly outperformed by the other estimators.},
  archivePrefix ={arXiv},
  eprint =       {1810.13237},
  primaryClass = {econ.EM},
}
                  
@TECHREPORT{athey-2015-machin-learn,
  title =        {Machine Learning for Estimating Heterogeneous Causal Effects},
  author =       {Athey, Susan and Imbens, Guido},
  year =         {2015},
  institution =  {Stanford University, Graduate School of Business},
  type =         {Research Papers},
  abstract =     {In this paper we study the problems of estimating
                  heterogeneity in causal effects in experimental or
                  observational studies and conducting inference about the
                  magnitude of the differences in treatment effects across
                  subsets of the population. In applications, our method
                  provides a data-driven approach to determine which
                  subpopulations have large or small treatment effects and to
                  test hypotheses about the differences in these effects. For
                  experiments, our method allows researchers to identify
                  heterogeneity in treatment effects that was not specified in a
                  pre-analysis plan, without concern about invalidating
                  inference due to multiple testing. In most of the literature
                  on supervised machine learning (e.g. regression trees, random
                  forests, LASSO, etc.), the goal is to build a model of the
                  relationship between a unit's attributes and an observed
                  outcome. A prominent role in these methods is played by
                  cross-validation which compares predictions to actual outcomes
                  in test samples, in order to select the level of complexity of
                  the model that provides the best predictive power. Our method
                  is closely related, but it differs in that it is tailored for
                  predicting causal effects of a treatment rather than a unit's
                  outcome. The challenge is that the "ground truth" for a causal
                  effect is not observed for any individual unit: we observe the
                  unit with the treatment, or without the treatment, but not
                  both at the same time. Thus, it is not obvious how to use
                  cross-validation to determine whether a causal effect has been
                  accurately predicted. We propose several novel
                  cross-validation criteria for this problem and demonstrate
                  through simulations the conditions under which they perform
                  better than standard methods for the problem of causal
                  effects. We then apply the method to a large-scale field
                  experiment re-ranking results on a search engine.},
  url =          {https://econpapers.repec.org/paper/eclstabus/3350.htm}
}

@article{rubin-1974-estim-causal,
  author =       {Donald B. Rubin},
  title =        {Estimating Causal Effects of Treatments in Randomized and
                  Nonrandomized Studies.},
  journal =      {Journal of Educational Psychology},
  volume =       66,
  number =       5,
  pages =        {688-701},
  year =         1974,
  doi =          {10.1037/h0037350},
  url =          {https://doi.org/10.1037/h0037350},
  DATE_ADDED =   {Tue Jun 16 07:53:45 2020},
}

@article{ratner-2017-snork,
  author =       {Ratner, Alexander and Bach, Stephen H. and Ehrenberg, Henry
                  and Fries, Jason and Wu, Sen and R{\'e}, Christopher},
  title =        {Snorkel: Rapid Training Data Creation With Weak Supervision},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1711.10160v1},
  abstract =     {Labeling training data is increasingly the largest bottleneck
                  in deploying machine learning systems. We present Snorkel, a
                  first-of-its-kind system that enables users to train
                  state-of-the-art models without hand labeling any training
                  data. Instead, users write labeling functions that express
                  arbitrary heuristics, which can have unknown accuracies and
                  correlations. Snorkel denoises their outputs without access to
                  ground truth by incorporating the first end-to-end
                  implementation of our recently proposed machine learning
                  paradigm, data programming. We present a flexible interface
                  layer for writing labeling functions based on our experience
                  over the past year collaborating with companies, agencies, and
                  research labs. In a user study, subject matter experts build
                  models 2.8x faster and increase predictive performance an
                  average 45.5 \% versus seven hours of hand labeling. We study
                  the modeling tradeoffs in this new setting and propose an
                  optimizer for automating tradeoff decisions that gives up to
                  1.8x speedup per pipeline execution. In two collaborations,
                  with the U.S. Department of Veterans Affairs and the U.S. Food
                  and Drug Administration, and on four open-source text and
                  image data sets representative of other deployments, Snorkel
                  provides 132 \% average improvements to predictive performance
                  over prior heuristic approaches and comes within an average
                  3.60 \% of the predictive performance of large hand-curated
                  training sets.},
  archivePrefix ={arXiv},
  eprint =       {1711.10160},
  primaryClass = {cs.LG},
}


@article{ratner-2019-snork,
  author =       {Alexander Ratner and Stephen H. Bach and Henry Ehrenberg and
                  Jason Fries and Sen Wu and Christopher R{\'e}},
  title =        {Snorkel: Rapid Training Data Creation With Weak Supervision},
  journal =      {The VLDB Journal},
  volume =       29,
  number =       {2-3},
  pages =        {709-730},
  year =         2019,
  doi =          {10.1007/s00778-019-00552-1},
  url =          {https://doi.org/10.1007/s00778-019-00552-1},
  DATE_ADDED =   {Wed Jun 24 08:59:22 2020},
}

@inproceedings{juan-2016-field-factor,
  author =       {Yuchin Juan and Yong Zhuang and Wei-Sheng Chin and Chih-Jen
                  Lin},
  title =        {Field-aware Factorization Machines for CTR Prediction},
  booktitle =    {Proceedings of the 10th ACM Conference on Recommender Systems},
  year =         2016,
  pages =        {nil},
  doi =          {10.1145/2959100.2959134},
  url =          {https://doi.org/10.1145/2959100.2959134},
  DATE_ADDED =   {Wed Jun 24 13:09:18 2020},
  month =        9,
}

@inproceedings{ratner-2016-data-progr,
  author =       {Ratner, Alexander and Sa, Christopher De and Wu, Sen and
                  Selsam, Daniel and R{\'e}, Christopher},
  title =        {Data Programming: Creating Large Training Sets, Quickly},
  booktitle =    {Proceedings of the 30th International Conference on Neural Information Processing},
  pages =        {3574–3582},
  year =         2016,
  url =          {https://dl.acm.org/doi/10.5555/3157382.3157497},
  abstract =     {Large labeled training sets are the critical building blocks
                  of supervised learning methods and are key enablers of deep
                  learning techniques. For some applications, creating labeled
                  training sets is the most time-consuming and expensive part of
                  applying machine learning. We therefore propose a paradigm for
                  the programmatic creation of training sets called data
                  programming in which users express weak supervision strategies
                  or domain heuristics as labeling functions, which are programs
                  that label subsets of the data, but that are noisy and may
                  conflict. We show that by explicitly representing this
                  training set labeling process as a generative model, we can
                  "denoise" the generated training set, and establish
                  theoretically that we can recover the parameters of these
                  generative models in a handful of settings. We then show how
                  to modify a discriminative loss function to make it
                  noise-aware, and demonstrate our method over a range of
                  discriminative models including logistic regression and LSTMs.
                  Experimentally, on the 2014 TAC-KBP Slot Filling challenge, we
                  show that data programming would have led to a new winning
                  score, and also show that applying data programming to an LSTM
                  model leads to a TAC-KBP score almost 6 F1 points over a
                  state-of-the-art LSTM baseline (and into second place in the
                  competition). Additionally, in initial user studies we
                  observed that data programming may be an easier way for
                  non-experts to create machine learning models when training
                  data is limited or unavailable.},
  archivePrefix ={arXiv},
  eprint =       {1605.07723},
  primaryClass = {stat.ML},
}

@inproceedings{bach-2017-learn-struc,
  author =       {Bach, Stephen H. and He, Bryan and Ratner, Alexander and
                  R{\'e}, Christopher},
  title =        {Learning the Structure of Generative Models Without Labeled
                  Data},
  booktitle =    {Proceedings of the 34th International Conference on Machine Learning},
  year =         2017,
  url =          {http://arxiv.org/abs/1703.00854v2},
  abstract =     {Curating labeled training data has become the primary
                  bottleneck in machine learning. Recent frameworks address this
                  bottleneck with generative models to synthesize labels at
                  scale from weak supervision sources. The generative model's
                  dependency structure directly affects the quality of the
                  estimated labels, but selecting a structure automatically
                  without any labeled data is a distinct challenge. We propose a
                  structure estimation method that maximizes the
                  $\ell_1$-regularized marginal pseudolikelihood of the observed
                  data. Our analysis shows that the amount of unlabeled data
                  required to identify the true structure scales sublinearly in
                  the number of possible dependencies for a broad class of
                  models. Simulations show that our method is 100$\times$ faster
                  than a maximum likelihood approach and selects $1/4$ as many
                  extraneous dependencies. We also show that our method provides
                  an average of 1.5 F1 points of improvement over existing,
                  user-developed information extraction applications on
                  real-world data such as PubMed journal abstracts.},
  archivePrefix ={arXiv},
  eprint =       {1703.00854},
  primaryClass = {cs.LG},
}

@InProceedings{li-2013-error-rate,
  author =       {Li, Hongwei and Yu, Bin and Zhou, Denny},
  title =        {Error Rate Analysis Of Labeling By Crowdsourcing},
  booktitle =    {ICML '13 Workshop: Machine Learning Meets Crowdsourcing},
  year =         {2013},
  month =        {June},
  abstract =     {Crowdsourcing label generation has been a crucial component
                  for many real-world machine learning applications. In this
                  paper, we provide finite-sample exponential bounds on the
                  error rate (in probability and in expectation) of hyperplane
                  binary labeling rules for the Dawid-Skene (and Symmetric
                  Dawid-Skene) crowdsourcing model. The bounds can be applied to
                  analyze many commonly used prediction methods, including the
                  majority voting, weighted majority voting and maximum a
                  posteriori (MAP) rules. These bound results can be used to
                  control the error rate and design better algorithms. In
                  particular, under the Symmetric Dawid-Skene model we use
                  simulation to demonstrate that the data-driven EM-MAP rule is
                  a good approximation to the oracle MAP rule which
                  approximately optimizes our upper bound on the mean error rate
                  for any hyperplane binary labeling rule. Meanwhile, the
                  average error rate of the EM-MAP rule is bounded well by the
                  upper bound on the mean error rate of the oracle MAP rule in
                  the simulation.},
  url =
                  {https://www.microsoft.com/en-us/research/publication/error-rate-analysis-labeling-crowdsourcing/},
  edition =      {ICML ’13 Workshop: Machine Learning Meets Crowdsourcing},
}

@inproceedings{lundberg-2017-unified-approac,
  author =       {Lundberg, Scott and Lee, Su-In},
  title =        {A Unified Approach To Interpreting Model Predictions},
  journal =      {NeurIPS},
  year =         2017,
  pages =        {4765--4774},
  url =          {http://arxiv.org/abs/1705.07874v2},
  abstract =     {Understanding why a model makes a certain prediction can be as
                  crucial as the prediction's accuracy in many applications.
                  However, the highest accuracy for large modern datasets is
                  often achieved by complex models that even experts struggle to
                  interpret, such as ensemble or deep learning models, creating
                  a tension between accuracy and interpretability. In response,
                  various methods have recently been proposed to help users
                  interpret the predictions of complex models, but it is often
                  unclear how these methods are related and when one method is
                  preferable over another. To address this problem, we present a
                  unified framework for interpreting predictions, SHAP (SHapley
                  Additive exPlanations). SHAP assigns each feature an
                  importance value for a particular prediction. Its novel
                  components include: (1) the identification of a new class of
                  additive feature importance measures, and (2) theoretical
                  results showing there is a unique solution in this class with
                  a set of desirable properties. The new class unifies six
                  existing methods, notable because several recent methods in
                  the class lack the proposed desirable properties. Based on
                  insights from this unification, we present new methods that
                  show improved computational performance and/or better
                  consistency with human intuition than previous approaches.},
  archivePrefix ={arXiv},
  eprint =       {1705.07874},
  primaryClass = {cs.AI},
}

@article{alvarez-melis-2018-robus-inter-method,
  author =       {Alvarez-Melis, David and Jaakkola, Tommi S.},
  title =        {On the Robustness of Interpretability Methods},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1806.08049v1},
  abstract =     {We argue that robustness of explanations---i.e., that similar
                  inputs should give rise to similar explanations---is a key
                  desideratum for interpretability. We introduce metrics to
                  quantify robustness and demonstrate that current methods do
                  not perform well according to these metrics. Finally, we
                  propose ways that robustness can be enforced on existing
                  interpretability approaches.},
  archivePrefix ={arXiv},
  eprint =       {1806.08049},
  primaryClass = {cs.LG},
}


@article{koren-2009-matrix-factor,
  author =       {Yehuda Koren and Robert Bell and Chris Volinsky},
  title =        {Matrix Factorization Techniques for Recommender Systems},
  journal =      {Computer},
  volume =       42,
  number =       8,
  pages =        {30-37},
  year =         2009,
  doi =          {10.1109/mc.2009.263},
  url =          {https://doi.org/10.1109/mc.2009.263},
  DATE_ADDED =   {Fri Jul 3 09:44:46 2020},
}

@article{hernan-2019-secon-chanc,
  author =       {Miguel A. Hern{\'a}n and John Hsu and Brian Healy},
  title =        {A Second Chance To Get Causal Inference Right: a
                  Classification of Data Science Tasks},
  journal =      {CHANCE},
  volume =       32,
  number =       1,
  pages =        {42-49},
  year =         2019,
  doi =          {10.1080/09332480.2019.1579578},
  url =          {https://doi.org/10.1080/09332480.2019.1579578},
  DATE_ADDED =   {Fri Jul 3 14:08:07 2020},
}

@article{lipovetsky-2001-analy-regres,
  author =       {Stan Lipovetsky and Michael Conklin},
  title =        {Analysis of Regression in Game Theory Approach},
  journal =      {Applied Stochastic Models in Business and Industry},
  volume =       17,
  number =       4,
  pages =        {319-330},
  year =         2001,
  doi =          {10.1002/asmb.446},
  url =          {https://doi.org/10.1002/asmb.446},
  DATE_ADDED =   {Wed Jul 8 06:33:18 2020},
}

@article{vstrumbelj-2014-explain-predic,
  author =       {Erik {\v{S}}trumbelj and Igor Kononenko},
  title =        {Explaining Prediction Models and Individual Predictions With
                  Feature Contributions},
  journal =      {Knowledge and Information Systems},
  volume =       41,
  number =       3,
  pages =        {647-665},
  year =         2014,
  doi =          {10.1007/s10115-013-0679-x},
  url =          {https://doi.org/10.1007/s10115-013-0679-x},
  DATE_ADDED =   {Wed Jul 8 06:43:59 2020},
}

@article{lundberg-2020-from-local,
  author =       {Scott M. Lundberg and Gabriel Erion and Hugh Chen and Alex
                  DeGrave and Jordan M. Prutkin and Bala Nair and Ronit Katz and
                  Jonathan Himmelfarb and Nisha Bansal and Su-In Lee},
  title =        {From Local Explanations To Global Understanding With
                  Explainable Ai for Trees},
  journal =      {Nature Machine Intelligence},
  volume =       2,
  number =       1,
  pages =        {56-67},
  year =         2020,
  doi =          {10.1038/s42256-019-0138-9},
  url =          {https://doi.org/10.1038/s42256-019-0138-9},
  DATE_ADDED =   {Wed Jul 8 07:11:34 2020},
}

@inbook{shapley-1953,
  DATE_ADDED =   {Wed Jul 8 07:14:36 2020},
  author =       {L. S. Shapley},
  booktitle =    {Contributions to the Theory of Games (AM-28), Volume II},
  doi =          {10.1515/9781400881970-018},
  pages =        {307-318},
  publisher =    {Princeton University Press},
  chapter = 17,
  series =       {Contributions to the Theory of Games (AM-28), Volume II},
  title =        {17. A Value for n-Person Games},
  url =          {https://doi.org/10.1515/9781400881970-018},
  year =         1953,
}


@inbook{shapley-1988,
  DATE_ADDED =   {Wed Jul 8 07:17:29 2020},
  author =       {Lloyd S. Shapley},
  booktitle =    {The Shapley Value},
  doi =          {10.1017/cbo9780511528446.003},
  pages =        {31-40},
  publisher =    {Cambridge University Press},
  series =       {The Shapley Value},
  title =        {A value for n-person games},
  url =          {https://doi.org/10.1017/cbo9780511528446.003},
  year =         {1988},
}

@book{quinlan_c4.5_1993,
  author =       {Quinlan, J. R.},
  publisher =    {Morgan Kaufmann Publishers},
  address =      {San Mateo, Calif.},
  isbn =         {9780080500584, 0080500587},
  title =        {C4.5 : programs for machine learning},
  date =         1993,
  language =     {eng},
}
                  
@article{janzing-2019-featur-relev,
  author =       {Janzing, Dominik and Minorics, Lenon and Bl{\"o}baum, Patrick},
  title =        {Feature Relevance Quantification in Explainable Ai: a Causal
                  Problem},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1910.13413v2},
  abstract =     {We discuss promising recent contributions on quantifying
                  feature relevance using Shapley values, where we observed some
                  confusion on which probability distribution is the right one
                  for dropped features. We argue that the confusion is based on
                  not carefully distinguishing between observational and
                  interventional conditional probabilities and try a
                  clarification based on Pearl's seminal work on causality. We
                  conclude that unconditional rather than conditional
                  expectations provide the right notion of dropping features in
                  contradiction to the theoretical justification of the software
                  package SHAP. Parts of SHAP are unaffected because
                  unconditional expectations (which we argue to be conceptually
                  right) are used as approximation for the conditional ones,
                  which encouraged others to `improve' SHAP in a way that we
                  believe to be flawed.},
  archivePrefix ={arXiv},
  eprint =       {1910.13413},
  primaryClass = {stat.ML},
}
@article{sundararajan-2019-many-shapl,
  author =       {Sundararajan, Mukund and Najmi, Amir},
  title =        {The Many Shapley Values for Model Explanation},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1908.08474v2},
  abstract =     {The Shapley value has become a popular method to attribute the
                  prediction of a machine-learning model on an input to its base
                  features. The use of the Shapley value is justified by citing
                  [16] showing that it is the \emph{unique} method that
                  satisfies certain good properties (\emph{axioms}). There are,
                  however, a multiplicity of ways in which the Shapley value is
                  operationalized in the attribution problem. These differ in
                  how they reference the model, the training data, and the
                  explanation context. These give very different results,
                  rendering the uniqueness result meaningless. Furthermore, we
                  find that previously proposed approaches can produce
                  counterintuitive attributions in theory and in practice---for
                  instance, they can assign non-zero attributions to features
                  that are not even referenced by the model. In this paper, we
                  use the axiomatic approach to study the differences between
                  some of the many operationalizations of the Shapley value for
                  attribution, and propose a technique called Baseline Shapley
                  (BShap) that is backed by a proper uniqueness result. We also
                  contrast BShap with Integrated Gradients, another extension of
                  Shapley value to the continuous setting.},
  archivePrefix ={arXiv},
  eprint =       {1908.08474},
  primaryClass = {cs.AI},
}


@inbook{dietterich-2000-ensem-method,
  DATE_ADDED =   {Fri Jul 24 07:08:57 2020},
  author =       {Thomas G. Dietterich},
  booktitle =    {Multiple Classifier Systems},
  doi =          {10.1007/3-540-45014-9_1},
  pages =        {1-15},
  publisher =    {Springer Berlin Heidelberg},
  series =       {Multiple Classifier Systems},
  title =        {Ensemble Methods in Machine Learning},
  url =          {https://doi.org/10.1007/3-540-45014-9_1},
  year =         {2000},
}

@article{holland-1986-statis-causal-infer,
  author =       {Paul W. Holland},
  title =        {Statistics and Causal Inference},
  journal =      {Journal of the American Statistical Association},
  volume =       81,
  number =       396,
  pages =        {945-960},
  year =         1986,
  doi =          {10.1080/01621459.1986.10478354},
  url =          {https://doi.org/10.1080/01621459.1986.10478354},
  DATE_ADDED =   {Tue Aug 18 09:21:46 2020},
}

@article{goldstein-2013-peekin-insid,
  author =       {Goldstein, Alex and Kapelner, Adam and Bleich, Justin and
                  Pitkin, Emil},
  title =        {Peeking Inside the Black Box: Visualizing Statistical Learning
                  With Plots of Individual Conditional Expectation},
  journal =      {CoRR},
  year =         2013,
  url =          {http://arxiv.org/abs/1309.6392v2},
  abstract =     {This article presents Individual Conditional Expectation (ICE)
                  plots, a tool for visualizing the model estimated by any
                  supervised learning algorithm. Classical partial dependence
                  plots (PDPs) help visualize the average partial relationship
                  between the predicted response and one or more features. In
                  the presence of substantial interaction effects, the partial
                  response relationship can be heterogeneous. Thus, an average
                  curve, such as the PDP, can obfuscate the complexity of the
                  modeled relationship. Accordingly, ICE plots refine the
                  partial dependence plot by graphing the functional
                  relationship between the predicted response and the feature
                  for individual observations. Specifically, ICE plots highlight
                  the variation in the fitted values across the range of a
                  covariate, suggesting where and to what extent heterogeneities
                  might exist. In addition to providing a plotting suite for
                  exploratory analysis, we include a visual test for additive
                  structure in the data generating model. Through simulated
                  examples and real data sets, we demonstrate how ICE plots can
                  shed light on estimated models in ways PDPs cannot. Procedures
                  outlined are available in the R package ICEbox.},
  archivePrefix ={arXiv},
  eprint =       {1309.6392},
  primaryClass = {stat.AP},
}
                  
@Article{goldstein-2015-peekin-insid,
  title =        {Peeking Inside the Black Box: Visualizing Statistical Learning
                  With Plots of Individual Conditional Expectation},
  author =       {Alex Goldstein and Adam Kapelner and Justin Bleich and Emil
                  Pitkin},
  journal =      {Journal of Computational and Graphical Statistics},
  volume =       24,
  number =       1,
  pages =        {44--65},
  doi =          {10.1080/10618600.2014.907095},
  year =         2015,
}

@article{ratner-2018-train-compl,
  author =       {Ratner, Alexander and Hancock, Braden and Dunnmon, Jared and
                  Sala, Frederic and Pandey, Shreyash and R{\'e}, Christopher},
  title =        {Training Complex Models With Multi-Task Weak Supervision},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1810.02840v2},
  abstract =     {As machine learning models continue to increase in complexity,
                  collecting large hand-labeled training sets has become one of
                  the biggest roadblocks in practice. Instead, weaker forms of
                  supervision that provide noisier but cheaper labels are often
                  used. However, these weak supervision sources have diverse and
                  unknown accuracies, may output correlated labels, and may
                  label different tasks or apply at different levels of
                  granularity. We propose a framework for integrating and
                  modeling such weak supervision sources by viewing them as
                  labeling different related sub-tasks of a problem, which we
                  refer to as the multi-task weak supervision setting. We show
                  that by solving a matrix completion-style problem, we can
                  recover the accuracies of these multi-task sources given their
                  dependency structure, but without any labeled data, leading to
                  higher-quality supervision for training an end model.
                  Theoretically, we show that the generalization error of models
                  trained with this approach improves with the number of
                  unlabeled data points, and characterize the scaling with
                  respect to the task and dependency structures. On three
                  fine-grained classification problems, we show that our
                  approach leads to average gains of 20.2 points in accuracy
                  over a traditional supervised approach, 6.8 points over a
                  majority vote baseline, and 4.1 points over a previously
                  proposed weak supervision method that models tasks
                  separately.},
  archivePrefix ={arXiv},
  eprint =       {1810.02840},
  primaryClass = {stat.ML},
}


@article{laan-2007-super-learn,
  author =       {Mark J. van der Laan and Eric C Polley and Alan E. Hubbard},
  title =        {Super Learner},
  journal =      {Statistical Applications in Genetics and Molecular Biology},
  volume =       6,
  number =       1,
  pages =        {nil},
  year =         2007,
  doi =          {10.2202/1544-6115.1309},
  url =          {https://doi.org/10.2202/1544-6115.1309},
  DATE_ADDED =   {Wed Aug 19 19:29:10 2020},
}

@article{raykar-2010-learning,
  abstract =     {For many supervised learning tasks it may be infeasible (or
                  very expensive) to obtain objective and reliable labels.
                  Instead, we can collect subjective (possibly noisy) labels
                  from multiple experts or annotators. In practice, there is a
                  substantial amount of disagreement among the annotators, and
                  hence it is of great practical interest to address
                  conventional supervised learning problems in this scenario. In
                  this paper we describe a probabilistic approach for supervised
                  learning when we have multiple annotators providing (possibly
                  noisy) labels but no absolute gold standard. The proposed
                  algorithm evaluates the different experts and also gives an
                  estimate of the actual hidden labels. Experimental results
                  indicate that the proposed method is superior to the commonly
                  used majority voting baseline.},
  acmid =        {1859894},
  added-at =     {2012-06-20T11:57:50.000+0200},
  author =       {Raykar, Vikas C. and Yu, Shipeng and Zhao, Linda H. and
                  Valadez, Gerardo Hermosillo and Florin, Charles and Bogoni,
                  Luca and Moy, Linda},
  biburl =
                  {https://www.bibsonomy.org/bibtex/214220abe8babfab01c0cdd5ebd5e4b7c/jaeschke},
  interhash =    {8113daf47997fddf48e4c6c79f2eba56},
  intrahash =    {14220abe8babfab01c0cdd5ebd5e4b7c},
  issn =         {1532-4435},
  issue_date =   {3/1/2010},
  journal =      {Journal of Machine Learning Research},
  keywords =     {cirg collective computing crowdsourcing extraction human ie
                  information intelligence learning machine ml social},
  month =        aug,
  numpages =     {26},
  pages =        {1297--1322},
  publisher =    {JMLR.org},
  timestamp =    {2014-07-28T15:57:31.000+0200},
  title =        {Learning From Crowds},
  url =          {http://dl.acm.org/citation.cfm?id=1756006.1859894},
  volume =       11,
  year =         2010
}

@article{zhang-2014-spect-method,
  author =       {Yuchen Zhang and Xi Chen and Dengyong Zhou and Michael I.
                  Jordan},
  title =        {Spectral Methods Meet EM: A Provably Optimal Algorithm for
                  Crowdsourcing},
  journal =      {Journal of Machine Learning Research},
  year =         {2016},
  volume =       {17},
  number =       {102},
  pages =        {1-44},
  url =          {http://jmlr.org/papers/v17/14-511.html}
}                  

@article{settles-2012-activ-learn,
  author =       {Burr Settles},
  title =        {Active Learning},
  journal =      {Synthesis Lectures on Artificial Intelligence and Machine
                  Learning},
  volume =       6,
  number =       1,
  pages =        {1-114},
  year =         2012,
  doi =          {10.2200/s00429ed1v01y201207aim018},
  url =          {https://doi.org/10.2200/s00429ed1v01y201207aim018},
  DATE_ADDED =   {Thu Aug 20 11:15:02 2020},
}


@article{taylor-2018-forecasting,
  author =       {Sean J. Taylor and Benjamin Letham},
  title =        {Forecasting at Scale},
  journal =      {The American Statistician},
  volume =       72,
  number =       1,
  pages =        {37-45},
  year =         2018,
  publisher =    {Taylor \& Francis},
  doi =          {10.1080/00031305.2017.1380080},
  URL =          { https://doi.org/10.1080/00031305.2017.1380080 },
  eprint =       { https://doi.org/10.1080/00031305.2017.1380080 },
  keywords =     {Prophet}
}

@inproceedings{lewis-1994-heterogeneous,
  added-at =     {2008-05-27T08:15:25.000+0200},
  address =      { New Brunswick, US },
  author =       {Lewis, David D. and Catlett, Jason},
  biburl =
                  {https://www.bibsonomy.org/bibtex/295da1a0e7d7a311a9f793cd7fb6105b5/mgrani},
  booktitle =    { Proceedings of {ICML}-94, 11th International Conference on
                  Machine Learning },
  editor =       {Cohen, William W. and Hirsh, Haym},
  interhash =    {e4e54e49e66c14da8f0f2145afa39c32},
  intrahash =    {95da1a0e7d7a311a9f793cd7fb6105b5},
  keywords =     {imported},
  pages =        { 148--156 },
  publisher =    { Morgan Kaufmann Publishers, San Francisco, US },
  timestamp =    {2008-05-27T08:15:40.000+0200},
  title =        { Heterogeneous uncertainty sampling for supervised learning },
  url =          { citeseer.nj.nec.com/135290.html },
  year =         { 1994 }
}

@techreport{settles-2009-active,
  added-at = {2011-03-25T11:05:49.000+0100},
  author = {Settles, Burr},
  biburl = {https://www.bibsonomy.org/bibtex/211a6f820b613ae8cacc5cccfe41f6b38/beate},
  institution = {University of Wisconsin--Madison},
  interhash = {d21ffc0eaffcf51e86e81779fe2b22c2},
  intrahash = {11a6f820b613ae8cacc5cccfe41f6b38},
  keywords = {active-learning literature-review spam-detection survey},
  number = 1648,
  timestamp = {2011-03-25T11:05:49.000+0100},
  title = {Active Learning Literature Survey},
  type = {Computer Sciences Technical Report},
  url = {http://axon.cs.byu.edu/~martinez/classes/778/Papers/settles.activelearning.pdf},
  year = 2009
}

@article{wager-2018-estimation,
  author =       {Stefan Wager and Susan Athey},
  title =        {Estimation and Inference of Heterogeneous Treatment Effects
                  using Random Forests},
  journal =      {Journal of the American Statistical Association},
  volume =       {113},
  number =       {523},
  pages =        {1228-1242},
  year =         {2018},
  publisher =    {Taylor & Francis},
  doi =          {10.1080/01621459.2017.1319839},
  URL =          { https://doi.org/10.1080/01621459.2017.1319839 },
  eprint =       { https://doi.org/10.1080/01621459.2017.1319839 }
}

@article{athey-2015-recur-partit,
  author =       {Athey, Susan and Imbens, Guido},
  title =        {Recursive Partitioning for Heterogeneous Causal Effects},
  journal =      {CoRR},
  year =         2015,
  url =          {http://arxiv.org/abs/1504.01132v3},
  abstract =     {In this paper we study the problems of estimating
                  heterogeneity in causal effects in experimental or
                  observational studies and conducting inference about the
                  magnitude of the differences in treatment effects across
                  subsets of the population. In applications, our method
                  provides a data-driven approach to determine which
                  subpopulations have large or small treatment effects and to
                  test hypotheses about the differences in these effects. For
                  experiments, our method allows researchers to identify
                  heterogeneity in treatment effects that was not specified in a
                  pre-analysis plan, without concern about invalidating
                  inference due to multiple testing. In most of the literature
                  on supervised machine learning (e.g. regression trees, random
                  forests, LASSO, etc.), the goal is to build a model of the
                  relationship between a unit's attributes and an observed
                  outcome. A prominent role in these methods is played by
                  cross-validation which compares predictions to actual outcomes
                  in test samples, in order to select the level of complexity of
                  the model that provides the best predictive power. Our method
                  is closely related, but it differs in that it is tailored for
                  predicting causal effects of a treatment rather than a unit's
                  outcome. The challenge is that the "ground truth" for a causal
                  effect is not observed for any individual unit: we observe the
                  unit with the treatment, or without the treatment, but not
                  both at the same time. Thus, it is not obvious how to use
                  cross-validation to determine whether a causal effect has been
                  accurately predicted. We propose several novel
                  cross-validation criteria for this problem and demonstrate
                  through simulations the conditions under which they perform
                  better than standard methods for the problem of causal
                  effects. We then apply the method to a large-scale field
                  experiment re-ranking results on a search engine.},
  archivePrefix ={arXiv},
  eprint =       {1504.01132},
  primaryClass = {stat.ML},
}

@article{chipman-2010-BART,
  author =       "Chipman, Hugh A. and George, Edward I. and McCulloch, Robert
                  E.",
  doi =          "10.1214/09-AOAS285",
  fjournal =     "Annals of Applied Statistics",
  journal =      "Ann. Appl. Stat.",
  month =        "03",
  number =       "1",
  pages =        "266--298",
  publisher =    "The Institute of Mathematical Statistics",
  title =        "BART: Bayesian additive regression trees",
  url =          "https://doi.org/10.1214/09-AOAS285",
  volume =       "4",
  year =         "2010"
}
@article{guo-2016-entit-embed,
  author =       {Guo, Cheng and Berkhahn, Felix},
  title =        {Entity Embeddings of Categorical Variables},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1604.06737v1},
  abstract =     {We map categorical variables in a function approximation
                  problem into Euclidean spaces, which are the entity embeddings
                  of the categorical variables. The mapping is learned by a
                  neural network during the standard supervised training
                  process. Entity embedding not only reduces memory usage and
                  speeds up neural networks compared with one-hot encoding, but
                  more importantly by mapping similar values close to each other
                  in the embedding space it reveals the intrinsic properties of
                  the categorical variables. We applied it successfully in a
                  recent Kaggle competition and were able to reach the third
                  position with relative simple features. We further demonstrate
                  in this paper that entity embedding helps the neural network
                  to generalize better when the data is sparse and statistics is
                  unknown. Thus it is especially useful for datasets with lots
                  of high cardinality features, where other methods tend to
                  overfit. We also demonstrate that the embeddings obtained from
                  the trained neural network boost the performance of all tested
                  machine learning methods considerably when used as the input
                  features instead. As entity embedding defines a distance
                  measure for categorical variables it can be used for
                  visualizing categorical data and for data clustering.},
  archivePrefix ={arXiv},
  eprint =       {1604.06737},
  primaryClass = {cs.LG},
}
@article{cheng-2016-wide-deep,
  author =       {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and
                  Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and
                  Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir,
                  Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan
                  and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
  title =        {Wide \& Deep Learning for Recommender Systems},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1606.07792v1},
  abstract =     {Generalized linear models with nonlinear feature
                  transformations are widely used for large-scale regression and
                  classification problems with sparse inputs. Memorization of
                  feature interactions through a wide set of cross-product
                  feature transformations are effective and interpretable, while
                  generalization requires more feature engineering effort. With
                  less feature engineering, deep neural networks can generalize
                  better to unseen feature combinations through low-dimensional
                  dense embeddings learned for the sparse features. However,
                  deep neural networks with embeddings can over-generalize and
                  recommend less relevant items when the user-item interactions
                  are sparse and high-rank. In this paper, we present Wide \&
                  Deep learning---jointly trained wide linear models and deep
                  neural networks---to combine the benefits of memorization and
                  generalization for recommender systems. We productionized and
                  evaluated the system on Google Play, a commercial mobile app
                  store with over one billion active users and over one million
                  apps. Online experiment results show that Wide \& Deep
                  significantly increased app acquisitions compared with
                  wide-only and deep-only models. We have also open-sourced our
                  implementation in TensorFlow.},
  archivePrefix ={arXiv},
  eprint =       {1606.07792},
  primaryClass = {cs.LG},
}
@article{parr-2020-nonpar-featur,
  author =       {Parr, Terence and Wilson, James D. and Hamrick, Jeff},
  title =        {Nonparametric Feature Impact and Importance},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2006.04750v1},
  abstract =     {Practitioners use feature importance to rank and eliminate
                  weak predictors during model development in an effort to
                  simplify models and improve generality. Unfortunately, they
                  also routinely conflate such feature importance measures with
                  feature impact, the isolated effect of an explanatory variable
                  on the response variable. This can lead to real-world
                  consequences when importance is inappropriately interpreted as
                  impact for business or medical insight purposes. The dominant
                  approach for computing importances is through interrogation of
                  a fitted model, which works well for feature selection, but
                  gives distorted measures of feature impact. The same method
                  applied to the same data set can yield different feature
                  importances, depending on the model, leading us to conclude
                  that impact should be computed directly from the data. While
                  there are nonparametric feature selection algorithms, they
                  typically provide feature rankings, rather than measures of
                  impact or importance. They also typically focus on
                  single-variable associations with the response. In this paper,
                  we give mathematical definitions of feature impact and
                  importance, derived from partial dependence curves, that
                  operate directly on the data. To assess quality, we show that
                  features ranked by these definitions are competitive with
                  existing feature selection techniques using three real data
                  sets for predictive tasks.},
  archivePrefix ={arXiv},
  eprint =       {2006.04750},
  primaryClass = {cs.LG},
}
                  
@article{parr-2019-techn-repor,
  author =       {Parr, Terence and Wilson, James D.},
  title =        {Technical Report: Partial Dependence Through Stratification},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1907.06698v4},
  abstract =     {Partial dependence curves (FPD) introduced by Friedman, are an
                  important model interpretation tool, but are often not
                  accessible to business analysts and scientists who typically
                  lack the skills to choose, tune, and assess machine learning
                  models. It is also common for the same partial dependence
                  algorithm on the same data to give meaningfully different
                  curves for different models, which calls into question their
                  precision. Expertise is required to distinguish between model
                  artifacts and true relationships in the data. In this paper,
                  we contribute methods for computing partial dependence curves,
                  for both numerical (StratPD) and categorical explanatory
                  variables (CatStratPD), that work directly from training data
                  rather than predictions of a model. Our methods provide a
                  direct estimate of partial dependence, and rely on
                  approximating the partial derivative of an unknown regression
                  function without first fitting a model and then approximating
                  its partial derivative. We investigate settings where
                  contemporary partial dependence methods---including FPD, ALE,
                  and SHAP methods---give biased results. Furthermore, we
                  demonstrate that our approach works correctly on synthetic and
                  plausibly on real data sets. Our goal is not to argue that
                  model-based techniques are not useful. Rather, we hope to open
                  a new line of inquiry into nonparametric partial dependence.},
  archivePrefix ={arXiv},
  eprint =       {1907.06698},
  primaryClass = {cs.LG},
}

@inproceedings{oakden-rayner-2020-hidden,
  author =       {Oakden-Rayner, Luke and Dunnmon, Jared and Carneiro, Gustavo
                  and Re, Christopher},
  title =        {Hidden Stratification Causes Clinically Meaningful Failures in
                  Machine Learning for Medical Imaging},
  year =         {2020},
  isbn =         {9781450370462},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi-org.proxy.library.nyu.edu/10.1145/3368555.3384468},
  doi =          {10.1145/3368555.3384468},
  abstract =     {Machine learning models for medical image analysis often
                  suffer from poor performance on important subsets of a
                  population that are not identified during training or testing.
                  For example, overall performance of a cancer detection model
                  may be high, but the model may still consistently miss a rare
                  but aggressive cancer subtype. We refer to this problem as
                  hidden stratification, and observe that it results from
                  incompletely describing the meaningful variation in a dataset.
                  While hidden stratification can substantially reduce the
                  clinical efficacy of machine learning models, its effects
                  remain difficult to measure. In this work, we assess the
                  utility of several possible techniques for measuring hidden
                  stratification effects, and characterize these effects both
                  via synthetic experiments on the CIFAR-100 benchmark dataset
                  and on multiple real-world medical imaging datasets. Using
                  these measurement techniques, we find evidence that hidden
                  stratification can occur in unidentified imaging subsets with
                  low prevalence, low label quality, subtle distinguishing
                  features, or spurious correlates, and that it can result in
                  relative performance differences of over 20\% on clinically
                  important subsets. Finally, we discuss the clinical
                  implications of our findings, and suggest that evaluation of
                  hidden stratification should be a critical component of any
                  machine learning deployment in medical imaging.},
  booktitle =    {Proceedings of the ACM Conference on Health, Inference, and
                  Learning},
  pages =        {151–159},
  numpages =     {9},
  keywords =     {hidden stratification, machine learning, convolutional neural
                  networks},
  location =     {Toronto, Ontario, Canada},
  series =       {CHIL '20}
}

@InProceedings{swaminathan-2015-counterfactual,
  title =        {Counterfactual Risk Minimization: Learning from Logged Bandit
                  Feedback},
  author =       {Adith Swaminathan and Thorsten Joachims},
  pages =        {814--823},
  year =         {2015},
  editor =       {Francis Bach and David Blei},
  volume =       {37},
  series =       {Proceedings of Machine Learning Research},
  address =      {Lille, France},
  month =        {07--09 Jul},
  publisher =    {PMLR},
  pdf =          {http://proceedings.mlr.press/v37/swaminathan15.pdf},
  url =          {http://proceedings.mlr.press/v37/swaminathan15.html},
  abstract =     {We develop a learning principle and an efficient algorithm for
                  batch learning from logged bandit feedback. This learning
                  setting is ubiquitous in online systems (e.g., ad placement,
                  web search, recommendation), where an algorithm makes a
                  prediction (e.g., ad ranking) for a given input (e.g., query)
                  and observes bandit feedback (e.g., user clicks on presented
                  ads). We first address the counterfactual nature of the
                  learning problem through propensity scoring. Next, we prove
                  generalization error bounds that account for the variance of
                  the propensity-weighted empirical risk estimator. These
                  constructive bounds give rise to the Counterfactual Risk
                  Minimization (CRM) principle. We show how CRM can be used to
                  derive a new learning method – called Policy Optimizer for
                  Exponential Models (POEM) – for learning stochastic linear
                  rules for structured output prediction. We present a
                  decomposition of the POEM objective that enables efficient
                  stochastic gradient optimization. POEM is evaluated on several
                  multi-label classification problems showing substantially
                  improved robustness and generalization performance compared to
                  the state-of-the-art.}
}

@incollection{swaminathan-2015-self,
  title =        {The Self-Normalized Estimator for Counterfactual Learning},
  author =       {Swaminathan, Adith and Joachims, Thorsten},
  booktitle =    {Advances in Neural Information Processing Systems 28},
  editor =       {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and
                  R. Garnett},
  pages =        {3231--3239},
  year =         {2015},
  publisher =    {Curran Associates, Inc.},
  url =
                  {http://papers.nips.cc/paper/5748-the-self-normalized-estimator-for-counterfactual-learning.pdf}
}

@inproceedings{makar-2019-distillation,
  author =       {Maggie Makar and Adith Swaminathan and Emre Kiciman},
  title =        {A Distillation Approach to Data Efficient Individual Treatment
                  Effect Estimation},
  booktitle =    {The Thirty-Third {AAAI} Conference on Artificial Intelligence,
                  {AAAI} 2019, The Thirty-First Innovative Applications of
                  Artificial Intelligence Conference, {IAAI} 2019, The Ninth
                  {AAAI} Symposium on Educational Advances in Artificial
                  Intelligence, {EAAI} 2019, Honolulu, Hawaii, USA, January 27 -
                  February 1, 2019},
  pages =        {4544--4551},
  publisher =    {{AAAI} Press},
  year =         {2019},
  url =          {https://doi.org/10.1609/aaai.v33i01.33014544},
  doi =          {10.1609/aaai.v33i01.33014544},
  timestamp =    {Wed, 25 Sep 2019 11:05:08 +0200},
  biburl =       {https://dblp.org/rec/conf/aaai/MakarSK19.bib},
  bibsource =    {dblp computer science bibliography, https://dblp.org}
}
@article{lefortier-2016-large-scale,
  author =       {Lefortier, Damien and Swaminathan, Adith and Gu, Xiaotao and
                  Joachims, Thorsten and Rijke, Maarten de},
  title =        {Large-Scale Validation of Counterfactual Learning Methods: a
                  Test-Bed},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1612.00367v2},
  abstract =     {The ability to perform effective off-policy learning would
                  revolutionize the process of building better interactive
                  systems, such as search engines and recommendation systems for
                  e-commerce, computational advertising and news. Recent
                  approaches for off-policy evaluation and learning in these
                  settings appear promising. With this paper, we provide
                  real-world data and a standardized test-bed to systematically
                  investigate these algorithms using data from display
                  advertising. In particular, we consider the problem of filling
                  a banner ad with an aggregate of multiple products the user
                  may want to purchase. This paper presents our test-bed, the
                  sanity checks we ran to ensure its validity, and shows results
                  comparing state-of-the-art off-policy learning methods like
                  doubly robust optimization, POEM, and reductions to supervised
                  learning using regression baselines. Our results show
                  experimental evidence that recent off-policy learning methods
                  can improve upon state-of-the-art supervised learning
                  techniques on a large-scale real-world data set.},
  archivePrefix ={arXiv},
  eprint =       {1612.00367},
  primaryClass = {cs.LG},
}

@incollection{swaminathan-2017-off-polic,
  title =        {Off-policy evaluation for slate recommendation},
  author =       {Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal,
                  Alekh and Dudik, Miro and Langford, John and Jose, Damien and
                  Zitouni, Imed},
  booktitle =    {Advances in Neural Information Processing Systems 30},
  editor =       {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R.
                  Fergus and S. Vishwanathan and R. Garnett},
  pages =        {3632--3642},
  year =         {2017},
  publisher =    {Curran Associates, Inc.},
  url =
                  {http://papers.nips.cc/paper/6954-off-policy-evaluation-for-slate-recommendation.pdf}
}

@article{swaminathan-2016-off-polic,
  author =       {Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal,
                  Alekh and Dud{\'i}k, Miroslav and Langford, John and Jose,
                  Damien and Zitouni, Imed},
  title =        {Off-Policy Evaluation for Slate Recommendation},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1605.04812v3},
  abstract =     {This paper studies the evaluation of policies that recommend
                  an ordered set of items (e.g., a ranking) based on some
                  context---a common scenario in web search, ads, and
                  recommendation. We build on techniques from combinatorial
                  bandits to introduce a new practical estimator that uses
                  logged data to estimate a policy's performance. A thorough
                  empirical evaluation on real-world data reveals that our
                  estimator is accurate in a variety of settings, including as a
                  subroutine in a learning-to-rank task, where it achieves
                  competitive performance. We derive conditions under which our
                  estimator is unbiased---these conditions are weaker than prior
                  heuristics for slate evaluation---and experimentally
                  demonstrate a smaller bias than parametric approaches, even
                  when these conditions are violated. Finally, our theory and
                  experiments also show exponential savings in the amount of
                  required data compared with general unbiased estimators.},
  archivePrefix ={arXiv},
  eprint =       {1605.04812},
  primaryClass = {cs.LG},
}

@InProceedings{mothilal-2020-explaining,
  author =       {Mothilal, Ramaravind K. and Sharma, Amit and Tan, Chenhao},
  title =        {Explaining Machine Learning Classifiers through Diverse
                  Counterfactual Examples},
  booktitle =    {ACM Conference on Fairness, Accountability, and Transparency},
  year =         {2020},
  month =        {January},
  abstract =     {Post-hoc explanations of machine learning models are crucial
                  for people to understand and act on algorithmic predictions.
                  An intriguing class of explanations is through
                  counterfactuals, hypothetical examples that show people how to
                  obtain a different prediction. We posit that effective
                  counterfactual explanations should satisfy two properties:
                  feasibility of the counterfactual actions given user context
                  and constraints, and diversity among the counterfactuals
                  presented. To this end, we propose a framework for generating
                  and evaluating a diverse set of counterfactual explanations
                  based on determinantal point processes. To evaluate the
                  actionability of counterfactuals, we provide metrics that
                  enable comparison of counterfactual-based methods to other
                  local explanation methods. We further address necessary
                  tradeoffs and point to causal implications in optimizing for
                  counterfactuals. Our experiments on four real-world datasets
                  show that our framework can generate a set of counterfactuals
                  that are diverse and well approximate local decision
                  boundaries, outperforming prior approaches to generating
                  diverse counterfactuals. We provide an implementation of the
                  framework at https://github.com/microsoft/DiCE.},
  url =
                  {https://www.microsoft.com/en-us/research/publication/explaining-machine-learning-classifiers-through-diverse-counterfactual-examples/},
}

@INPROCEEDINGS{pozzolo-2015-calibrating,
  author =       {A. D. {Pozzolo} and O. {Caelen} and R. A. {Johnson} and G.
                  {Bontempi}},
  booktitle =    {2015 IEEE Symposium Series on Computational Intelligence},
  title =        {Calibrating Probability with Undersampling for Unbalanced
                  Classification},
  year =         {2015},
  volume =       {},
  number =       {},
  pages =        {159-166},
}

@inproceedings{dacrema-2019-are-we-really,
  author =       {Dacrema, Maurizio Ferrari and Cremonesi, Paolo and Jannach,
                  Dietmar},
  title =        {Are We Really Making Much Progress? A Worrying Analysis of
                  Recent Neural Recommendation Approaches},
  year =         {2019},
  isbn =         {9781450362436},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi-org.proxy.library.nyu.edu/10.1145/3298689.3347058},
  doi =          {10.1145/3298689.3347058},
  abstract =     {Deep learning techniques have become the method of choice for
                  researchers working on algorithmic aspects of recommender
                  systems. With the strongly increased interest in machine
                  learning in general, it has, as a result, become difficult to
                  keep track of what represents the state-of-the-art at the
                  moment, e.g., for top-n recommendation tasks. At the same
                  time, several recent publications point out problems in
                  today's research practice in applied machine learning, e.g.,
                  in terms of the reproducibility of the results or the choice
                  of the baselines when proposing new models.In this work, we
                  report the results of a systematic analysis of algorithmic
                  proposals for top-n recommendation tasks. Specifically, we
                  considered 18 algorithms that were presented at top-level
                  research conferences in the last years. Only 7 of them could
                  be reproduced with reasonable effort. For these methods, it
                  however turned out that 6 of them can often be outperformed
                  with comparably simple heuristic methods, e.g., based on
                  nearest-neighbor or graph-based techniques. The remaining one
                  clearly outperformed the baselines but did not consistently
                  outperform a well-tuned non-neural linear ranking method.
                  Overall, our work sheds light on a number of potential
                  problems in today's machine learning scholarship and calls for
                  improved scientific practices in this area.},
  booktitle =    {Proceedings of the 13th ACM Conference on Recommender Systems},
  pages =        {101–109},
  numpages =     {9},
  keywords =     {evaluation, reproducibility, recommender systems, deep
                  learning},
  location =     {Copenhagen, Denmark},
  series =       {RecSys '19}
}

@article{dacrema-2019-troub-analy
,
  author =       {Dacrema, Maurizio Ferrari and Boglio, Simone and Cremonesi,
                  Paolo and Jannach, Dietmar},
  title =        {A Troubling Analysis of Reproducibility and Progress in
                  Recommender Systems Research},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1911.07698v2},
  abstract =     {The design of algorithms that generate personalized ranked
                  item lists is a central topic of research in the field of
                  recommender systems. In the past few years, in particular,
                  approaches based on deep learning (neural) techniques have
                  become dominant in the literature. For all of them,
                  substantial progress over the state-of-the-art is claimed.
                  However, indications exist of certain problems in today's
                  research practice, e.g., with respect to the choice and
                  optimization of the baselines used for comparison, raising
                  questions about the published claims. In order to obtain a
                  better understanding of the actual progress, we have tried to
                  reproduce recent results in the area of neural recommendation
                  approaches based on collaborative filtering. The worrying
                  outcome of the analysis of these recent works-all were
                  published at prestigious scientific conferences between 2015
                  and 2018-is that 11 out of the 12 reproducible neural
                  approaches can be outperformed by conceptually simple methods,
                  e.g., based on the nearest-neighbor heuristics. None of the
                  computationally complex neural methods was actually
                  consistently better than already existing learning-based
                  techniques, e.g., using matrix factorization or linear models.
                  In our analysis, we discuss common issues in today's research
                  practice, which, despite the many papers that are published on
                  the topic, have apparently led the field to a certain level of
                  stagnation.},
  archivePrefix ={arXiv},
  eprint =       {1911.07698},
  primaryClass = {cs.IR},
}


@inproceedings{steck-2019-embar-shall,
  author =       {Steck, Harald},
  title =        {Embarrassingly Shallow Autoencoders for Sparse Data},
  year =         {2019},
  isbn =         {9781450366748},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi.org/10.1145/3308558.3313710},
  doi =          {10.1145/3308558.3313710},
  abstract =     {Combining simple elements from the literature, we define a
                  linear model that is geared toward sparse data, in particular
                  implicit feedback data for recommender systems. We show that
                  its training objective has a closed-form solution, and discuss
                  the resulting conceptual insights. Surprisingly, this simple
                  model achieves better ranking accuracy than various
                  state-of-the-art collaborative-filtering approaches, including
                  deep non-linear models, on most of the publicly available
                  data-sets used in our experiments.},
  booktitle =    {The World Wide Web Conference},
  pages =        {3251–3257},
  numpages =     {7},
  keywords =     {Autoencoder, Neighborhood Approach, Collaborative Filtering,
                  Closed-Form Solution, Linear Regression, Recommender System},
  location =     {San Francisco, CA, USA},
  series =       {WWW '19}
}

@inproceedings{elahi-2019-varia-low,
author = {Elahi, Ehtsham and Wang, Wei and Ray, Dave and Fenton, Aish and Jebara, Tony},
title = {Variational Low Rank Multinomials for Collaborative Filtering with Side-Information},
year = {2019},
isbn = {9781450362436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3298689.3347036},
doi = {10.1145/3298689.3347036},
abstract = {We are interested in Bayesian models for collaborative filtering that incorporate side-information or metadata about items in addition to user-item interaction data. We present a simple and flexible framework to build models for this task that exploit the low-rank structure in user-item interaction datasets. Although the resulting models are non-conjugate, we develop an efficient technique for approximating posteriors over model parameters using variational inference. We borrow the "re-parameterization trick" from Bayesian deep learning literature to enable variational inference in our models. The resulting approximate Bayesian inference algorithm is scalable and can handle large scale datasets. We demonstrate our ideas on three real world datasets where we show competitive performance against widely used baselines.},
booktitle = {Proceedings of the 13th ACM Conference on Recommender Systems},
pages = {340–347},
numpages = {8},
keywords = {variational inference, collaborative filtering, side-information},
location = {Copenhagen, Denmark},
series = {RecSys '19}
}

@INPROCEEDINGS{ning-2011-slim-sparse,
  author =       {X. {Ning} and G. {Karypis}},
  booktitle =    {2011 IEEE 11th International Conference on Data Mining},
  title =        {SLIM: Sparse Linear Methods for Top-N Recommender Systems},
  year =         {2011},
  volume =       {},
  number =       {},
  pages =        {497-506},
}

@article{rendle-2019-diffic-evaluat-basel,
  author =       {Rendle, Steffen and Zhang, Li and Koren, Yehuda},
  title =        {On the Difficulty of Evaluating Baselines: a Study on
                  Recommender Systems},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1905.01395v1},
  abstract =     {Numerical evaluations with comparisons to baselines play a
                  central role when judging research in recommender systems. In
                  this paper, we show that running baselines properly is
                  difficult. We demonstrate this issue on two extensively
                  studied datasets. First, we show that results for baselines
                  that have been used in numerous publications over the past
                  five years for the Movielens 10M benchmark are suboptimal.
                  With a careful setup of a vanilla matrix factorization
                  baseline, we are not only able to improve upon the reported
                  results for this baseline but even outperform the reported
                  results of any newly proposed method. Secondly, we recap the
                  tremendous effort that was required by the community to obtain
                  high quality results for simple methods on the Netflix Prize.
                  Our results indicate that empirical findings in research
                  papers are questionable unless they were obtained on
                  standardized benchmarks where baselines have been tuned
                  extensively by the research community.},
  archivePrefix ={arXiv},
  eprint =       {1905.01395},
  primaryClass = {cs.IR},
}
@article{liang-2018-variat-autoen,
  author =       {Liang, Dawen and Krishnan, Rahul G. and Hoffman, Matthew D.
                  and Jebara, Tony},
  title =        {Variational Autoencoders for Collaborative Filtering},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1802.05814v1},
  abstract =     {We extend variational autoencoders (VAEs) to collaborative
                  filtering for implicit feedback. This non-linear probabilistic
                  model enables us to go beyond the limited modeling capacity of
                  linear factor models which still largely dominate
                  collaborative filtering research.We introduce a generative
                  model with multinomial likelihood and use Bayesian inference
                  for parameter estimation. Despite widespread use in language
                  modeling and economics, the multinomial likelihood receives
                  less attention in the recommender systems literature. We
                  introduce a different regularization parameter for the
                  learning objective, which proves to be crucial for achieving
                  competitive performance. Remarkably, there is an efficient way
                  to tune the parameter using annealing. The resulting model and
                  learning algorithm has information-theoretic connections to
                  maximum entropy discrimination and the information bottleneck
                  principle. Empirically, we show that the proposed approach
                  significantly outperforms several state-of-the-art baselines,
                  including two recently-proposed neural network approaches, on
                  several real-world datasets. We also provide extended
                  experiments comparing the multinomial likelihood with other
                  commonly used likelihood functions in the latent factor
                  collaborative filtering literature and show favorable results.
                  Finally, we identify the pros and cons of employing a
                  principled Bayesian inference approach and characterize
                  settings where it provides the most significant improvements.},
  archivePrefix ={arXiv},
  eprint =       {1802.05814},
  primaryClass = {stat.ML},
}

@INPROCEEDINGS{rendle-2010-factor-machin,
  author =       {S. {Rendle}},
  booktitle =    {2010 IEEE International Conference on Data Mining},
  title =        {Factorization Machines},
  year =         {2010},
  volume =       {},
  number =       {},
  pages =        {995-1000},
}

@inproceedings{rendle-2009-bayesian-personalized,
  author =       {Rendle, Steffen and Freudenthaler, Christoph and Gantner, Zeno
                  and Schmidt-Thieme, Lars},
  title =        {BPR: Bayesian Personalized Ranking from Implicit Feedback},
  year =         {2009},
  isbn =         {9780974903958},
  publisher =    {AUAI Press},
  address =      {Arlington, Virginia, USA},
  abstract =     {Item recommendation is the task of predicting a personalized
                  ranking on a set of items (e.g. websites, movies, products).
                  In this paper, we investigate the most common scenario with
                  implicit feedback (e.g. clicks, purchases). There are many
                  methods for item recommendation from implicit feedback like
                  matrix factorization (MF) or adaptive k-nearest-neighbor
                  (kNN). Even though these methods are designed for the item
                  prediction task of personalized ranking, none of them is
                  directly optimized for ranking. In this paper we present a
                  generic optimization criterion BPR-Opt for personalized
                  ranking that is the maximum posterior estimator derived from a
                  Bayesian analysis of the problem. We also provide a generic
                  learning algorithm for optimizing models with respect to
                  BPR-Opt. The learning method is based on stochastic gradient
                  descent with bootstrap sampling. We show how to apply our
                  method to two state-of-the-art recommender models: matrix
                  factorization and adaptive kNN. Our experiments indicate that
                  for the task of personalized ranking our optimization method
                  outperforms the standard learning techniques for MF and kNN.
                  The results show the importance of optimizing models for the
                  right criterion.},
  booktitle =    {Proceedings of the Twenty-Fifth Conference on Uncertainty in
                  Artificial Intelligence},
  pages =        {452–461},
  numpages =     {10},
  location =     {Montreal, Quebec, Canada},
  series =       {UAI '09}
}

@inproceedings{cremonesi-2010-perf-recom-algor,
  author =       {Cremonesi, Paolo and Koren, Yehuda and Turrin, Roberto},
  title =        {Performance of Recommender Algorithms on Top-n Recommendation
                  Tasks},
  year =         {2010},
  isbn =         {9781605589060},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi.org/10.1145/1864708.1864721},
  doi =          {10.1145/1864708.1864721},
  abstract =     {In many commercial systems, the 'best bet' recommendations are
                  shown, but the predicted rating values are not. This is
                  usually referred to as a top-N recommendation task, where the
                  goal of the recommender system is to find a few specific items
                  which are supposed to be most appealing to the user. Common
                  methodologies based on error metrics (such as RMSE) are not a
                  natural fit for evaluating the top-N recommendation task.
                  Rather, top-N performance can be directly measured by
                  alternative methodologies based on accuracy metrics (such as
                  precision/recall).An extensive evaluation of several
                  state-of-the art recommender algorithms suggests that
                  algorithms optimized for minimizing RMSE do not necessarily
                  perform as expected in terms of top-N recommendation task.
                  Results show that improvements in RMSE often do not translate
                  into accuracy improvements. In particular, a naive
                  non-personalized algorithm can outperform some common
                  recommendation approaches and almost match the accuracy of
                  sophisticated algorithms. Another finding is that the very few
                  top popular items can skew the top-N performance. The analysis
                  points out that when evaluating a recommender algorithm on the
                  top-N recommendation task, the test set should be chosen
                  carefully in order to not bias accuracy metrics towards
                  non-personalized solutions. Finally, we offer practitioners
                  new variants of two collaborative filtering algorithms that,
                  regardless of their RMSE, significantly outperform other
                  recommender algorithms in pursuing the top-N recommendation
                  task, with offering additional practical advantages. This
                  comes at surprise given the simplicity of these two methods.},
  booktitle =    {Proceedings of the Fourth ACM Conference on Recommender
                  Systems},
  pages =        {39–46},
  numpages =     {8},
  keywords =     {precision, evaluation, top-n recommendations, recall},
  location =     {Barcelona, Spain},
  series =       {RecSys '10}
}
@article{zhang-2017-deep-learn,
  author =       {Zhang, Shuai and Yao, Lina and Sun, Aixin and Tay, Yi},
  title =        {Deep Learning Based Recommender System: a Survey and New
                  Perspectives},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1707.07435v7},
  abstract =     {With the ever-growing volume of online information,
                  recommender systems have been an effective strategy to
                  overcome such information overload. The utility of recommender
                  systems cannot be overstated, given its widespread adoption in
                  many web applications, along with its potential impact to
                  ameliorate many problems related to over-choice. In recent
                  years, deep learning has garnered considerable interest in
                  many research fields such as computer vision and natural
                  language processing, owing not only to stellar performance but
                  also the attractive property of learning feature
                  representations from scratch. The influence of deep learning
                  is also pervasive, recently demonstrating its effectiveness
                  when applied to information retrieval and recommender systems
                  research. Evidently, the field of deep learning in recommender
                  system is flourishing. This article aims to provide a
                  comprehensive review of recent research efforts on deep
                  learning based recommender systems. More concretely, we
                  provide and devise a taxonomy of deep learning based
                  recommendation models, along with providing a comprehensive
                  summary of the state-of-the-art. Finally, we expand on current
                  trends and provide new perspectives pertaining to this new
                  exciting development of the field.},
  archivePrefix ={arXiv},
  eprint =       {1707.07435},
  primaryClass = {cs.IR},
}

@book{zhang-2020-dive,
    title={Dive into Deep Learning},
    author={Aston Zhang and Zachary C. Lipton and Mu Li and Alexander J. Smola},
    note={\url{https://d2l.ai}},
    year={2020}
}

@INPROCEEDINGS{hu-2008-collab-filt-implicit,
  author =       {Y. {Hu} and Y. {Koren} and C. {Volinsky}},
  booktitle =    {2008 Eighth IEEE International Conference on Data Mining},
  title =        {Collaborative Filtering for Implicit Feedback Datasets},
  year =         {2008},
  volume =       {},
  number =       {},
  pages =        {263-272},
}

@article{neeraj2020wsfortoxicity,
    title = "Data Labeling using Weak Supervision: In Action",
    author = "Neeraj, Trishala",
    journal = "trishalaneeraj.github.io",
    year = "2020",
    url = "https://trishalaneeraj.github.io/2020-07-26/data-labeling-weak-supervision"
}

@inproceedings{sedhain-2015-autorec,
author = {Sedhain, Suvash and Menon, Aditya Krishna and Sanner, Scott and Xie, Lexing},
title = {AutoRec: Autoencoders Meet Collaborative Filtering},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2742726},
doi = {10.1145/2740908.2742726},
abstract = {This paper proposes AutoRec, a novel autoencoder framework for collaborative filtering (CF). Empirically, AutoRec's compact and efficiently trainable model outperforms state-of-the-art CF techniques (biased matrix factorization, RBM-CF and LLORMA) on the Movielens and Netflix datasets.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {111–112},
numpages = {2},
keywords = {collaborative filtering, autoencoders, recommender systems},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{steck-2013-eval-rec,
  author =       {Steck, Harald},
  title =        {Evaluation of Recommendations: Rating-Prediction and Ranking},
  year =         {2013},
  isbn =         {9781450324090},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi.org/10.1145/2507157.2507160},
  doi =          {10.1145/2507157.2507160},
  abstract =     {The literature on recommender systems distinguishes typically
                  between two broad categories of measuring recommendation
                  accuracy: rating prediction, often quantified in terms of the
                  root mean square error (RMSE), and ranking, measured in terms
                  of metrics like precision and recall, among others. In this
                  paper, we examine both approaches in detail, and find that the
                  dominating difference lies instead in the training and test
                  data considered: rating prediction is concerned with only the
                  observed ratings, while ranking typically accounts for all
                  items in the collection, whether the user has rated them or
                  not. Furthermore, we show that predicting observed ratings,
                  while popular in the literature, only solves a (small) part of
                  the rating prediction task for any item in the collection,
                  which is a common real-world problem. The reasons are
                  selection bias in the data, combined with data sparsity. We
                  show that the latter rating-prediction task involves the
                  prediction task 'Who rated What' as a sub-problem, which can
                  be cast as a classification or ranking problem. This suggests
                  that solving the ranking problem is not only valuable by
                  itself, but also for predicting the rating value of any item.},
  booktitle =    {Proceedings of the 7th ACM Conference on Recommender Systems},
  pages =        {213–220},
  numpages =     {8},
  keywords =     {recommender systems, selection bias, ranking, rating
                  prediction},
  location =     {Hong Kong, China},
  series =       {RecSys '13}
}

@inproceedings{he-2017-neural-collab-filt,
  author =       {He, Xiangnan and Liao, Lizi and Zhang, Hanwang and Nie,
                  Liqiang and Hu, Xia and Chua, Tat-Seng},
  title =        {Neural Collaborative Filtering},
  year =         {2017},
  isbn =         {9781450349130},
  publisher =    {International World Wide Web Conferences Steering Committee},
  address =      {Republic and Canton of Geneva, CHE},
  url =          {https://doi.org/10.1145/3038912.3052569},
  doi =          {10.1145/3038912.3052569},
  abstract =     {In recent years, deep neural networks have yielded immense
                  success on speech recognition, computer vision and natural
                  language processing. However, the exploration of deep neural
                  networks on recommender systems has received relatively less
                  scrutiny. In this work, we strive to develop techniques based
                  on neural networks to tackle the key problem in recommendation
                  --- collaborative filtering --- on the basis of implicit
                  feedback.Although some recent work has employed deep learning
                  for recommendation, they primarily used it to model auxiliary
                  information, such as textual descriptions of items and
                  acoustic features of musics. When it comes to model the key
                  factor in collaborative filtering --- the interaction between
                  user and item features, they still resorted to matrix
                  factorization and applied an inner product on the latent
                  features of users and items.By replacing the inner product
                  with a neural architecture that can learn an arbitrary
                  function from data, we present a general framework named NCF,
                  short for Neural network-based Collaborative Filtering. NCF is
                  generic and can express and generalize matrix factorization
                  under its framework. To supercharge NCF modelling with
                  non-linearities, we propose to leverage a multi-layer
                  perceptron to learn the user-item interaction function.
                  Extensive experiments on two real-world datasets show
                  significant improvements of our proposed NCF framework over
                  the state-of-the-art methods. Empirical evidence shows that
                  using deeper layers of neural networks offers better
                  recommendation performance.},
  booktitle =    {Proceedings of the 26th International Conference on World Wide
                  Web},
  pages =        {173–182},
  numpages =     {10},
  keywords =     {matrix factorization, collaborative filtering, implicit
                  feedback, neural networks, deep learning},
  location =     {Perth, Australia},
  series =       {WWW '17}
}

@inbook{lee-2010-exploit-contex,
  DATE_ADDED =   {Thu Sep 17 09:12:34 2020},
  author =       {Dongjoo Lee and Sung Eun Park and Minsuk Kahng and Sangkeun
                  Lee and Sang-goo Lee},
  booktitle =    {Computer and Information Science 2010},
  doi =          {10.1007/978-3-642-15405-8_11},
  pages =        {121-139},
  publisher =    {Springer Berlin Heidelberg},
  series =       {Computer and Information Science 2010},
  title =        {Exploiting Contextual Information from Event Logs for
                  Personalized Recommendation},
  url =          {https://doi.org/10.1007/978-3-642-15405-8_11},
  year =         {2010},
}

@article{deshpande-2004-item-based,
  author =       {Deshpande, Mukund and Karypis, George},
  title =        {Item-Based Top-<i>N</i> Recommendation Algorithms},
  year =         {2004},
  issue_date =   {January 2004},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  volume =       {22},
  number =       {1},
  issn =         {1046-8188},
  url =          {https://doi-org.proxy.library.nyu.edu/10.1145/963770.963776},
  doi =          {10.1145/963770.963776},
  abstract =     {The explosive growth of the world-wide-web and the emergence
                  of e-commerce has led to the development of recommender
                  systems---a personalized information filtering technology used
                  to identify a set of items that will be of interest to a
                  certain user. User-based collaborative filtering is the most
                  successful technology for building recommender systems to date
                  and is extensively used in many commercial recommender
                  systems. Unfortunately, the computational complexity of these
                  methods grows linearly with the number of customers, which in
                  typical commercial applications can be several millions. To
                  address these scalability concerns model-based recommendation
                  techniques have been developed. These techniques analyze the
                  user--item matrix to discover relations between the different
                  items and use these relations to compute the list of
                  recommendations.In this article, we present one such class of
                  model-based recommendation algorithms that first determines
                  the similarities between the various items and then uses them
                  to identify the set of items to be recommended. The key steps
                  in this class of algorithms are (i) the method used to compute
                  the similarity between the items, and (ii) the method used to
                  combine these similarities in order to compute the similarity
                  between a basket of items and a candidate recommender item.
                  Our experimental evaluation on eight real datasets shows that
                  these item-based algorithms are up to two orders of magnitude
                  faster than the traditional user-neighborhood based
                  recommender systems and provide recommendations with
                  comparable or better quality.},
  journal =      {ACM Trans. Inf. Syst.},
  month =        jan,
  pages =        {143–177},
  numpages =     {35},
  keywords =     {predicting user behavior, world wide web, e-commerce}
}

@inproceedings{agarwal-2019-general-frame-counter,
  author =       {Agarwal, Aman and Takatsu, Kenta and Zaitsev, Ivan and
                  Joachims, Thorsten},
  title =        {A General Framework for Counterfactual Learning-to-Rank},
  year =         {2019},
  isbn =         {9781450361729},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi.org/10.1145/3331184.3331202},
  doi =          {10.1145/3331184.3331202},
  abstract =     {Implicit feedback (e.g., click, dwell time) is an attractive
                  source of training data for Learning-to-Rank, but its naive
                  use leads to learning results that are distorted by
                  presentation bias. For the special case of optimizing average
                  rank for linear ranking functions, however, the recently
                  developed SVM-PropRank method has shown that counterfactual
                  inference techniques can be used to provably overcome the
                  distorting effect of presentation bias. Going beyond this
                  special case, this paper provides a general and theoretically
                  rigorous framework for counterfactual learning-to-rank that
                  enables unbiased training for a broad class of additive
                  ranking metrics (e.g., Discounted Cumulative Gain (DCG)) as
                  well as a broad class of models (e.g., deep networks).
                  Specifically, we derive a relaxation for propensity-weighted
                  rank-based metrics which is subdifferentiable and thus
                  suitable for gradient-based optimization. We demonstrate the
                  effectiveness of this general approach by instantiating two
                  new learning methods. One is a new type of unbiased SVM that
                  optimizes DCG - called SVM PropDCG - and we show how the
                  resulting optimization problem can be solved via the Convex
                  Concave Procedure (CCP). The other is Deep PropDCG, where the
                  ranking function can be an arbitrary deep network. In addition
                  to the theoretical support, we empirically find that SVM
                  PropDCG significantly outperforms existing linear rankers in
                  terms of DCG. Moreover, the ability to train non-linear
                  ranking functions via Deep PropDCG further improves
                  performance.},
  booktitle =    {Proceedings of the 42nd International ACM SIGIR Conference on
                  Research and Development in Information Retrieval},
  pages =        {5–14},
  numpages =     {10},
  keywords =     {counterfactual inference, presentation bias, learning to rank},
  location =     {Paris, France},
  series =       {SIGIR'19}
}

@inproceedings{dudik-2011-doubly-robust,
  author =       {Dud{\'{i}}k, Miroslav and Langford, John and Li, Lihong},
  title =        {Doubly Robust Policy Evaluation and Learning},
  year =         {2011},
  isbn =         {9781450306195},
  publisher =    {Omnipress},
  address =      {Madison, WI, USA},
  abstract =     {We study decision making in environments where the reward is
                  only partially observed, but can be modeled as a function of
                  an action and an observed context. This setting, known as
                  contextual bandits, encompasses a wide variety of applications
                  including health-care policy and Internet advertising. A
                  central task is evaluation of a new policy given historic data
                  consisting of contexts, actions and received rewards. The key
                  challenge is that the past data typically does not faithfully
                  represent proportions of actions taken by a new policy.
                  Previous approaches rely either on models of rewards or models
                  of the past policy. The former are plagued by a large bias
                  whereas the latter have a large variance.In this work, we
                  leverage the strength and overcome the weaknesses of the two
                  approaches by applying the doubly robust technique to the
                  problems of policy evaluation and optimization. We prove that
                  this approach yields accurate value estimates when we have
                  either a good (but not necessarily consistent) model of
                  rewards or a good (but not necessarily consistent) model of
                  past policy. Extensive empirical comparison demonstrates that
                  the doubly robust approach uniformly improves over existing
                  techniques, achieving both lower variance in value estimation
                  and better policies. As such, we expect the doubly robust
                  approach to become common practice.},
  booktitle =    {Proceedings of the 28th International Conference on
                  International Conference on Machine Learning},
  pages =        {1097-1104},
  numpages =     {8},
  location =     {Bellevue, Washington, USA},
  series =       {ICML'11}
}

@inproceedings{joachims-2017-unbiased-learn-to-rank,
  author =       {Joachims, Thorsten and Swaminathan, Adith and Schnabel,
                  Tobias},
  title =        {Unbiased Learning-to-Rank with Biased Feedback},
  year =         {2017},
  isbn =         {9781450346757},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi.org/10.1145/3018661.3018699},
  doi =          {10.1145/3018661.3018699},
  abstract =     {Implicit feedback (e.g., clicks, dwell times, etc.) is an
                  abundant source of data in human-interactive systems. While
                  implicit feedback has many advantages (e.g., it is inexpensive
                  to collect, user centric, and timely), its inherent biases are
                  a key obstacle to its effective use. For example, position
                  bias in search rankings strongly influences how many clicks a
                  result receives, so that directly using click data as a
                  training signal in Learning-to-Rank (LTR) methods yields
                  sub-optimal results. To overcome this bias problem, we present
                  a counterfactual inference framework that provides the
                  theoretical basis for unbiased LTR via Empirical Risk
                  Minimization despite biased data. Using this framework, we
                  derive a Propensity-Weighted Ranking SVM for discriminative
                  learning from implicit feedback, where click models take the
                  role of the propensity estimator. In contrast to most
                  conventional approaches to de-biasing the data using click
                  models, this allows training of ranking functions even in
                  settings where queries do not repeat. Beyond the theoretical
                  support, we show empirically that the proposed learning method
                  is highly effective in dealing with biases, that it is robust
                  to noise and propensity model misspecification, and that it
                  scales efficiently. We also demonstrate the real-world
                  applicability of our approach on an operational search engine,
                  where it substantially improves retrieval performance.},
  booktitle =    {Proceedings of the Tenth ACM International Conference on Web
                  Search and Data Mining},
  pages =        {781–789},
  numpages =     {9},
  keywords =     {ranking svm, click models, learning to rank, propensity
                  weighting, implicit feedback},
  location =     {Cambridge, United Kingdom},
  series =       {WSDM '17}
}

@inproceedings{bonner-2018-causal-embed,
author = {Bonner, Stephen and Vasile, Flavian},
title = {Causal Embeddings for Recommendation},
year = {2018},
isbn = {9781450359016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240323.3240360},
doi = {10.1145/3240323.3240360},
abstract = {Many current applications use recommendations in order to modify the natural user behavior, such as to increase the number of sales or the time spent on a website. This results in a gap between the final recommendation objective and the classical setup where recommendation candidates are evaluated by their coherence with past user behavior, by predicting either the missing entries in the user-item matrix, or the most likely next event. To bridge this gap, we optimize a recommendation policy for the task of increasing the desired outcome versus the organic user behavior. We show this is equivalent to learning to predict recommendation outcomes under a fully random recommendation policy. To this end, we propose a new domain adaptation algorithm that learns from logged data containing outcomes from a biased recommendation policy and predicts recommendation outcomes according to random exposure. We compare our method against state-of-the-art factorization methods, in addition to new approaches of causal recommendation and show significant improvements.},
booktitle = {Proceedings of the 12th ACM Conference on Recommender Systems},
pages = {104–112},
numpages = {9},
keywords = {causality, counterfactual inference, embeddings, neural networks, recommender systems},
location = {Vancouver, British Columbia, Canada},
series = {RecSys '18}
}

@article{swaminathan-2015-batch-learn,
  author  = {Adith Swaminathan and Thorsten Joachims},
  title   = {Batch Learning from Logged Bandit Feedback through Counterfactual Risk Minimization},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
  volume  = {16},
  number  = {52},
  pages   = {1731-1755},
  url     = {http://jmlr.org/papers/v16/swaminathan15a.html}
}

@inproceedings{yang-2018-unbias-offline,
author = {Yang, Longqi and Cui, Yin and Xuan, Yuan and Wang, Chenyang and Belongie, Serge and Estrin, Deborah},
title = {Unbiased Offline Recommender Evaluation for Missing-Not-at-Random Implicit Feedback},
year = {2018},
isbn = {9781450359016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240323.3240355},
doi = {10.1145/3240323.3240355},
abstract = {Implicit-feedback Recommenders (ImplicitRec) leverage positive only user-item interactions, such as clicks, to learn personalized user preferences. Recommenders are often evaluated and compared offline using datasets collected from online platforms. These platforms are subject to popularity bias (i.e., popular items are more likely to be presented and interacted with), and therefore logged ground truth data are Missing-Not-At-Random (MNAR). As a result, the widely used Average-Over-All (AOA) evaluator is biased toward accurately recommending trendy items. In this paper, we (a) investigate evaluation bias of AOA and (b) develop an unbiased and practical offline evaluator for implicit MNAR datasets using the Inverse-Propensity-Scoring (IPS) technique. Through extensive experiments using four real-world datasets and four widely used algorithms, we show that (a) popularity bias is widely manifested in item presentation and interaction; (b) evaluation bias due to MNAR data pervasively exists in most cases where AOA is used to evaluate ImplicitRec; and (c) the unbiased estimator significantly reduces the AOA evaluation bias by more than 30% in the Yahoo! music dataset in terms of the Mean Absolute Error (MAE).},
booktitle = {Proceedings of the 12th ACM Conference on Recommender Systems},
pages = {279–287},
numpages = {9},
keywords = {bias, evaluation, implicit feedback, recommendation, propensity},
location = {Vancouver, British Columbia, Canada},
series = {RecSys '18}
}

@inproceedings{joachims-2018-deep-learn,
  author    = {Thorsten Joachims and
               Adith Swaminathan and
               Maarten de Rijke},
  title     = {Deep Learning with Logged Bandit Feedback},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=SJaP\_-xAb},
  timestamp = {Thu, 25 Jul 2019 14:25:54 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/JoachimsSR18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{wang-2018-decon-recom,
  author =       {Wang, Yixin and Liang, Dawen and Charlin, Laurent and Blei,
                  David M.},
  title =        {The Deconfounded Recommender: a Causal Inference Approach To
                  Recommendation},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1808.06581v2},
  abstract =     {The goal of recommendation is to show users items that they
                  will like. Though usually framed as a prediction, the spirit
                  of recommendation is to answer an interventional
                  question---for each user and movie, what would the rating be
                  if we "forced" the user to watch the movie? To this end, we
                  develop a causal approach to recommendation, one where
                  watching a movie is a "treatment" and a user's rating is an
                  "outcome." The problem is there may be unobserved confounders,
                  variables that affect both which movies the users watch and
                  how they rate them; unobserved confounders impede causal
                  predictions with observational data. To solve this problem, we
                  develop the deconfounded recommender, a way to use classical
                  recommendation models for causal recommendation. Following
                  Wang \& Blei [23], the deconfounded recommender involves two
                  probabilistic models. The first models which movies the users
                  watch; it provides a substitute for the unobserved
                  confounders. The second one models how each user rates each
                  movie; it employs the substitute to help account for
                  confounders. This two-stage approach removes bias due to
                  confounding. It improves recommendation and enjoys stable
                  performance against interventions on test sets.},
  archivePrefix ={arXiv},
  eprint =       {1808.06581},
  primaryClass = {cs.IR},
}

@article{greensmith-2004-var-reduct,
  author =       {Greensmith, Evan and Bartlett, Peter L. and Baxter, Jonathan},
  title =        {Variance Reduction Techniques for Gradient Estimates in
                  Reinforcement Learning},
  year =         {2004},
  issue_date =   {12/1/2004},
  publisher =    {JMLR.org},
  volume =       {5},
  issn =         {1532-4435},
  abstract =     {Policy gradient methods for reinforcement learning avoid some
                  of the undesirable properties of the value function
                  approaches, such as policy degradation (Baxter and Bartlett,
                  2001). However, the variance of the performance gradient
                  estimates obtained from the simulation is sometimes excessive.
                  In this paper, we consider variance reduction methods that
                  were developed for Monte Carlo estimates of integrals. We
                  study two commonly used policy gradient techniques, the
                  baseline and actor-critic methods, from this perspective. Both
                  can be interpreted as additive control variate variance
                  reduction methods. We consider the expected average reward
                  performance measure, and we focus on the GPOMDP algorithm for
                  estimating performance gradients in partially observable
                  Markov decision processes controlled by stochastic reactive
                  policies. We give bounds for the estimation error of the
                  gradient estimates for both baseline and actor-critic
                  algorithms, in terms of the sample size and mixing properties
                  of the controlled system. For the baseline technique, we
                  compute the optimal baseline, and show that the popular
                  approach of using the average reward to define the baseline
                  can be suboptimal. For actor-critic algorithms, we show that
                  using the true value function as the critic can be suboptimal.
                  We also discuss algorithms for estimating the optimal baseline
                  and approximate value function.},
  journal =      {J. Mach. Learn. Res.},
  month =        dec,
  pages =        {1471-1530},
  numpages =     {60}
}

@inproceedings{dacrema-2020-method-issues,
  title     = {Methodological Issues in Recommender Systems Research (Extended Abstract)},
  author    = {Ferrari Dacrema, Maurizio and Cremonesi, Paolo and Jannach, Dietmar},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  editor    = {Christian Bessiere},	
  pages     = {4706--4710},
  year      = {2020},
  month     = {7},
  note      = {Sister Conferences Best Papers},
  doi       = {10.24963/ijcai.2020/650},
  url       = {https://doi.org/10.24963/ijcai.2020/650},
}

@inproceedings{mcinerney-2018-explore-exploit,
  author =       {McInerney, James and Lacker, Benjamin and Hansen, Samantha and
                  Higley, Karl and Bouchard, Hugues and Gruson, Alois and
                  Mehrotra, Rishabh},
  title =        {Explore, Exploit, and Explain: Personalizing Explainable
                  Recommendations with Bandits},
  year =         {2018},
  isbn =         {9781450359016},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi.org/10.1145/3240323.3240354},
  doi =          {10.1145/3240323.3240354},
  abstract =     {The multi-armed bandit is an important framework for balancing
                  exploration with exploitation in recommendation. Exploitation
                  recommends content (e.g., products, movies, music playlists)
                  with the highest predicted user engagement and has
                  traditionally been the focus of recommender systems.
                  Exploration recommends content with uncertain predicted user
                  engagement for the purpose of gathering more information. The
                  importance of exploration has been recognized in recent years,
                  particularly in settings with new users, new items,
                  non-stationary preferences and attributes. In parallel,
                  explaining recommendations ("recsplanations") is crucial if
                  users are to understand their recommendations. Existing work
                  has looked at bandits and explanations independently. We
                  provide the first method that combines both in a principled
                  manner. In particular, our method is able to jointly (1) learn
                  which explanations each user responds to; (2) learn the best
                  content to recommend for each user; and (3) balance
                  exploration with exploitation to deal with uncertainty.
                  Experiments with historical log data and tests with live
                  production traffic in a large-scale music recommendation
                  service show a significant improvement in user engagement.},
  booktitle =    {Proceedings of the 12th ACM Conference on Recommender Systems},
  pages =        {31–39},
  numpages =     {9},
  location =     {Vancouver, British Columbia, Canada},
  series =       {RecSys '18}
}

@article{li-2014-learn-to,
  author =       {Hang Li},
  title =        {Learning To Rank for Information Retrieval and Natural
                  Language Processing, Second Edition},
  journal =      {Synthesis Lectures on Human Language Technologies},
  volume =       7,
  number =       3,
  pages =        {1-121},
  year =         2014,
  doi =          {10.2200/s00607ed2v01y201410hlt026},
  url =          {https://doi.org/10.2200/s00607ed2v01y201410hlt026},
  DATE_ADDED =   {Fri Sep 18 07:18:23 2020},
}

@article{xu-2020-dl-for-match,
url = {http://dx.doi.org/10.1561/1500000076},
year = {2020},
volume = {14},
journal = {Foundations and Trends® in Information Retrieval},
title = {Deep Learning for Matching in Search and Recommendation},
doi = {10.1561/1500000076},
issn = {1554-0669},
number = {2-3},
pages = {102-288},
author = {Jun Xu and Xiangnan He and Hang Li}
}

@article{glowacka-2019-bandit-alg-IR,
url = {http://dx.doi.org/10.1561/1500000067},
year = {2019},
volume = {13},
journal = {Foundations and Trends® in Information Retrieval},
title = {Bandit Algorithms in Information Retrieval},
doi = {10.1561/1500000067},
issn = {1554-0669},
number = {4},
pages = {299-424},
author = {Dorota Glowacka}
}

@article{russo-2018-tutor-thomp-sampl,
  author =       {Daniel J. Russo and Benjamin Van Roy and Abbas Kazerouni and
                  Ian Osband and Zheng Wen},
  title =        {A Tutorial on Thompson Sampling},
  journal =      {Foundations and Trends® in Machine Learning},
  volume =       11,
  number =       1,
  pages =        {1-96},
  year =         2018,
  doi =          {10.1561/2200000070},
  url =          {https://doi.org/10.1561/2200000070},
  DATE_ADDED =   {Fri Sep 18 11:28:03 2020},
}

@InProceedings{hung-2013-evaluat-aggreg,
  author =       "Quoc Viet Hung, Nguyen and Tam, Nguyen Thanh and Tran, Lam
                  Ngoc and Aberer, Karl",
  editor =       "Lin, Xuemin and Manolopoulos, Yannis and Srivastava, Divesh
                  and Huang, Guangyan",
  title =        "An Evaluation of Aggregation Techniques in Crowdsourcing",
  booktitle =    "Web Information Systems Engineering -- WISE 2013",
  year =         "2013",
  publisher =    "Springer Berlin Heidelberg",
  address =      "Berlin, Heidelberg",
  pages =        "1--15",
  abstract =     "As the volumes of AI problems involving, human knowledge are
                  likely to soar, crowdsourcing has become essential in a wide
                  range of world-wide-web applications. One of the biggest
                  challenges of crowdsourcing is aggregating the answers
                  collected from the crowd since the workers might have
                  wide-ranging levels of expertise. In order to tackle this
                  challenge, many aggregation techniques have been proposed.
                  These techniques, however, have never been compared and
                  analyzed under the same setting, rendering a `right' choice
                  for a particular application very difficult. Addressing this
                  problem, this paper presents a benchmark that offers a
                  comprehensive empirical study on the performance comparison of
                  the aggregation techniques. Specifically, we integrated
                  several state-of-the-art methods in a comparable manner, and
                  measured various performance metrics with our benchmark,
                  including computation time, accuracy, robustness to spammers,
                  and adaptivity to multi-labeling. We then provide in-depth
                  analysis of benchmarking results, obtained by simulating the
                  crowdsourcing process with different types of workers. We
                  believe that the findings from the benchmark will be able to
                  serve as a practical guideline for crowdsourcing
                  applications.",
  isbn =         "978-3-642-41154-0"
}

@inproceedings{nguyen-2013-batc-bench,
  author =       {Nguyen, Quoc Viet Hung and Nguyen, Thanh Tam and Lam, Ngoc
                  Tran and Aberer, Karl},
  title =        {BATC: A Benchmark for Aggregation Techniques in Crowdsourcing},
  year =         {2013},
  isbn =         {9781450320344},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi-org.proxy.library.nyu.edu/10.1145/2484028.2484199},
  doi =          {10.1145/2484028.2484199},
  abstract =     {As the volumes of AI problems involving human knowledge are
                  likely to soar, crowdsourcing has become essential in a wide
                  range of world-wide-web applications. One of the biggest
                  challenges of crowdsourcing is aggregating the answers
                  collected from crowd workers; and thus, many aggregate
                  techniques have been proposed. However, given a new
                  application, it is difficult for users to choose the
                  best-suited technique as well as appropriate parameter values
                  since each of these techniques has distinct performance
                  characteristics depending on various factors (e.g. worker
                  expertise, question difficulty). In this paper, we develop a
                  benchmarking tool that allows to (i) simulate the crowd and
                  (ii) evaluate aggregate techniques in different aspects
                  (accuracy, sensitivity to spammers, etc.). We believe that
                  this tool will be able to serve as a practical guideline for
                  both researchers and software developers. While researchers
                  can use our tool to assess existing or new techniques,
                  developers can reuse its components to reduce the development
                  complexity.},
  booktitle =    {Proceedings of the 36th International ACM SIGIR Conference on
                  Research and Development in Information Retrieval},
  pages =        {1079–1080},
  numpages =     {2},
  keywords =     {benchmark, aggregate technique, crowdsourcing},
  location =     {Dublin, Ireland},
  series =       {SIGIR '13}
}

@article{khetan-2017-learn-from,
  author =       {Khetan, Ashish and Lipton, Zachary C. and Anandkumar, Anima},
  title =        {Learning From Noisy Singly-Labeled Data},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1712.04577v2},
  abstract =     {Supervised learning depends on annotated examples, which are
                  taken to be the \emph{ground truth}. But these labels often
                  come from noisy crowdsourcing platforms, like Amazon
                  Mechanical Turk. Practitioners typically collect multiple
                  labels per example and aggregate the results to mitigate noise
                  (the classic crowdsourcing problem). Given a fixed annotation
                  budget and unlimited unlabeled data, redundant annotation
                  comes at the expense of fewer labeled examples. This raises
                  two fundamental questions: (1) How can we best learn from
                  noisy workers? (2) How should we allocate our labeling budget
                  to maximize the performance of a classifier? We propose a new
                  algorithm for jointly modeling labels and worker quality from
                  noisy crowd-sourced data. The alternating minimization
                  proceeds in rounds, estimating worker quality from
                  disagreement with the current model and then updating the
                  model by optimizing a loss function that accounts for the
                  current estimate of worker quality. Unlike previous
                  approaches, even with only one annotation per example, our
                  algorithm can estimate worker quality. We establish a
                  generalization error bound for models learned with our
                  algorithm and establish theoretically that it's better to
                  label many examples once (vs less multiply) when worker
                  quality is above a threshold. Experiments conducted on both
                  ImageNet (with simulated noisy workers) and MS-COCO (using the
                  real crowdsourced labels) confirm our algorithm's benefits.},
  archivePrefix ={arXiv},
  eprint =       {1712.04577},
  primaryClass = {cs.LG},
}

@article{zhou-2015-regul-minim,
  author =       {Zhou, Dengyong and Liu, Qiang and Platt, John C. and Meek,
                  Christopher and Shah, Nihar B.},
  title =        {Regularized Minimax Conditional Entropy for Crowdsourcing},
  journal =      {CoRR},
  year =         2015,
  url =          {http://arxiv.org/abs/1503.07240v1},
  abstract =     {There is a rapidly increasing interest in crowdsourcing for
                  data labeling. By crowdsourcing, a large number of labels can
                  be often quickly gathered at low cost. However, the labels
                  provided by the crowdsourcing workers are usually not of high
                  quality. In this paper, we propose a minimax conditional
                  entropy principle to infer ground truth from noisy
                  crowdsourced labels. Under this principle, we derive a unique
                  probabilistic labeling model jointly parameterized by worker
                  ability and item difficulty. We also propose an objective
                  measurement principle, and show that our method is the only
                  method which satisfies this objective measurement principle.
                  We validate our method through a variety of real crowdsourcing
                  datasets with binary, multiclass or ordinal labels.},
  archivePrefix ={arXiv},
  eprint =       {1503.07240},
  primaryClass = {cs.LG},
}
                  
@inproceedings{niculescu-mizil-2005-predic,
  author =       {Alexandru Niculescu-Mizil and Rich Caruana},
  title =        {Predicting good probabilities with supervised learning},
  booktitle =    {Proceedings of the 22nd international conference on Machine
                  learning - ICML '05},
  year =         2005,
  pages =        {nil},
  doi =          {10.1145/1102351.1102430},
  url =          {https://doi.org/10.1145/1102351.1102430},
  DATE_ADDED =   {Tue Oct 13 06:40:28 2020},
  month =        {-},
}

@conference {naeini-2015-obtaining,
	title = {Obtaining Well Calibrated Probabilities Using Bayesian Binning.},
	booktitle = {AAAI},
	year = {2015},
	pages = {2901{\textendash}2907},
	author = {Mahdi Pakdaman Naeini and Cooper, Gregory F and Hauskrecht, Milos}
}

@article{naeini-2014-binar-class-calib,
  author =       {Naeini, Mahdi Pakdaman and Cooper, Gregory F. and Hauskrecht,
                  Milos},
  title =        {Binary Classifier Calibration: Non-Parametric Approach},
  journal =      {CoRR},
  year =         2014,
  url =          {http://arxiv.org/abs/1401.3390v1},
  abstract =     {Accurate calibration of probabilistic predictive models
                  learned is critical for many practical prediction and
                  decision-making tasks. There are two main categories of
                  methods for building calibrated classifiers. One approach is
                  to develop methods for learning probabilistic models that are
                  well-calibrated, ab initio. The other approach is to use some
                  post-processing methods for transforming the output of a
                  classifier to be well calibrated, as for example histogram
                  binning, Platt scaling, and isotonic regression. One advantage
                  of the post-processing approach is that it can be applied to
                  any existing probabilistic classification model that was
                  constructed using any machine-learning method. In this paper,
                  we first introduce two measures for evaluating how well a
                  classifier is calibrated. We prove three theorems showing that
                  using a simple histogram binning post-processing method, it is
                  possible to make a classifier be well calibrated while
                  retaining its discrimination capability. Also, by casting the
                  histogram binning method as a density-based non-parametric
                  binary classifier, we can extend it using two simple
                  non-parametric density estimation methods. We demonstrate the
                  performance of the proposed calibration methods on synthetic
                  and real datasets. Experimental results show that the proposed
                  methods either outperform or are comparable to existing
                  calibration methods.},
  archivePrefix ={arXiv},
  eprint =       {1401.3390},
  primaryClass = {stat.ML},
}
                  


@ARTICLE{huang-2020-exper-invest-calib,
  author={L. {Huang} and J. {Zhao} and B. {Zhu} and H. {Chen} and S. V. {Broucke}},
  journal={IEEE Access}, 
  title={An Experimental Investigation of Calibration Techniques for Imbalanced Data}, 
  year={2020},
  volume={8},
  number={},
  pages={127343-127352},}

@inproceedings{zadrozny-2001-obtain-calib-prob,
author = {Zadrozny, Bianca and Elkan, Charles},
title = {Obtaining Calibrated Probability Estimates from Decision Trees and Naive Bayesian Classifiers},
year = {2001},
isbn = {1558607781},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Eighteenth International Conference on Machine Learning},
pages = {609–616},
numpages = {8},
series = {ICML '01}
}

@inproceedings{guo-2017-calb-moder-neur,
  author =       {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger,
                  Kilian Q.},
  title =        {On Calibration of Modern Neural Networks},
  year =         {2017},
  publisher =    {JMLR.org},
  abstract =     {Confidence calibration - the problem of predicting probability
                  estimates representative of the true correctness likelihood -
                  is important for classification models in many applications.
                  We discover that modern neural networks, unlike those from a
                  decade ago, are poorly calibrated. Through extensive
                  experiments, we observe that depth, width, weight decay, and
                  Batch Normalization are important factors influencing
                  calibration. We evaluate the performance of various
                  post-processing calibration methods on state-of-the-art
                  architectures with image and document classification datasets.
                  Our analysis and experiments not only offer insights into
                  neural network learning, but also provide a simple and
                  straightforward recipe for practical settings: on most
                  datasets, temperature scaling - a single-parameter variant of
                  Platt Scaling - is surprisingly effective at calibrating
                  predictions.},
  booktitle =    {Proceedings of the 34th International Conference on Machine
                  Learning - Volume 70},
  pages =        {1321-1330},
  numpages =     {10},
  location =     {Sydney, NSW, Australia},
  series =       {ICML'17}
}

@INPROCEEDINGS{platt-1999-prob-output,
  author =       {John C. Platt},
  title =        {Probabilistic Outputs for Support Vector Machines and
                  Comparisons to Regularized Likelihood Methods},
  booktitle =    {ADVANCES IN LARGE MARGIN CLASSIFIERS},
  year =         {1999},
  pages =        {61--74},
  publisher =    {MIT Press}
}

@inproceedings{gal-2016-dropout-bayes-approx,
  author =       {Gal, Yarin and Ghahramani, Zoubin},
  title =        {Dropout as a Bayesian Approximation: Representing Model
                  Uncertainty in Deep Learning},
  year =         {2016},
  publisher =    {JMLR.org},
  abstract =     {Deep learning tools have gained tremendous attention in
                  applied machine learning. However such tools for regression
                  and classification do not capture model uncertainty. In
                  comparison, Bayesian models offer a mathematically grounded
                  framework to reason about model uncertainty, but usually come
                  with a prohibitive computational cost. In this paper we
                  develop a new theoretical framework casting dropout training
                  in deep neural networks (NNs) as approximate Bayesian
                  inference in deep Gaussian processes. A direct result of this
                  theory gives us tools to model uncertainty with dropout NNs -
                  extracting information from existing models that has been
                  thrown away so far. This mitigates the problem of representing
                  uncertainty in deep learning without sacrificing either
                  computational complexity or test accuracy. We perform an
                  extensive study of the properties of dropout's uncertainty.
                  Various network architectures and nonlinearities are assessed
                  on tasks of regression and classification, using MNIST as an
                  example. We show a considerable improvement in predictive
                  log-likelihood and RMSE compared to existing state-of-the-art
                  methods, and finish by using dropout's uncertainty in deep
                  reinforcement learning.},
  booktitle =    {Proceedings of the 33rd International Conference on
                  International Conference on Machine Learning - Volume 48},
  pages =        {1050–1059},
  numpages =     {10},
  location =     {New York, NY, USA},
  series =       {ICML'16}
}

@inproceedings{coleman-2020-select-via-proxy,
  author =       {C. Coleman and C. Yeh and S. Mussmann and B. Mirzasoleiman and
                  P. Bailis and P. Liang and J. Leskovec and M. Zaharia},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  title =        {Selection via Proxy: Efficient Data Selection for Deep
                  Learning},
  year =         {2020},
}

@inproceedings{kumar-2019-verif-uncert-calib,
  author = {A. Kumar and P. Liang and T. Ma},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  title = {Verified Uncertainty Calibration},
  year = {2019},
}

@incollection{kull-2019-beyond-temp-scaling,
  title =        {Beyond temperature scaling: Obtaining well-calibrated
                  multi-class probabilities with Dirichlet calibration},
  author =       {Kull, Meelis and Perello Nieto, Miquel and K\"{a}ngsepp,
                  Markus and Silva Filho, Telmo and Song, Hao and Flach, Peter},
  booktitle =    {Advances in Neural Information Processing Systems 32},
  editor =       {H. Wallach and H. Larochelle and A. Beygelzimer and F.
                  d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages =        {12316--12326},
  year =         {2019},
  publisher =    {Curran Associates, Inc.},
  url =
                  {http://papers.nips.cc/paper/9397-beyond-temperature-scaling-obtaining-well-calibrated-multi-class-probabilities-with-dirichlet-calibration.pdf}
}

@article{gneiting-2014-probab-forec,
  author =       {Tilmann Gneiting and Matthias Katzfuss},
  title =        {Probabilistic Forecasting},
  journal =      {Annual Review of Statistics and Its Application},
  volume =       1,
  number =       1,
  pages =        {125-151},
  year =         2014,
  doi =          {10.1146/annurev-statistics-062713-085831},
  url =          {https://doi.org/10.1146/annurev-statistics-062713-085831},
  DATE_ADDED =   {Wed Sep 23 08:49:32 2020},
}

@article{gneiting-2007-stric-proper,
  author =       {Tilmann Gneiting and Adrian E Raftery},
  title =        {Strictly Proper Scoring Rules, Prediction, and Estimation},
  journal =      {Journal of the American Statistical Association},
  volume =       102,
  number =       477,
  pages =        {359-378},
  year =         2007,
  doi =          {10.1198/016214506000001437},
  url =          {https://doi.org/10.1198/016214506000001437},
  DATE_ADDED =   {Wed Sep 23 08:57:05 2020},
}

@article{gneiting-2007-probab-forec,
  author =       {Tilmann Gneiting and Fadoua Balabdaoui and Adrian E. Raftery},
  title =        {Probabilistic Forecasts, Calibration and Sharpness},
  journal =      {Journal of the Royal Statistical Society: Series B
                  (Statistical Methodology)},
  volume =       69,
  number =       2,
  pages =        {243-268},
  year =         2007,
  doi =          {10.1111/j.1467-9868.2007.00587.x},
  url =          {https://doi.org/10.1111/j.1467-9868.2007.00587.x},
  DATE_ADDED =   {Wed Sep 23 09:04:01 2020},
}

 @book{sutton-2018-reinf-learn-2ed,
  author =       {Sutton, Richard S. and Barto, Andrew G.},
  title =        {Reinforcement Learning: An Introduction},
  year =         2018,
  isbn =         0262039249,
  publisher =    {A Bradford Book},
  address =      {Cambridge, MA, USA},
  abstract =     {The significantly expanded and updated new edition of a widely
                  used text on reinforcement learning, one of the most active
                  research areas in artificial intelligence. Reinforcement
                  learning, one of the most active research areas in artificial
                  intelligence, is a computational approach to learning whereby
                  an agent tries to maximize the total amount of reward it
                  receives while interacting with a complex, uncertain
                  environment. In Reinforcement Learning, Richard Sutton and
                  Andrew Barto provide a clear and simple account of the field's
                  key ideas and algorithms. This second edition has been
                  significantly expanded and updated, presenting new topics and
                  updating coverage of other topics. Like the first edition,
                  this second edition focuses on core online learning
                  algorithms, with the more mathematical material set off in
                  shaded boxes. Part I covers as much of reinforcement learning
                  as possible without going beyond the tabular case for which
                  exact solutions can be found. Many algorithms presented in
                  this part are new to the second edition, including UCB,
                  Expected Sarsa, and Double Learning. Part II extends these
                  ideas to function approximation, with new sections on such
                  topics as artificial neural networks and the Fourier basis,
                  and offers expanded treatment of off-policy learning and
                  policy-gradient methods. Part III has new chapters on
                  reinforcement learning's relationships to psychology and
                  neuroscience, as well as an updated case-studies chapter
                  including AlphaGo and AlphaGo Zero, Atari game playing, and
                  IBM Watson's wagering strategy. The final chapter discusses
                  the future societal impacts of reinforcement learning.},
  url =          {http://incompleteideas.net/book/the-book.html}
}

@article{friedman-2001-greedy-func-appr,
  author =       "Friedman, Jerome H.",
  doi =          "10.1214/aos/1013203451",
  fjournal =     "Annals of Statistics",
  journal =      "Ann. Statist.",
  month =        "10",
  number =       "5",
  pages =        "1189--1232",
  publisher =    "The Institute of Mathematical Statistics",
  title =        "Greedy function approximation: A gradient boosting machine.",
  url =          "https://doi.org/10.1214/aos/1013203451",
  volume =       "29",
  year =         "2001"
}


@article{zhao-2019-causal-inter,
  author =       {Qingyuan Zhao and Trevor Hastie},
  title =        {Causal Interpretations of Black-Box Models},
  journal =      {Journal of Business \& Economic Statistics},
  volume =       {nil},
  number =       {nil},
  pages =        {1-10},
  year =         2019,
  doi =          {10.1080/07350015.2019.1624293},
  url =          {https://doi.org/10.1080/07350015.2019.1624293},
  DATE_ADDED =   {Wed Sep 23 11:07:09 2020},
}

@article{apley-2016-visual-effec,
  author =       {Apley, Daniel W. and Zhu, Jingyu},
  title =        {Visualizing the Effects of Predictor Variables in Black Box
                  Supervised Learning Models},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1612.08468v2},
  abstract =     {When fitting black box supervised learning models (e.g.,
                  complex trees, neural networks, boosted trees, random forests,
                  nearest neighbors, local kernel-weighted methods, etc.),
                  visualizing the main effects of the individual predictor
                  variables and their low-order interaction effects is often
                  important, and partial dependence (PD) plots are the most
                  popular approach for accomplishing this. However, PD plots
                  involve a serious pitfall if the predictor variables are far
                  from independent, which is quite common with large
                  observational data sets. Namely, PD plots require
                  extrapolation of the response at predictor values that are far
                  outside the multivariate envelope of the training data, which
                  can render the PD plots unreliable. Although marginal plots (M
                  plots) do not require such extrapolation, they produce
                  substantially biased and misleading results when the
                  predictors are dependent, analogous to the omitted variable
                  bias in regression. We present a new visualization approach
                  that we term accumulated local effects (ALE) plots, which
                  inherits the desirable characteristics of PD and M plots,
                  without inheriting their preceding shortcomings. Like M plots,
                  ALE plots do not require extrapolation; and like PD plots,
                  they are not biased by the omitted variable phenomenon.
                  Moreover, ALE plots are far less computationally expensive
                  than PD plots.},
  archivePrefix ={arXiv},
  eprint =       {1612.08468},
  primaryClass = {stat.ME},
}


@article{friedman-2008-predic-learn,
  author =       {Jerome H. Friedman and Bogdan E. Popescu},
  title =        {Predictive Learning Via Rule Ensembles},
  journal =      {The Annals of Applied Statistics},
  volume =       2,
  number =       3,
  pages =        {916-954},
  year =         2008,
  doi =          {10.1214/07-aoas148},
  url =          {https://doi.org/10.1214/07-aoas148},
  DATE_ADDED =   {Wed Sep 23 11:30:08 2020},
}

@inproceedings{hooker-2004-discov,
  author =       {Giles Hooker},
  title =        {Discovering additive structure in black box functions},
  booktitle =    {Proceedings of the 2004 ACM SIGKDD international conference on
                  Knowledge discovery and data mining - KDD '04},
  year =         2004,
  pages =        {nil},
  doi =          {10.1145/1014052.1014122},
  url =          {https://doi.org/10.1145/1014052.1014122},
  DATE_ADDED =   {Wed Sep 23 11:32:40 2020},
  month =        {-},
}

@article{greenwell-2018-simpl-effec,
  author =       {Greenwell, Brandon M. and Boehmke, Bradley C. and McCarthy,
                  Andrew J.},
  title =        {A Simple and Effective Model-Based Variable Importance
                  Measure},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1805.04755v1},
  abstract =     {In the era of "big data", it is becoming more of a challenge
                  to not only build state-of-the-art predictive models, but also
                  gain an understanding of what's really going on in the data.
                  For example, it is often of interest to know which, if any, of
                  the predictors in a fitted model are relatively influential on
                  the predicted outcome. Some modern algorithms---like random
                  forests and gradient boosted decision trees---have a natural
                  way of quantifying the importance or relative influence of
                  each feature. Other algorithms---like naive Bayes classifiers
                  and support vector machines---are not capable of doing so and
                  model-free approaches are generally used to measure each
                  predictor's importance. In this paper, we propose a
                  standardized, model-based approach to measuring predictor
                  importance across the growing spectrum of supervised learning
                  algorithms. Our proposed method is illustrated through both
                  simulated and real data examples. The R code to reproduce all
                  of the figures in this paper is available in the supplementary
                  materials.},
  archivePrefix ={arXiv},
  eprint =       {1805.04755},
  primaryClass = {stat.ML},
}


@article{breiman-2001-random-forest,
  author =       {Breiman, Leo},
  title =        {Random Forests},
  year =         {2001},
  issue_date =   {October 1 2001},
  publisher =    {Kluwer Academic Publishers},
  address =      {USA},
  volume =       {45},
  number =       {1},
  issn =         {0885-6125},
  url =          {https://doi.org/10.1023/A:1010933404324},
  doi =          {10.1023/A:1010933404324},
  abstract =     {Random forests are a combination of tree predictors such that
                  each tree depends on the values of a random vector sampled
                  independently and with the same distribution for all trees in
                  the forest. The generalization error for forests converges
                  a.s. to a limit as the number of trees in the forest becomes
                  large. The generalization error of a forest of tree
                  classifiers depends on the strength of the individual trees in
                  the forest and the correlation between them. Using a random
                  selection of features to split each node yields error rates
                  that compare favorably to Adaboost (Y. Freund &amp; R.
                  Schapire, Machine Learning: Proceedings of the Thirteenth
                  International conference, ***, 148–156), but are more robust
                  with respect to noise. Internal estimates monitor error,
                  strength, and correlation and these are used to show the
                  response to increasing the number of features used in the
                  splitting. Internal estimates are also used to measure
                  variable importance. These ideas are also applicable to
                  regression.},
  journal =      {Mach. Learn.},
  month =        oct,
  pages =        {5-32},
  numpages =     {28},
  keywords =     {classification, ensemble, regression}
}

@article{fisher-2019-all-models-wrong,
  author  = {Aaron Fisher and Cynthia Rudin and Francesca Dominici},
  title   = {All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {177},
  pages   = {1-81},
  url     = {http://jmlr.org/papers/v20/18-760.html}
}


@inproceedings{pawelczyk-2020-learn-model,
  author =       {Martin Pawelczyk and Klaus Broelemann and Gjergji Kasneci},
  title =        {Learning Model-Agnostic Counterfactual Explanations for
                  Tabular Data},
  booktitle =    {Proceedings of The Web Conference 2020},
  year =         2020,
  pages =        {nil},
  doi =          {10.1145/3366423.3380087},
  url =          {https://doi.org/10.1145/3366423.3380087},
  DATE_ADDED =   {Wed Sep 23 11:56:14 2020},
  month =        4,
}

@inproceedings{ribiero-2018-anchors,
  author =       {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  title =        {Anchors: High-Precision Model-Agnostic Explanations},
  booktitle =   {AAAI Conference on Artificial Intelligence},
  year =         {2018},
  keywords =     {machine learning;interpretability},
  abstract =     {We introduce a novel model-agnostic system that explains the
                  behavior of complex models with high-precision rules called
                  anchors, representing local, "sufficient" conditions for
                  predictions. We propose an algorithm to efficiently compute
                  these explanations for any black-box model with
                  high-probability guarantees. We demonstrate the flexibility of
                  anchors by explaining a myriad of different models for
                  different domains and tasks. In a user study, we show that
                  anchors enable users to predict how a model would behave on
                  unseen instances with less effort and higher precision, as
                  compared to existing linear explanations or no explanations.},
  url =
                  {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16982}
}
@article{fu-2020-fast-three-rious,
  author =       {Fu, Daniel Y. and Chen, Mayee F. and Sala, Frederic and
                  Hooper, Sarah M. and Fatahalian, Kayvon and R{\'e},
                  Christopher},
  title =        {Fast and Three-Rious: Speeding Up Weak Supervision With
                  Triplet Methods},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2002.11955v2},
  abstract =     {Weak supervision is a popular method for building machine
                  learning models without relying on ground truth annotations.
                  Instead, it generates probabilistic training labels by
                  estimating the accuracies of multiple noisy labeling sources
                  (e.g., heuristics, crowd workers). Existing approaches use
                  latent variable estimation to model the noisy sources, but
                  these methods can be computationally expensive, scaling
                  superlinearly in the data. In this work, we show that, for a
                  class of latent variable models highly applicable to weak
                  supervision, we can find a closed-form solution to model
                  parameters, obviating the need for iterative solutions like
                  stochastic gradient descent (SGD). We use this insight to
                  build FlyingSquid, a weak supervision framework that runs
                  orders of magnitude faster than previous weak supervision
                  approaches and requires fewer assumptions. In particular, we
                  prove bounds on generalization error without assuming that the
                  latent variable model can exactly parameterize the underlying
                  data distribution. Empirically, we validate FlyingSquid on
                  benchmark weak supervision datasets and find that it achieves
                  the same or higher quality compared to previous approaches
                  without the need to tune an SGD procedure, recovers model
                  parameters 170 times faster on average, and enables new video
                  analysis and online learning applications.},
  archivePrefix ={arXiv},
  eprint =       {2002.11955},
  primaryClass = {stat.ML},
}
@article{yang-2016-bench-compar,
  author =       {Yang, Yazhou and Loog, Marco},
  title =        {A Benchmark and Comparison of Active Learning for Logistic
                  Regression},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1611.08618v2},
  abstract =     {Logistic regression is by far the most widely used classifier
                  in real-world applications. In this paper, we benchmark the
                  state-of-the-art active learning methods for logistic
                  regression and discuss and illustrate their underlying
                  characteristics. Experiments are carried out on three
                  synthetic datasets and 44 real-world datasets, providing
                  insight into the behaviors of these active learning methods
                  with respect to the area of the learning curve (which plots
                  classification accuracy as a function of the number of queried
                  examples) and their computational costs. Surprisingly, one of
                  the earliest and simplest suggested active learning methods,
                  i.e., uncertainty sampling, performs exceptionally well
                  overall. Another remarkable finding is that random sampling,
                  which is the rudimentary baseline to improve upon, is not
                  overwhelmed by individual active learning techniques in many
                  cases.},
  archivePrefix ={arXiv},
  eprint =       {1611.08618},
  primaryClass = {stat.ML},
}
@article{awasthi-2020-learn-from,
  author =       {Awasthi, Abhijeet and Ghosh, Sabyasachi and Goyal, Rasna and
                  Sarawagi, Sunita},
  title =        {Learning From Rules Generalizing Labeled Exemplars},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2004.06025v2},
  abstract =     {In many applications labeled data is not readily available,
                  and needs to be collected via pain-staking human supervision.
                  We propose a rule-exemplar method for collecting human
                  supervision to combine the efficiency of rules with the
                  quality of instance labels. The supervision is coupled such
                  that it is both natural for humans and synergistic for
                  learning. We propose a training algorithm that jointly
                  denoises rules via latent coverage variables, and trains the
                  model through a soft implication loss over the coverage and
                  label variables. The denoised rules and trained model are used
                  jointly for inference. Empirical evaluation on five different
                  tasks shows that (1) our algorithm is more accurate than
                  several existing methods of learning from a mix of clean and
                  noisy supervision, and (2) the coupled rule-exemplar
                  supervision is effective in denoising rules.},
  archivePrefix ={arXiv},
  eprint =       {2004.06025},
  primaryClass = {cs.LG},
}

@article{dawid-1979-mle-observ-err,
 ISSN = {00359254, 14679876},
 URL = {http://www.jstor.org/stable/2346806},
 abstract = {In compiling a patient record many facets are subject to errors of measurement. A model is presented which allows individual error-rates to be estimated for polytomous facets even when the patient's "true" response is not available. The EM algorithm is shown to provide a slow but sure way of obtaining maximum likelihood estimates of the parameters of interest. Some preliminary experience is reported and the limitations of the method are described.},
 author = {A. P. Dawid and A. M. Skene},
 journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
 number = {1},
 pages = {20--28},
 publisher = {[Wiley, Royal Statistical Society]},
 title = {Maximum Likelihood Estimation of Observer Error-Rates Using the EM Algorithm},
 volume = {28},
 year = {1979}
}

@inproceedings{steck-2020-admm-slim,
  author =       {Steck, Harald and Dimakopoulou, Maria and Riabov, Nickolai and
                  Jebara, Tony},
  title =        {ADMM SLIM: Sparse Recommendations for Many Users},
  year =         {2020},
  isbn =         {9781450368223},
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi.org/10.1145/3336191.3371774},
  doi =          {10.1145/3336191.3371774},
  abstract =     {The Sparse Linear Method (SLIM) is a well-established approach
                  for top-N recommendations. This article proposes several
                  improvements that are enabled by the Alternating Directions
                  Method of Multipliers (ADMM), a well-known optimization method
                  with many application areas. First, we show that optimizing
                  the original SLIM-objective by ADMM results in an approach
                  where the training time is independent of the number of users
                  in the training data, and hence trivially scales to large
                  numbers of users. Second, the flexibility of ADMM allows us to
                  switch on and off the various constraints and regularization
                  terms in the original SLIM-objective, in order to empirically
                  assess their contributions to ranking accuracy on given data.
                  Third, we also propose two extensions to the original SLIM
                  training-objective in order to improve recommendation accuracy
                  further without increasing the computational cost. In our
                  experiments on three well-known data-sets, we first compare to
                  the original SLIM-implementation and find that not only ADMM
                  reduces training time considerably, but also achieves an
                  improvement in recommendation accuracy due to better
                  optimization. We then compare to various state-of-the-art
                  approaches and observe up to 25% improvement in recommendation
                  accuracy in our experiments. Finally, we evaluate the
                  importance of sparsity and the non-negativity constraint in
                  the original SLIM-objective with sub-sampling experiments that
                  simulate scenarios of cold-starting and large catalog sizes
                  compared to relatively small user base, which often occur in
                  practice.},
  booktitle =    {Proceedings of the 13th International Conference on Web Search
                  and Data Mining},
  pages =        {555–563},
  numpages =     {9},
  keywords =     {recommender systems, sparse linear model, personalization},
  location =     {Houston, TX, USA},
  series =       {WSDM '20}
}
@article{stirn-2018-thomp-sampl,
  author =       {Stirn, Andrew and Jebara, Tony},
  title =        {Thompson Sampling for Noncompliant Bandits},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1812.00856v1},
  abstract =     {Thompson sampling, a Bayesian method for balancing exploration
                  and exploitation in bandit problems, has theoretical
                  guarantees and exhibits strong empirical performance in many
                  domains. Traditional Thompson sampling, however, assumes
                  perfect compliance, where an agent's chosen action is treated
                  as the implemented action. This article introduces a
                  stochastic noncompliance model that relaxes this assumption.
                  We prove that any noncompliance in a 2-armed Bernoulli bandit
                  increases existing regret bounds. With our noncompliance
                  model, we derive Thompson sampling variants that explicitly
                  handle both observed and latent noncompliance. With extensive
                  empirical analysis, we demonstrate that our algorithms either
                  match or outperform traditional Thompson sampling in both
                  compliant and noncompliant environments.},
  archivePrefix ={arXiv},
  eprint =       {1812.00856},
  primaryClass = {cs.LG},
}
@article{paisley-2012-variat-bayes,
  author =       {Paisley, John and Blei, David and Jordan, Michael},
  title =        {Variational Bayesian Inference With Stochastic Search},
  journal =      {CoRR},
  year =         2012,
  url =          {http://arxiv.org/abs/1206.6430v1},
  abstract =     {Mean-field variational inference is a method for approximate
                  Bayesian posterior inference. It approximates a full posterior
                  distribution with a factorized set of distributions by
                  maximizing a lower bound on the marginal likelihood. This
                  requires the ability to integrate a sum of terms in the log
                  joint likelihood using this factorized distribution. Often not
                  all integrals are in closed form, which is typically handled
                  by using a lower bound. We present an alternative algorithm
                  based on stochastic optimization that allows for direct
                  optimization of the variational lower bound. This method uses
                  control variates to reduce the variance of the stochastic
                  search gradient, in which existing lower bounds can play an
                  important role. We demonstrate the approach on two
                  non-conjugate models: logistic regression and an approximation
                  to the HDP.},
  archivePrefix ={arXiv},
  eprint =       {1206.6430},
  primaryClass = {cs.LG},
}

@techreport{cho-2017-brief-intro-to-ml, 
   title={Brief Introduction to Machine Learning without Deep Learning}, 
   author={Kyunghyun Cho}, 
   year={2017}, 
   institution={New York University}, 
   note={Lecture Note for CSCI-UA.0473-001} 
}

@article{loecher-2020-unbias-var-imp,
  author =       {Markus Loecher},
  title =        {Unbiased variable importance for random forests},
  journal =      {Communications in Statistics - Theory and Methods},
  volume =       {0},
  number =       {0},
  pages =        {1-13},
  year =         {2020},
  publisher =    {Taylor & Francis},
  doi =          {10.1080/03610926.2020.1764042},
  URL =          { https://doi.org/10.1080/03610926.2020.1764042 },
  eprint =       { https://doi.org/10.1080/03610926.2020.1764042 }
}

@article{loecher-2020-unbias-variab,
  author =       {Loecher, Markus},
  title =        {Unbiased Variable Importance for Random Forests},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2003.02106v2},
  abstract =     {The default variable-importance measure in random Forests,
                  Gini importance, has been shown to suffer from the bias of the
                  underlying Gini-gain splitting criterion. While the
                  alternative permutation importance is generally accepted as a
                  reliable measure of variable importance, it is also
                  computationally demanding and suffers from other shortcomings.
                  We propose a simple solution to the misleading/untrustworthy
                  Gini importance which can be viewed as an overfitting problem:
                  we compute the loss reduction on the out-of-bag instead of the
                  in-bag training samples.},
  archivePrefix ={arXiv},
  eprint =       {2003.02106},
  primaryClass = {stat.ML},
}
@article{tjoa-2019-survey-explain,
  author =       {Tjoa, Erico and Guan, Cuntai},
  title =        {A Survey on Explainable Artificial Intelligence (XAI): Towards
                  Medical Xai},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1907.07374v5},
  abstract =     {Recently, artificial intelligence and machine learning in
                  general have demonstrated remarkable performances in many
                  tasks, from image processing to natural language processing,
                  especially with the advent of deep learning. Along with
                  research progress, they have encroached upon many different
                  fields and disciplines. Some of them require high level of
                  accountability and thus transparency, for example the medical
                  sector. Explanations for machine decisions and predictions are
                  thus needed to justify their reliability. This requires
                  greater interpretability, which often means we need to
                  understand the mechanism underlying the algorithms.
                  Unfortunately, the blackbox nature of the deep learning is
                  still unresolved, and many machine decisions are still poorly
                  understood. We provide a review on interpretabilities
                  suggested by different research works and categorize them. The
                  different categories show different dimensions in
                  interpretability research, from approaches that provide
                  "obviously" interpretable information to the studies of
                  complex patterns. By applying the same categorization to
                  interpretability in medical research, it is hoped that (1)
                  clinicians and practitioners can subsequently approach these
                  methods with caution, (2) insights into interpretability will
                  be born with more considerations for medical practices, and
                  (3) initiatives to push forward data-based, mathematically-
                  and technically-grounded medical education are encouraged.},
  archivePrefix ={arXiv},
  eprint =       {1907.07374},
  primaryClass = {cs.LG},
}
@article{nori-2019-inter,
  author =       {Nori, Harsha and Jenkins, Samuel and Koch, Paul and Caruana,
                  Rich},
  title =        {Interpretml: a Unified Framework for Machine Learning
                  Interpretability},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1909.09223v1},
  abstract =     {InterpretML is an open-source Python package which exposes
                  machine learning interpretability algorithms to practitioners
                  and researchers. InterpretML exposes two types of
                  interpretability - glassbox models, which are machine learning
                  models designed for interpretability (ex: linear models, rule
                  lists, generalized additive models), and blackbox
                  explainability techniques for explaining existing systems (ex:
                  Partial Dependence, LIME). The package enables practitioners
                  to easily compare interpretability algorithms by exposing
                  multiple methods under a unified API, and by having a
                  built-in, extensible visualization platform. InterpretML also
                  includes the first implementation of the Explainable Boosting
                  Machine, a powerful, interpretable, glassbox model that can be
                  as accurate as many blackbox models. The MIT licensed source
                  code can be downloaded from github.com/microsoft/interpret.},
  archivePrefix ={arXiv},
  eprint =       {1909.09223},
  primaryClass = {cs.LG},
}
@article{hall-2018-art-scien,
  author =       {Hall, Patrick},
  title =        {On the Art and Science of Machine Learning Explanations},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1810.02909v4},
  abstract =     {This text discusses several popular explanatory methods that
                  go beyond the error measurements and plots traditionally used
                  to assess machine learning models. Some of the explanatory
                  methods are accepted tools of the trade while others are
                  rigorously derived and backed by long-standing theory. The
                  methods, decision tree surrogate models, individual
                  conditional expectation (ICE) plots, local interpretable
                  model-agnostic explanations (LIME), partial dependence plots,
                  and Shapley explanations, vary in terms of scope, fidelity,
                  and suitable application domain. Along with descriptions of
                  these methods, this text presents real-world usage
                  recommendations supported by a use case and public, in-depth
                  software examples for reproducibility.},
  archivePrefix ={arXiv},
  eprint =       {1810.02909},
  primaryClass = {stat.ML},
}


@book{breiman-1984-cart,
  author =       {Leo Breiman and Jerome H. Friedman and Richard A. Olshen and
                  Charles J. Stone},
  title =        {Classification And Regression Trees},
  year =         1984,
  publisher =    {Taylor & Francis Group, LLC},
  url =          {https://doi.org/10.1201/9781315139470},
  DATE_ADDED =   {Fri Oct 2 05:52:26 2020},
  doi =          {10.1201/9781315139470},
}

@inproceedings{cestnik-87-assistant-86,
  author =       {Cestnik, Bojan and Kononenko, Igor and Bratko, Ivan},
  title =        {ASSISTANT 86: A Knowledge-Elicitation Tool for Sophisticated
                  Users},
  year =         1987,
  isbn =         {185058088X},
  publisher =    {Sigma Press},
  booktitle =    {Proceedings of the 2nd European Conference on European Working
                  Session on Learning},
  pages =        {31–45},
  numpages =     15,
  location =     {Bled, Yugoslavia},
  series =       {EWSL'87},
  note = {\url{https://www.researchgate.net/publication/221112466_ASSISTANT_86_A_Knowledge-Elicitation_Tool_for_Sophisticated_Users}}
                  
}

@article {laan-2006-stat-inf-var-imp,
  author =       "Mark J. van der Laan",
  title =        "Statistical Inference for Variable Importance",
  journal =      "The International Journal of Biostatistics",
  year =         "2006",
  publisher =    "De Gruyter",
  address =      "Berlin, Boston",
  volume =       "2",
  number =       "1",
  doi =          "https://doi.org/10.2202/1557-4679.1008",
  url =
                  "https://www.degruyter.com/view/journals/ijb/2/1/article-ijb.2006.2.1.1008.xml.xml"
}

@article{strobl-2007-bias-rand-forest,
  added-at =     {2010-07-07T17:27:19.000+0200},
  author =       {Strobl, Carolin and Boulesteix, Anne-Laure and Zeileis, Achim
                  and Hothorn, Torsten},
  biburl =
                  {https://www.bibsonomy.org/bibtex/2cfd31917206fc201d631f1258986ae76/pillo},
  interhash =    {310f5dd370f682632366dca682f053ad},
  intrahash =    {cfd31917206fc201d631f1258986ae76},
  journal =      {BMC Bioinformatics},
  keywords =     {imported},
  number =       25,
  owner =        {Bernd Panassiti},
  timestamp =    {2010-07-07T17:27:24.000+0200},
  title =        {Bias in Random Forest Variable Importance Measures:
                  Illustrations, Sources and a Solution},
  volume =       8,
  year =         2007
}

@InProceedings{strumbelj-2011-general-method,
  author =       "{\v{S}}trumbelj, Erik and Kononenko, Igor",
  editor =       "Dobnikar, Andrej and Lotri{\v{c}}, Uro{\v{s}} and {\v{S}}ter,
                  Branko",
  title =        "A General Method for Visualizing and Explaining Black-Box
                  Regression Models",
  booktitle =    "Adaptive and Natural Computing Algorithms",
  year =         "2011",
  publisher =    "Springer Berlin Heidelberg",
  address =      "Berlin, Heidelberg",
  pages =        "21--30",
  abstract =     "We propose a method for explaining regression models and their
                  predictions for individual instances. The method successfully
                  reveals how individual features influence the model and can be
                  used with any type of regression model in a uniform way. We
                  used different types of models and data sets to demonstrate
                  that the method is a useful tool for explaining, comparing,
                  and identifying errors in regression models.",
  isbn =         "978-3-642-20267-4"
}

@article{vidovic-2016-featur-impor,
  author =       {Vidovic, Marina M. -C. and G{\"o}rnitz, Nico and M{\"u}ller,
                  Klaus-Robert and Kloft, Marius},
  title =        {Feature Importance Measure for Non-Linear Learning Algorithms},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1611.07567v1},
  abstract =     {Complex problems may require sophisticated, non-linear
                  learning methods such as kernel machines or deep neural
                  networks to achieve state of the art prediction accuracies.
                  However, high prediction accuracies are not the only objective
                  to consider when solving problems using machine learning.
                  Instead, particular scientific applications require some
                  explanation of the learned prediction function. Unfortunately,
                  most methods do not come with out of the box straight forward
                  interpretation. Even linear prediction functions are not
                  straight forward to explain if features exhibit complex
                  correlation structure. In this paper, we propose the Measure
                  of Feature Importance (MFI). MFI is general and can be applied
                  to any arbitrary learning machine (including kernel machines
                  and deep learning). MFI is intrinsically non-linear and can
                  detect features that by itself are inconspicuous and only
                  impact the prediction function through their interaction with
                  other features. Lastly, MFI can be used for both ---
                  model-based feature importance and instance-based feature
                  importance (i.e, measuring the importance of a feature for a
                  particular data point).},
  archivePrefix ={arXiv},
  eprint =       {1611.07567},
  primaryClass = {cs.AI},
}
@article{zhou-2019-unbias-measur,
  author =       {Zhou, Zhengze and Hooker, Giles},
  title =        {Unbiased Measurement of Feature Importance in Tree-Based
                  Methods},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1903.05179v2},
  abstract =     {We propose a modification that corrects for split-improvement
                  variable importance measures in Random Forests and other
                  tree-based methods. These methods have been shown to be biased
                  towards increasing the importance of features with more
                  potential splits. We show that by appropriately incorporating
                  split-improvement as measured on out of sample data, this bias
                  can be corrected yielding better summaries and screening
                  tools.},
  archivePrefix ={arXiv},
  eprint =       {1903.05179},
  primaryClass = {stat.ML},
}

@article{hooker-2019-pleas-stop,
  author =       {Hooker, Giles and Mentch, Lucas},
  title =        {Please Stop Permuting Features: an Explanation and
                  Alternatives},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1905.03151v1},
  abstract =     {This paper advocates against permute-and-predict (PaP) methods
                  for interpreting black box functions. Methods such as the
                  variable importance measures proposed for random forests,
                  partial dependence plots, and individual conditional
                  expectation plots remain popular because of their ability to
                  provide model-agnostic measures that depend only on the
                  pre-trained model output. However, numerous studies have found
                  that these tools can produce diagnostics that are highly
                  misleading, particularly when there is strong dependence among
                  features. Rather than simply add to this growing literature by
                  further demonstrating such issues, here we seek to provide an
                  explanation for the observed behavior. In particular, we argue
                  that breaking dependencies between features in hold-out data
                  places undue emphasis on sparse regions of the feature space
                  by forcing the original model to extrapolate to regions where
                  there is little to no data. We explore these effects through
                  various settings where a ground-truth is understood and find
                  support for previous claims in the literature that PaP metrics
                  tend to over-emphasize correlated features both in variable
                  importance and partial dependence plots, even though applying
                  permutation methods to the ground-truth models do not. As an
                  alternative, we recommend more direct approaches that have
                  proven successful in other settings: explicitly removing
                  features, conditional permutations, or model distillation
                  methods.},
  archivePrefix ={arXiv},
  eprint =       {1905.03151},
  primaryClass = {stat.ME},
}
                  
@inproceedings{zhang-2019-axiom-inter,
  author =       {Zhang, Xuezhou and Tan, Sarah and Koch, Paul and Lou, Yin and
                  Chajewska, Urszula and Caruana, Rich},
  title =        {Axiomatic Interpretability for Multiclass Additive Models},
  year =         2019,
  isbn =         9781450362016,
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi-org.proxy.library.nyu.edu/10.1145/3292500.3330898},
  doi =          {10.1145/3292500.3330898},
  abstract =     {Generalized additive models (GAMs) are favored in many
                  regression and binary classification problems because they are
                  able to fit complex, nonlinear functions while still remaining
                  interpretable. In the first part of this paper, we generalize
                  a state-of-the-art GAM learning algorithm based on boosted
                  trees to the multiclass setting, showing that this multiclass
                  algorithm outperforms existing GAM learning algorithms and
                  sometimes matches the performance of full complexity models
                  such as gradient boosted trees. In the second part, we turn
                  our attention to the interpretability of GAMs in the
                  multiclass setting. Surprisingly, the natural interpretability
                  of GAMs breaks down when there are more than two classes.
                  Naive interpretation of multiclass GAMs can lead to false
                  conclusions. Inspired by binary GAMs, we identify two axioms
                  that any additive model must satisfy in order to not be
                  visually misleading. We then develop a technique called
                  Additive Post-Processing for Interpretability (API) that
                  provably transforms a pretrained additive model to satisfy the
                  interpretability axioms without sacrificing accuracy. The
                  technique works not just on models trained with our learning
                  algorithm, but on any multiclass additive model, including
                  multiclass linear and logistic regression. We demonstrate the
                  effectiveness of API on a 12-class infant mortality dataset.},
  booktitle =    {Proceedings of the 25th ACM SIGKDD International Conference on
                  Knowledge Discovery &amp; Data Mining},
  pages =        {226–234},
  numpages =     9,
  keywords =     {interpretable model, additive models, machine learning},
  location =     {Anchorage, AK, USA},
  series =       {KDD '19}
}

@article{zhang-2018-axiom-inter,
  author =       {Zhang, Xuezhou and Tan, Sarah and Koch, Paul and Lou, Yin and
                  Chajewska, Urszula and Caruana, Rich},
  title =        {Axiomatic Interpretability for Multiclass Additive Models},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1810.09092v2},
  abstract =     {Generalized additive models (GAMs) are favored in many
                  regression and binary classification problems because they are
                  able to fit complex, nonlinear functions while still remaining
                  interpretable. In the first part of this paper, we generalize
                  a state-of-the-art GAM learning algorithm based on boosted
                  trees to the multiclass setting, and show that this multiclass
                  algorithm outperforms existing GAM learning algorithms and
                  sometimes matches the performance of full complexity models
                  such as gradient boosted trees. In the second part, we turn
                  our attention to the interpretability of GAMs in the
                  multiclass setting. Surprisingly, the natural interpretability
                  of GAMs breaks down when there are more than two classes.
                  Naive interpretation of multiclass GAMs can lead to false
                  conclusions. Inspired by binary GAMs, we identify two axioms
                  that any additive model must satisfy in order to not be
                  visually misleading. We then develop a technique called
                  Additive Post-Processing for Interpretability (API), that
                  provably transforms a pre-trained additive model to satisfy
                  the interpretability axioms without sacrificing accuracy. The
                  technique works not just on models trained with our learning
                  algorithm, but on any multiclass additive model, including
                  multiclass linear and logistic regression. We demonstrate the
                  effectiveness of API on a 12-class infant mortality dataset.},
  archivePrefix ={arXiv},
  eprint =       {1810.09092},
  primaryClass = {cs.LG},
}

@inproceedings{sundararajan-2017-axiom-attrib,
  author =       {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  title =        {Axiomatic Attribution for Deep Networks},
  year =         {2017},
  publisher =    {JMLR.org},
  abstract =     {We study the problem of attributing the prediction of a deep
                  network to its input features, a problem previously studied by
                  several other works. We identify two fundamental axioms—
                  Sensitivity and Implementation Invariance that attribution
                  methods ought to satisfy. We show that they are not satisfied
                  by most known attribution methods, which we consider to be a
                  fundamental weakness of those methods. We use the axioms to
                  guide the design of a new attribution method called Integrated
                  Gradients. Our method requires no modification to the original
                  network and is extremely simple to implement; it just needs a
                  few calls to the standard gradient operator. We apply this
                  method to a couple of image models, a couple of text models
                  and a chemistry model, demonstrating its ability to debug
                  networks, to extract rules from a network, and to enable users
                  to engage with models better.},
  booktitle =    {Proceedings of the 34th International Conference on Machine
                  Learning - Volume 70},
  pages =        {3319–3328},
  numpages =     {10},
  location =     {Sydney, NSW, Australia},
  series =       {ICML'17}
}

@article{gregorutti-2015-group-variab,
  author =       {Baptiste Gregorutti and Bertrand Michel and Philippe
                  Saint-Pierre},
  title =        {Grouped Variable Importance With Random Forests and
                  Application To Multiple Functional Data Analysis},
  journal =      {Computational Statistics \& Data Analysis},
  volume =       90,
  number =       {nil},
  pages =        {15-35},
  year =         2015,
  doi =          {10.1016/j.csda.2015.04.002},
  url =          {https://doi.org/10.1016/j.csda.2015.04.002},
  DATE_ADDED =   {Sun Oct 4 15:33:13 2020},
}

@inproceedings{rendle-2020-neural-collab,
  author =       {Steffen Rendle and Walid Krichene and Li Zhang and John
                  Anderson},
  title =        {Neural Collaborative Filtering vs. Matrix Factorization
                  Revisited},
  booktitle =    {Fourteenth ACM Conference on Recommender Systems},
  year =         2020,
  pages =        {nil},
  doi =          {10.1145/3383313.3412488},
  url =          {https://doi.org/10.1145/3383313.3412488},
  DATE_ADDED =   {Mon Oct 5 11:03:45 2020},
  month =        9,
}

@book{molnar-2019-inter-machin-learn,
  title =        {Interpretable Machine Learning},
  author =       {Christoph Molnar},
  note =         {\url{https://christophm.github.io/interpretable-ml-book/}},
  year =         2019,
  subtitle =     {A Guide for Making Black Box Models Explainable},
  publisher =    {bookdown.org}
}

@article{tolosi-2011-class-correl,
    author = {Toloşi, Laura and Lengauer, Thomas},
    title = "{Classification with correlated features: unreliability of feature ranking and solutions}",
    journal = {Bioinformatics},
    volume = {27},
    number = {14},
    pages = {1986-1994},
    year = {2011},
    month = {05},
    abstract = "{Motivation: Classification and feature selection of genomics or transcriptomics data is often hampered by the large number of features as compared with the small number of samples available. Moreover, features represented by probes that either have similar molecular functions (gene expression analysis) or genomic locations (DNA copy number analysis) are highly correlated. Classical model selection methods such as penalized logistic regression or random forest become unstable in the presence of high feature correlations. Sophisticated penalties such as group Lasso or fused Lasso can force the models to assign similar weights to correlated features and thus improve model stability and interpretability. In this article, we show that the measures of feature relevance corresponding to the above-mentioned methods are biased such that the weights of the features belonging to groups of correlated features decrease as the sizes of the groups increase, which leads to incorrect model interpretation and misleading feature ranking.Results: With simulation experiments, we demonstrate that Lasso logistic regression, fused support vector machine, group Lasso and random forest models suffer from correlation bias. Using simulations, we show that two related methods for group selection based on feature clustering can be used for correcting the correlation bias. These techniques also improve the stability and the accuracy of the baseline models. We apply all methods investigated to a breast cancer and a bladder cancer arrayCGH dataset and in order to identify copy number aberrations predictive of tumor phenotype.Availability: R code can be found at: http://www.mpi-inf.mpg.de/~laura/Clustering.r.Contact:laura.tolosi@mpi-inf.mpg.deSupplementary information:Supplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btr300},
    url = {https://doi.org/10.1093/bioinformatics/btr300},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/27/14/1986/18530216/btr300.pdf},
}


@article{lei-2018-distr-free,
  author =       {Jing Lei and Max G'Sell and Alessandro Rinaldo and Ryan J.
                  Tibshirani and Larry Wasserman},
  title =        {Distribution-Free Predictive Inference for Regression},
  journal =      {Journal of the American Statistical Association},
  volume =       113,
  number =       523,
  pages =        {1094-1111},
  year =         2018,
  doi =          {10.1080/01621459.2017.1307116},
  url =          {https://doi.org/10.1080/01621459.2017.1307116},
  DATE_ADDED =   {Thu Oct 8 10:55:49 2020},
}

@inproceedings{lou-2013-accur,
  author =       {Yin Lou and Rich Caruana and Johannes Gehrke and Giles Hooker},
  title =        {Accurate intelligible models with pairwise interactions},
  booktitle =    {Proceedings of the 19th ACM SIGKDD international conference on
                  Knowledge discovery and data mining - KDD '13},
  year =         2013,
  pages =        {nil},
  doi =          {10.1145/2487575.2487579},
  url =          {https://doi.org/10.1145/2487575.2487579},
  DATE_ADDED =   {Thu Oct 8 11:08:13 2020},
  month =        {-},
}

@article{mentch-2016-quant-uncert,
  author  = {Lucas Mentch and Giles Hooker},
  title   = {Quantifying Uncertainty in Random Forests via Confidence Intervals and Hypothesis Tests},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {26},
  pages   = {1-41},
  url     = {http://jmlr.org/papers/v17/14-168.html}
}

@inproceedings{tan-2018-distil-compare,
  author =       {Sarah Tan and Rich Caruana and Giles Hooker and Yin Lou},
  editor =       {Jason Furman and Gary E. Marchant and Huw Price and Francesca
                  Rossi},
  title =        {Distill-and-Compare: Auditing Black-Box Models Using
                  Transparent Model Distillation},
  booktitle =    {Proceedings of the 2018 {AAAI/ACM} Conference on AI, Ethics,
                  and Society, {AIES} 2018, New Orleans, LA, USA, February
                  02-03, 2018},
  pages =        {303--310},
  publisher =    {{ACM}},
  year =         {2018},
  url =          {https://doi.org/10.1145/3278721.3278725},
  doi =          {10.1145/3278721.3278725},
  timestamp =    {Mon, 14 Jan 2019 09:04:03 +0100},
  biburl =       {https://dblp.org/rec/conf/aies/TanCHL18.bib},
  bibsource =    {dblp computer science bibliography, https://dblp.org}
}
@article{liu-2018-auto-encod,
  author =       {Liu, Ying and Zheng, Cheng},
  title =        {Auto-Encoding Knockoff Generator for Fdr Controlled Variable
                  Selection},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1809.10765v1},
  abstract =     {A new statistical procedure (Model-X \cite{candes2018}) has
                  provided a way to identify important factors using any
                  supervised learning method controlling for FDR. This line of
                  research has shown great potential to expand the horizon of
                  machine learning methods beyond the task of prediction, to
                  serve the broader needs in scientific researches for
                  interpretable findings. However, the lack of a practical and
                  flexible method to generate knockoffs remains the major
                  obstacle for wide application of Model-X procedure. This paper
                  fills in the gap by proposing a model-free knockoff generator
                  which approximates the correlation structure between features
                  through latent variable representation. We demonstrate our
                  proposed method can achieve FDR control and better power than
                  two existing methods in various simulated settings and a real
                  data example for finding mutations associated with drug
                  resistance in HIV-1 patients.},
  archivePrefix ={arXiv},
  eprint =       {1809.10765},
  primaryClass = {stat.ME},
}
@article{chang-2020-how-inter,
  author =       {Chang, Chun-Hao and Tan, Sarah and Lengerich, Ben and
                  Goldenberg, Anna and Caruana, Rich},
  title =        {How Interpretable and Trustworthy Are Gams?},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2006.06466v1},
  abstract =     {Generalized additive models (GAMs) have become a leading model
                  class for data bias discovery and model auditing. However,
                  there are a variety of algorithms for training GAMs, and these
                  do not always learn the same things. Statisticians originally
                  used splines to train GAMs, but more recently GAMs are being
                  trained with boosted decision trees. It is unclear which GAM
                  model(s) to believe, particularly when their explanations are
                  contradictory. In this paper, we investigate a variety of
                  different GAM algorithms both qualitatively and quantitatively
                  on real and simulated datasets. Our results suggest that
                  inductive bias plays a crucial role in model explanations and
                  tree-based GAMs are to be recommended for the kinds of
                  problems and dataset sizes we worked with.},
  archivePrefix ={arXiv},
  eprint =       {2006.06466},
  primaryClass = {cs.LG},
}
                  
@inproceedings{hendrycks-2018-deep-anomal,
  author =       {Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
  title =        {Deep Anomaly Detection With Outlier Exposure},
  booktitle =    {International Conference on Learning Representations},
  year =         2019,
  url =          {http://arxiv.org/abs/1812.04606v3},
  abstract =     {It is important to detect anomalous inputs when deploying
                  machine learning systems. The use of larger and more complex
                  inputs in deep learning magnifies the difficulty of
                  distinguishing between anomalous and in-distribution examples.
                  At the same time, diverse image and text data are available in
                  enormous quantities. We propose leveraging these data to
                  improve deep anomaly detection by training anomaly detectors
                  against an auxiliary dataset of outliers, an approach we call
                  Outlier Exposure (OE). This enables anomaly detectors to
                  generalize and detect unseen anomalies. In extensive
                  experiments on natural language processing and small- and
                  large-scale vision tasks, we find that Outlier Exposure
                  significantly improves detection performance. We also observe
                  that cutting-edge generative models trained on CIFAR-10 may
                  assign higher likelihoods to SVHN images than to CIFAR-10
                  images; we use OE to mitigate this issue. We also analyze the
                  flexibility and robustness of Outlier Exposure, and identify
                  characteristics of the auxiliary dataset that improve
                  performance.},
  archivePrefix ={arXiv},
  eprint =       {1812.04606},
  primaryClass = {cs.LG},
}


@incollection{kuleshov-2015-calib-struct-pred,
	Author = {Kuleshov, Volodymyr and Liang, Percy S},
	Booktitle = {Advances in Neural Information Processing Systems 28},
	Editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
	Pages = {3474--3482},
	Publisher = {Curran Associates, Inc.},
	Title = {Calibrated Structured Prediction},
	Url = {http://papers.nips.cc/paper/5658-calibrated-structured-prediction.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5658-calibrated-structured-prediction.pdf}}


@article{konstan-2012-recom-system,
  author =       {Joseph A. Konstan and John Riedl},
  title =        {Recommender Systems: From Algorithms To User Experience},
  journal =      {User Modeling and User-Adapted Interaction},
  volume =       22,
  number =       {1-2},
  pages =        {101-123},
  year =         2012,
  doi =          {10.1007/s11257-011-9112-x},
  url =          {https://doi.org/10.1007/s11257-011-9112-x},
  DATE_ADDED =   {Tue Oct 13 09:19:29 2020},
}

@article{murphy-1973-new-vector,
  author =       {Allan H. Murphy},
  title =        {A New Vector Partition of the Probability Score},
  journal =      {Journal of Applied Meteorology},
  volume =       12,
  number =       4,
  pages =        {595-600},
  year =         1973,
  doi =          {10.1175/1520-0450(1973)012<0595:anvpot>2.0.co;2},
  url =
                  {https://doi.org/10.1175/1520-0450(1973)012<0595:anvpot>2.0.co;2},
  DATE_ADDED =   {Tue Oct 13 21:07:23 2020},
}

@article{stephenson-2008-two-extra,
  author =       {D. B. Stephenson and C. A. S. Coelho and I. T. Jolliffe},
  title =        {Two Extra Components in the Brier Score Decomposition},
  journal =      {Weather and Forecasting},
  volume =       23,
  number =       4,
  pages =        {752-757},
  year =         2008,
  doi =          {10.1175/2007waf2006116.1},
  url =          {https://doi.org/10.1175/2007waf2006116.1},
  DATE_ADDED =   {Tue Oct 13 21:29:56 2020},
}

@inproceedings{zadrozny-2002-trans,
  author =       {Bianca Zadrozny and Charles Elkan},
  title =        {Transforming classifier scores into accurate multiclass
                  probability estimates},
  booktitle =    {Proceedings of the eighth ACM SIGKDD international conference
                  on Knowledge discovery and data mining - KDD '02},
  year =         2002,
  pages =        {695--699},
  doi =          {10.1145/775047.775151},
  url =          {https://doi.org/10.1145/775047.775151},
  DATE_ADDED =   {Tue Oct 13 22:03:30 2020},
  month =        {-},
}

@article{vyugin-2009-calib-error,
  author =       {Vladimir V. V'yugin},
  title =        {On Calibration Error of Randomized Forecasting Algorithms},
  journal =      {Theoretical Computer Science},
  volume =       410,
  number =       19,
  pages =        {1781-1795},
  year =         2009,
  doi =          {10.1016/j.tcs.2009.01.010},
  url =          {https://doi.org/10.1016/j.tcs.2009.01.010},
  DATE_ADDED =   {Thu Oct 15 08:18:57 2020},
}

@article{zhao-2020-indiv-calib,
  author =       {Zhao, Shengjia and Ma, Tengyu and Ermon, Stefano},
  title =        {Individual Calibration With Randomized Forecasting},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2006.10288v3},
  abstract =     {Machine learning applications often require calibrated
                  predictions, e.g. a 90\% credible interval should contain the
                  true outcome 90\% of the times. However, typical definitions
                  of calibration only require this to hold on average, and offer
                  no guarantees on predictions made on individual samples. Thus,
                  predictions can be systematically over or under confident on
                  certain subgroups, leading to issues of fairness and potential
                  vulnerabilities. We show that calibration for individual
                  samples is possible in the regression setup if the predictions
                  are randomized, i.e. outputting randomized credible intervals.
                  Randomization removes systematic bias by trading off bias with
                  variance. We design a training objective to enforce individual
                  calibration and use it to train randomized regression
                  functions. The resulting models are more calibrated for
                  arbitrarily chosen subgroups of the data, and can achieve
                  higher utility in decision making against adversaries that
                  exploit miscalibrated predictions.},
  archivePrefix ={arXiv},
  eprint =       {2006.10288},
  primaryClass = {stat.ML},
}

@InProceedings{abernethy-2012-charact,
  title =        {A Characterization of Scoring Rules for Linear Properties},
  author =       {Jacob D. Abernethy and Rafael M. Frongillo},
  pages =        {27.1--27.13},
  year =         {2012},
  editor =       {Shie Mannor and Nathan Srebro and Robert C. Williamson},
  volume =       {23},
  series =       {Proceedings of Machine Learning Research},
  address =      {Edinburgh, Scotland},
  month =        {25--27 Jun},
  publisher =    {JMLR Workshop and Conference Proceedings},
  pdf =          {http://proceedings.mlr.press/v23/abernethy12/abernethy12.pdf},
  url =          {http://proceedings.mlr.press/v23/abernethy12.html},
  abstract =     {We consider the design of proper scoring rules, equivalently
                  proper losses, when the goal is to elicit some function, known
                  as a property, of the underlying distribution. We provide a
                  full characterization of the class of proper scoring rules
                  when the property is linear as a function of the input
                  distribution. A key conclusion is that any such scoring rule
                  can be written in the form of a Bregman divergence for some
                  convex function. We also apply our results to the design of
                  prediction market mechanisms, showing a strong equivalence
                  between scoring rules for linear properties and automated
                  prediction market makers.}
}
@article{lopez-2020-learn-from,
  author =       {Lopez, Romain and Dhillon, Inderjit and Jordan, Michael I.},
  title =        {Learning From Extreme Bandit Feedback},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2009.12947v1},
  abstract =     {We study the problem of batch learning from bandit feedback in
                  the setting of extremely large action spaces. Learning from
                  extreme bandit feedback is ubiquitous in recommendation
                  systems, in which billions of decisions are made over sets
                  consisting of millions of choices in a single day, yielding
                  massive observational data. In these large-scale real-world
                  applications, supervised learning frameworks such as eXtreme
                  Multi-label Classification (XMC) are widely used despite the
                  fact that they incur significant biases due to the mismatch
                  between bandit feedback and supervised labels. Such biases can
                  be mitigated by importance sampling techniques, but these
                  techniques suffer from impractical variance when dealing with
                  a large number of actions. In this paper, we introduce a
                  selective importance sampling estimator (sIS) that operates in
                  a significantly more favorable bias-variance regime. The sIS
                  estimator is obtained by performing importance sampling on the
                  conditional expectation of the reward with respect to a small
                  subset of actions for each instance (a form of
                  Rao-Blackwellization). We employ this estimator in a novel
                  algorithmic procedure---named Policy Optimization for eXtreme
                  Models (POXM)---for learning from bandit feedback on XMC
                  tasks. In POXM, the selected actions for the sIS estimator are
                  the top-p actions of the logging policy, where p is adjusted
                  from the data and is significantly smaller than the size of
                  the action space. We use a supervised-to-bandit conversion on
                  three XMC datasets to benchmark our POXM method against three
                  competing methods: BanditNet, a previously applied partial
                  matching pruning strategy, and a supervised learning baseline.
                  Whereas BanditNet sometimes improves marginally over the
                  logging policy, our experiments show that POXM systematically
                  and significantly improves over all baselines.},
  archivePrefix ={arXiv},
  eprint =       {2009.12947},
  primaryClass = {stat.ML},
}
@article{lucena-2018-splin-based,
  author =       {Lucena, Brian},
  title =        {Spline-Based Probability Calibration},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1809.07751v1},
  abstract =     {In many classification problems it is desirable to output
                  well-calibrated probabilities on the different classes. We
                  propose a robust, non-parametric method of calibrating
                  probabilities called SplineCalib that utilizes smoothing
                  splines to determine a calibration function. We demonstrate
                  how applying certain transformations as part of the
                  calibration process can improve performance on problems in
                  deep learning and other domains where the scores tend to be
                  "overconfident". We adapt the approach to multi-class problems
                  and find that better calibration can improve accuracy as well
                  as log-loss by better resolving uncertain cases. Finally, we
                  present a cross-validated approach to calibration which
                  conserves data. Significant improvements to log-loss and
                  accuracy are shown on several different problems. We also
                  introduce the ml-insights python package which contains an
                  implementation of the SplineCalib algorithm.},
  archivePrefix ={arXiv},
  eprint =       {1809.07751},
  primaryClass = {stat.ML},
}

@inproceedings{mukhoti-2020-calib-deep,
  title =        {Calibrating Deep Neural Networks using Focal Loss},
  author =       {Mukhoti, Jishnu and Kulharia, Viveka and Sanyal, Amartya and
                  Golodetz, Stuart and Torr, Philip HS and Dokania, Puneet K},
  booktitle =    {Advances in Neural Information Processing Systems},
  year =         2020
}

@article{mukhoti-2020-calib-deep-arxiv,
  author =       {Mukhoti, Jishnu and Kulharia, Viveka and Sanyal, Amartya and
                  Golodetz, Stuart and Torr, Philip H. S. and Dokania, Puneet
                  K.},
  title =        {Calibrating Deep Neural Networks Using Focal Loss},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2002.09437v1},
  abstract =     {Miscalibration -- a mismatch between a model's confidence and
                  its correctness -- of Deep Neural Networks (DNNs) makes their
                  predictions hard to rely on. Ideally, we want networks to be
                  accurate, calibrated and confident. We show that, as opposed
                  to the standard cross-entropy loss, focal loss (Lin et al.,
                  2017) allows us to learn models that are already very well
                  calibrated. When combined with temperature scaling, whilst
                  preserving accuracy, it yields state-of-the-art calibrated
                  models. We provide a thorough analysis of the factors causing
                  miscalibration, and use the insights we glean from this to
                  justify the empirically excellent performance of focal loss.
                  To facilitate the use of focal loss in practice, we also
                  provide a principled approach to automatically select the
                  hyperparameter involved in the loss function. We perform
                  extensive experiments on a variety of computer vision and NLP
                  datasets, and with a wide variety of network architectures,
                  and show that our approach achieves state-of-the-art accuracy
                  and calibration in almost all cases.},
  archivePrefix ={arXiv},
  eprint =       {2002.09437},
  primaryClass = {cs.LG},
}


@article{cassel-1976-some-resul,
  author =       {CLAES M. CASSEL and CARL E. S{\"A}RNDAL and JAN H. WRETMAN},
  title =        {Some Results on Generalized Difference Estimation and
                  Generalized Regression Estimation for Finite Populations},
  journal =      {Biometrika},
  volume =       63,
  number =       3,
  pages =        {615-620},
  year =         1976,
  doi =          {10.1093/biomet/63.3.615},
  url =          {https://doi.org/10.1093/biomet/63.3.615},
  DATE_ADDED =   {Sat Oct 24 20:55:35 2020},
}

@inproceedings{beygelzimer-2009-offset-tree,
  author =       {Alina Beygelzimer and John Langford},
  title =        {The offset tree for learning with partial labels},
  booktitle =    {Proceedings of the 15th ACM SIGKDD international conference on
                  Knowledge discovery and data mining - KDD '09},
  year =         2009,
  pages =        {nil},
  doi =          {10.1145/1557019.1557040},
  url =          {https://doi.org/10.1145/1557019.1557040},
  DATE_ADDED =   {Sat Oct 24 20:59:04 2020},
  month =        {-},
}

@inbook{gretton-2008-covar-shift,
  DATE_ADDED =   {Sun Oct 25 13:32:39 2020},
  author =       {Arthur Gretton and Alex Smola and Jiayuan Huang and Marcel
                  Schmittfull and Karsten Borgwardt and Bernhard Sch{\"o}lkopf},
  booktitle =    {Dataset Shift in Machine Learning},
  doi =          {10.7551/mitpress/9780262170055.003.0008},
  pages =        {131-160},
  publisher =    {The MIT Press},
  series =       {Dataset Shift in Machine Learning},
  title =        {Covariate Shift by Kernel Mean Matching},
  url =          {https://doi.org/10.7551/mitpress/9780262170055.003.0008},
  year =         {2008},
}

@article{seaman-2018-introd-to,
  author =       {Shaun R. Seaman and Stijn Vansteelandt},
  title =        {Introduction To Double Robust Methods for Incomplete Data},
  journal =      {Statistical Science},
  volume =       33,
  number =       2,
  pages =        {184-197},
  year =         2018,
  doi =          {10.1214/18-sts647},
  url =          {https://doi.org/10.1214/18-sts647},
  DATE_ADDED =   {Sat Oct 31 19:37:29 2020},
}

@article{kang-2007-demys-doubl-robus,
  author =       {Joseph D. Y. Kang and Joseph L. Schafer},
  title =        {Demystifying Double Robustness: a Comparison of Alternative
                  Strategies for Estimating a Population Mean From Incomplete
                  Data},
  journal =      {Statistical Science},
  volume =       22,
  number =       4,
  pages =        {523-539},
  year =         2007,
  doi =          {10.1214/07-sts227},
  url =          {https://doi.org/10.1214/07-sts227},
  DATE_ADDED =   {Sat Oct 31 19:48:42 2020},
}

@inproceedings{joachims-2016-count-evaluat,
  author =       {Thorsten Joachims and Adith Swaminathan},
  title =        {Counterfactual Evaluation and Learning for Search,
                  Recommendation and Ad Placement},
  booktitle =    {Proceedings of the 39th International ACM SIGIR conference on
                  Research and Development in Information Retrieval - SIGIR '16},
  year =         2016,
  pages =        {nil},
  doi =          {10.1145/2911451.2914803},
  url =          {https://doi.org/10.1145/2911451.2914803},
  DATE_ADDED =   {Wed Nov 4 09:25:13 2020},
  month =        {-},
  abstract =     {Online metrics measured through A/B tests have become the gold
                  standard for many evaluation questions. But can we get the
                  same results as A/B tests without actually fielding a new
                  system? And can we train systems to optimize online metrics
                  without subjecting users to an online learning algorithm? This
                  tutorial summarizes and unifies the emerging body of methods
                  on counterfactual evaluation and learning. These
                  counterfactual techniques provide a well-founded way to
                  evaluate and optimize online metrics by exploiting logs of
                  past user interactions. In particular, the tutorial unifies
                  the causal inference, information retrieval, and machine
                  learning view of this problem, providing the basis for future
                  research in this emerging area of great potential impact.
                  Supplementary material and resources are available online at
                  http://www.cs.cornell.edu/~adith/CfactSIGIR2016.},
  pages =        {1199–1201},
  keywords =     {causal inference, batch learning from bandit feedback,
                  learning to rank, counterfactual estimation},
  location =     {Pisa, Italy},
  series =       {SIGIR '16}
}
                  
@inproceedings{zadrozny-2003-cost-sensit,
  author =       {Zadrozny, Bianca and Langford, John and Abe, Naoki},
  title =        {Cost-Sensitive Learning by Cost-Proportionate Example
                  Weighting},
  year =         {2003},
  isbn =         {0769519784},
  publisher =    {IEEE Computer Society},
  address =      {USA},
  abstract =     {We propose and evaluate a family of methods for
                  convertingclassifier learning algorithms and classification
                  theoryinto cost-sensitive algorithms and theory. The
                  proposedconversion is based on cost-proportionate weighting of
                  thetraining examples, which can be realized either by
                  feedingthe weights to the classification algorithm (as often
                  done inboosting), or by careful subsampling. We give some
                  theoreticalperformance guarantees on the proposed methods,as
                  well as empirical evidence that they are practical
                  alternativesto existing approaches. In particular, we
                  proposecosting, a method based on cost-proportionate
                  rejectionsampling and ensemble aggregation, which
                  achievesexcellent predictive performance on two publicly
                  availabledatasets, while drastically reducing the computation
                  requiredby other methods.},
  booktitle =    {Proceedings of the Third IEEE International Conference on Data
                  Mining},
  pages =        {435},
  numpages =     {1},
  series =       {ICDM '03},
  doi =          {10.1109/icdm.2003.1250950},
  url =          {https://doi.org/10.1109/icdm.2003.1250950},
  DATE_ADDED =   {Fri Nov 6 17:25:05 2020},
}

@article{horvitz-1952-gener-sampl,
  author =       {D. G. Horvitz and D. J. Thompson},
  title =        {A Generalization of Sampling Without Replacement From a Finite
                  Universe},
  journal =      {Journal of the American Statistical Association},
  volume =       47,
  number =       260,
  pages =        {663-685},
  year =         1952,
  doi =          {10.1080/01621459.1952.10483446},
  url =          {https://doi.org/10.1080/01621459.1952.10483446},
  DATE_ADDED =   {Fri Nov 6 18:25:49 2020},
}

@article{rosenbaum-1983-centr-role,
  author =       {Paul R. Rosenbaum and Donald B. Rubin},
  title =        {The Central Role of the Propensity Score in Observational
                  Studies for Causal Effects},
  journal =      {Biometrika},
  volume =       70,
  number =       1,
  pages =        {41-55},
  year =         1983,
  doi =          {10.1093/biomet/70.1.41},
  url =          {https://doi.org/10.1093/biomet/70.1.41},
  DATE_ADDED =   {Fri Nov 6 19:05:33 2020},
}

@inproceedings{li-2011-unbias,
  author =       {Lihong Li and Wei Chu and John Langford and Xuanhui Wang},
  title =        {Unbiased offline evaluation of contextual-bandit-based news
                  article recommendation algorithms},
  booktitle =    {Proceedings of the fourth ACM international conference on Web
                  search and data mining - WSDM '11},
  year =         2011,
  pages =        {nil},
  doi =          {10.1145/1935826.1935878},
  url =          {https://doi.org/10.1145/1935826.1935878},
  DATE_ADDED =   {Fri Nov 6 19:07:46 2020},
  month =        {-},
}

@book{owen-2013-monte-carlo,
   author = {Art B. Owen},
   year = 2013,
   title = {Monte Carlo theory, methods and examples}
}

@article{candes-2016-pannin-gold,
  author =       {Candes, Emmanuel and Fan, Yingying and Janson, Lucas and Lv,
                  Jinchi},
  title =        {Panning for Gold: Model-X Knockoffs for High-Dimensional
                  Controlled Variable Selection},
  journal =      {CoRR},
  year =         2016,
  url =          {http://arxiv.org/abs/1610.02351v4},
  abstract =     {Many contemporary large-scale applications involve building
                  interpretable models linking a large set of potential
                  covariates to a response in a nonlinear fashion, such as when
                  the response is binary. Although this modeling problem has
                  been extensively studied, it remains unclear how to
                  effectively control the fraction of false discoveries even in
                  high-dimensional logistic regression, not to mention general
                  high-dimensional nonlinear models. To address such a practical
                  problem, we propose a new framework of $model$-$X$ knockoffs,
                  which reads from a different perspective the knockoff
                  procedure (Barber and Cand\`es, 2015) originally designed for
                  controlling the false discovery rate in linear models. Whereas
                  the knockoffs procedure is constrained to homoscedastic linear
                  models with $n\ge p$, the key innovation here is that model-X
                  knockoffs provide valid inference from finite samples in
                  settings in which the conditional distribution of the response
                  is arbitrary and completely unknown. Furthermore, this holds
                  no matter the number of covariates. Correct inference in such
                  a broad setting is achieved by constructing knockoff variables
                  probabilistically instead of geometrically. To do this, our
                  approach requires the covariates be random (independent and
                  identically distributed rows) with a distribution that is
                  known, although we provide preliminary experimental evidence
                  that our procedure is robust to unknown/estimated
                  distributions. To our knowledge, no other procedure solves the
                  $controlled$ variable selection problem in such generality,
                  but in the restricted settings where competitors exist, we
                  demonstrate the superior power of knockoffs through
                  simulations. Finally, we apply our procedure to data from a
                  case-control study of Crohn's disease in the United Kingdom,
                  making twice as many discoveries as the original analysis of
                  the same data.},
  archivePrefix ={arXiv},
  eprint =       {1610.02351},
  primaryClass = {stat.ME},
}

@inproceedings{chapelle-2011-emp-eval-thomp,
  author =       {Chapelle, Olivier and Li, Lihong},
  title =        {An Empirical Evaluation of Thompson Sampling},
  year =         2011,
  isbn =         9781618395993,
  publisher =    {Curran Associates Inc.},
  address =      {Red Hook, NY, USA},
  abstract =     {Thompson sampling is one of oldest heuristic to address the
                  exploration / exploitation trade-off, but it is surprisingly
                  unpopular in the literature. We present here some empirical
                  results using Thompson sampling on simulated and real data,
                  and show that it is highly competitive. And since this
                  heuristic is very easy to implement, we argue that it should
                  be part of the standard baselines to compare against.},
  booktitle =    {Proceedings of the 24th International Conference on Neural
                  Information Processing Systems},
  pages =        {2249-2257},
  numpages =     9,
  location =     {Granada, Spain},
  series =       {NIPS'11}
}

@article{hesterberg-1995-weigh-averag,
  author =       {Tim Hesterberg},
  title =        {Weighted Average Importance Sampling and Defensive Mixture
                  Distributions},
  journal =      {Technometrics},
  volume =       37,
  number =       2,
  pages =        {185-194},
  year =         1995,
  doi =          {10.1080/00401706.1995.10484303},
  url =          {https://doi.org/10.1080/00401706.1995.10484303},
  DATE_ADDED =   {Sun Nov 15 17:22:33 2020},
}

@Book{tsiatis-2006-semipar-theory,
  author =    {Anastasios A. Tsiatis},
  title =        {Semiparametric theory and missing data},
  publisher =    {Springer},
  year =         2006
  }

@article{dutta-2019-autom-contex-bandit,
  author =       {Dutta, Praneet and Kit, Man and Cheuk, and Kim, Jonathan S and
                  Mascaro, Massimo},
  title =        {Automl for Contextual Bandits},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1909.03212v1},
  abstract =     {Contextual Bandits is one of the widely popular techniques
                  used in applications such as personalization, recommendation
                  systems, mobile health, causal marketing etc . As a dynamic
                  approach, it can be more efficient than standard A/B testing
                  in minimizing regret. We propose an end to end automated
                  meta-learning pipeline to approximate the optimal Q function
                  for contextual bandits problems. We see that our model is able
                  to perform much better than random exploration, being more
                  regret efficient and able to converge with a limited number of
                  samples, while remaining very general and easy to use due to
                  the meta-learning approach. We used a linearly annealed
                  e-greedy exploration policy to define the exploration vs
                  exploitation schedule. We tested the system on a synthetic
                  environment to characterize it fully and we evaluated it on
                  some open source datasets to benchmark against prior work. We
                  see that our model outperforms or performs comparatively to
                  other models while requiring no tuning nor feature
                  engineering.},
  archivePrefix ={arXiv},
  eprint =       {1909.03212},
  primaryClass = {cs.LG},
}
@article{rosenman-2018-using-poiss,
  author =       {Rosenman, Evan and Viswanathan, Nitin},
  title =        {Using Poisson Binomial Glms To Reveal Voter Preferences},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1802.01053v1},
  abstract =     {We present a new modeling technique for solving the problem of
                  ecological inference, in which individual-level associations
                  are inferred from labeled data available only at the aggregate
                  level. We model aggregate count data as arising from the
                  Poisson binomial, the distribution of the sum of independent
                  but not identically distributed Bernoulli random variables. We
                  relate individual-level probabilities to individual covariates
                  using both a logistic regression and a neural network. A
                  normal approximation is derived via the Lyapunov Central Limit
                  Theorem, allowing us to efficiently fit these models on large
                  datasets. We apply this technique to the problem of revealing
                  voter preferences in the 2016 presidential election, fitting a
                  model to a sample of over four million voters from the highly
                  contested swing state of Pennsylvania. We validate the model
                  at the precinct level via a holdout set, and at the individual
                  level using weak labels, finding that the model is predictive
                  and it learns intuitively reasonable associations.},
  archivePrefix ={arXiv},
  eprint =       {1802.01053},
  primaryClass = {stat.ML},
}
@article{kuck-2012-learn-about,
  author =       {Kuck, Hendrik and Freitas, Nando de},
  title =        {Learning About Individuals From Group Statistics},
  journal =      {CoRR},
  year =         2012,
  url =          {http://arxiv.org/abs/1207.1393v1},
  abstract =     {We propose a new problem formulation which is similar to, but
                  more informative than, the binary multiple-instance learning
                  problem. In this setting, we are given groups of instances
                  (described by feature vectors) along with estimates of the
                  fraction of positively-labeled instances per group. The task
                  is to learn an instance level classifier from this
                  information. That is, we are trying to estimate the unknown
                  binary labels of individuals from knowledge of group
                  statistics. We propose a principled probabilistic model to
                  solve this problem that accounts for uncertainty in the
                  parameters and in the unknown individual labels. This model is
                  trained with an efficient MCMC algorithm. Its performance is
                  demonstrated on both synthetic and real-world data arising in
                  general object recognition.},
  archivePrefix ={arXiv},
  eprint =       {1207.1393},
  primaryClass = {cs.LG},
}


@article{rubin-1976-infer-missin-data,
  author =       {DONALD B. RUBIN},
  title =        {Inference and Missing Data},
  journal =      {Biometrika},
  volume =       63,
  number =       3,
  pages =        {581-592},
  year =         1976,
  doi =          {10.1093/biomet/63.3.581},
  url =          {https://doi.org/10.1093/biomet/63.3.581},
  DATE_ADDED =   {Fri Nov 20 17:31:42 2020},
}

@article{bottou-2013-counter-reas,
  author =       {L{{\'e}}on Bottou and Jonas Peters and Joaquin
                  Qui{{\~n}}onero-Candela and Denis X. Charles and D. Max
                  Chickering and Elon Portugaly and Dipankar Ray and Patrice
                  Simard and Ed Snelson},
  title =        {Counterfactual Reasoning and Learning Systems: The Example of
                  Computational Advertising},
  journal =      {Journal of Machine Learning Research},
  year =         {2013},
  volume =       {14},
  number =       {65},
  pages =        {3207-3260},
  url =          {http://jmlr.org/papers/v14/bottou13a.html},
  DATE_ADDED =   {Fri Nov 20 17:49:42 2020},
}

@article{robins-1994-estim-regres,
  author =       {James M. Robins and Andrea Rotnitzky and Lue Ping Zhao},
  title =        {Estimation of Regression Coefficients When Some Regressors Are
                  Not Always Observed},
  journal =      {Journal of the American Statistical Association},
  volume =       89,
  number =       427,
  pages =        {846-866},
  year =         1994,
  doi =          {10.1080/01621459.1994.10476818},
  url =          {https://doi.org/10.1080/01621459.1994.10476818},
  DATE_ADDED =   {Sun Nov 22 17:20:41 2020},
}

@article{bang-2005-doubl-robus,
  author =       {Heejung Bang and James M. Robins},
  title =        {Doubly Robust Estimation in Missing Data and Causal Inference
                  Models},
  journal =      {Biometrics},
  volume =       61,
  number =       4,
  pages =        {962-973},
  year =         2005,
  doi =          {10.1111/j.1541-0420.2005.00377.x},
  url =          {https://doi.org/10.1111/j.1541-0420.2005.00377.x},
  DATE_ADDED =   {Mon Nov 23 06:40:19 2020},
}

@article{bang-2008-correc-to,
  author =       {Heejung Bang and James M. Robins},
  title =        {Correction To "Doubly Robust Estimation in Missing Data and
                  Causal Inference Models," By H. Bang and J. M. Robins; 61,
                  962-972, December 2005},
  journal =      {Biometrics},
  volume =       64,
  number =       2,
  pages =        {650-650},
  year =         2008,
  doi =          {10.1111/j.1541-0420.2008.01025.x},
  url =          {https://doi.org/10.1111/j.1541-0420.2008.01025.x},
  DATE_ADDED =   {Mon Nov 23 06:43:10 2020},
}

@article{farajtabar-2018-more-robus,
  author =       {Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh,
                  Mohammad},
  title =        {More Robust Doubly Robust Off-Policy Evaluation},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1802.03493v2},
  abstract =     {We study the problem of off-policy evaluation (OPE) in
                  reinforcement learning (RL), where the goal is to estimate the
                  performance of a policy from the data generated by another
                  policy(ies). In particular, we focus on the doubly robust (DR)
                  estimators that consist of an importance sampling (IS)
                  component and a performance model, and utilize the low (or
                  zero) bias of IS and low variance of the model at the same
                  time. Although the accuracy of the model has a huge impact on
                  the overall performance of DR, most of the work on using the
                  DR estimators in OPE has been focused on improving the IS
                  part, and not much on how to learn the model. In this paper,
                  we propose alternative DR estimators, called more robust
                  doubly robust (MRDR), that learn the model parameter by
                  minimizing the variance of the DR estimator. We first present
                  a formulation for learning the DR model in RL. We then derive
                  formulas for the variance of the DR estimator in both
                  contextual bandits and RL, such that their gradients
                  w.r.t.~the model parameters can be estimated from the samples,
                  and propose methods to efficiently minimize the variance. We
                  prove that the MRDR estimators are strongly consistent and
                  asymptotically optimal. Finally, we evaluate MRDR in bandits
                  and RL benchmark problems, and compare its performance with
                  the existing methods.},
  archivePrefix ={arXiv},
  eprint =       {1802.03493},
  primaryClass = {cs.AI},
}

@article{rubin-1977-assig-to,
  author =       {Donald B. Rubin},
  title =        {Assignment To Treatment Group on the Basis of a Covariate},
  journal =      {Journal of Educational Statistics},
  volume =       2,
  number =       1,
  pages =        1,
  year =         1977,
  doi =          {10.2307/1164933},
  url =          {https://doi.org/10.2307/1164933},
  DATE_ADDED =   {Wed Dec 9 15:27:38 2020},
}

@article{slivkins-2019-intro-multi,
  url =          {http://dx.doi.org/10.1561/2200000068},
  year =         {2019},
  volume =       {12},
  journal =      {Foundations and Trends® in Machine Learning},
  title =        {Introduction to Multi-Armed Bandits},
  doi =          {10.1561/2200000068},
  issn =         {1935-8237},
  number =       {1-2},
  pages =        {1-286},
  author =       {Aleksandrs Slivkins }
}

@incollection{chernozhukov-2017-lec6,
  author =       "Victor Chernozhukov and Iv{\'a}n Fern{\'a}ndez-Val",
  title =        "Treatment effects",
  booktitle =    "Econometrics---MIT Course 14.382",
  year =         2017,
  organization = "Massachusetts Institute of Technology",
  address =      "Cambridge~MA",
  note =         "{MIT OpenCourseWare}",
  url =
                  "https://ocw.mit.edu/courses/economics/14-382-econometrics-spring-2017/lecture-notes/MIT14_382S17_lec12.pdf",
}

@article{rubin-1978-bayes-infer,
  author =       {Donald B. Rubin},
  title =        {Bayesian Inference for Causal Effects: the Role of
                  Randomization},
  journal =      {The Annals of Statistics},
  volume =       6,
  number =       1,
  pages =        {34-58},
  year =         1978,
  doi =          {10.1214/aos/1176344064},
  url =          {https://doi.org/10.1214/aos/1176344064},
  DATE_ADDED =   {Mon Dec 14 19:19:55 2020},
}

@article{thompson-1933-likel-that,
  author =       {William R. Thompson},
  title =        {On the Likelihood That One Unknown Probability Exceeds Another
                  in View of the Evidence of Two Samples},
  journal =      {Biometrika},
  volume =       25,
  number =       {3/4},
  pages =        285,
  year =         1933,
  doi =          {10.2307/2332286},
  url =          {https://doi.org/10.2307/2332286},
  DATE_ADDED =   {Wed Dec 16 11:22:00 2020},
}

@Book{lattimore-2020-bandit,
  author =    {Tor Lattimore and Csaba Szepesv{\'a}ri},
  title =        {Bandit algorithms},
  publisher =    {Cambridge University Press},
  year =         2020}

@article{bietti-2018-contex-bandit,
  author =       {Bietti, Alberto and Agarwal, Alekh and Langford, John},
  title =        {A Contextual Bandit Bake-Off},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1802.04064v4},
  abstract =     {Contextual bandit algorithms are essential for solving many
                  real-world interactive machine learning problems. Despite
                  multiple recent successes on statistically and computationally
                  efficient methods, the practical behavior of these algorithms
                  is still poorly understood. We leverage the availability of
                  large numbers of supervised learning datasets to empirically
                  evaluate contextual bandit algorithms, focusing on practical
                  methods that learn by relying on optimization oracles from
                  supervised learning. We find that a recent method (Foster et
                  al., 2018) using optimism under uncertainty works the best
                  overall. A surprisingly close second is a simple greedy
                  baseline that only explores implicitly through the diversity
                  of contexts, followed by a variant of Online Cover (Agarwal et
                  al., 2014) which tends to be more conservative but robust to
                  problem specification by design. Along the way, we also
                  evaluate various components of contextual bandit algorithm
                  design such as loss estimators. Overall, this is a thorough
                  study and review of contextual bandit methodology.},
  archivePrefix ={arXiv},
  eprint =       {1802.04064},
  primaryClass = {stat.ML},
}

@inproceedings{langford-2007-epoch-greedy,
  author =       {Langford, John and Zhang, Tong},
  title =        {The Epoch-Greedy Algorithm for Contextual Multi-Armed Bandits},
  year =         {2007},
  isbn =         {9781605603520},
  publisher =    {Curran Associates Inc.},
  address =      {Red Hook, NY, USA},
  abstract =     {We present Epoch-Greedy, an algorithm for contextual
                  multi-armed bandits (also known as bandits with side
                  information). Epoch-Greedy has the following properties:1. No
                  knowledge of a time horizon T is necessary.2. The regret
                  incurred by Epoch-Greedy is controlled by a sample complexity
                  bound for a hypothesis class.3. The regret scales as
                  O(T2/3S1/3) or better (sometimes, much better). Here S is the
                  complexity term in a sample complexity bound for standard
                  supervised learning.},
  booktitle =    {Proceedings of the 20th International Conference on Neural
                  Information Processing Systems},
  pages =        {817-824},
  numpages =     {8},
  location =     {Vancouver, British Columbia, Canada},
  series =       {NIPS'07}
}

@inproceedings{langford-2008-explor,
  author =       {John Langford and Alexander Strehl and Jennifer Wortman},
  title =        {Exploration scavenging},
  booktitle =    {Proceedings of the 25th international conference on Machine
                  learning - ICML '08},
  year =         2008,
  pages =        {nil},
  doi =          {10.1145/1390156.1390223},
  url =          {https://doi.org/10.1145/1390156.1390223},
  DATE_ADDED =   {Tue Dec 22 08:06:04 2020},
  month =        {-},
}

@inproceedings{langford-2017-contex,
  author =       {John Langford},
  title =        {Contextual reinforcement learning},
  booktitle =    {2017 IEEE International Conference on Big Data (Big Data)},
  year =         2017,
  pages =        {nil},
  doi =          {10.1109/bigdata.2017.8257902},
  url =          {https://doi.org/10.1109/bigdata.2017.8257902},
  DATE_ADDED =   {Tue Dec 22 20:21:47 2020},
  month =        12,
}

@inproceedings{strehl-2010-learn-logged,
  author =       {Strehl, Alex and Langford, John and Li, Lihong and Kakade,
                  Sham M},
  booktitle =    {Advances in Neural Information Processing Systems},
  editor =       {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel
                  and A. Culotta},
  pages =        {2217--2225},
  publisher =    {Curran Associates, Inc.},
  title =        {Learning from Logged Implicit Exploration Data},
  url =
                  {https://proceedings.neurips.cc/paper/2010/file/c0f168ce8900fa56e57789e2a2f2c9d0-Paper.pdf},
  volume =       {23},
  year =         {2010}
}

@inproceedings{maurer-2009-emp-bernst,
  added-at =     {2011-03-25T00:00:00.000+0100},
  author =       {Maurer, Andreas and Pontil, Massimiliano},
  biburl =
                  {https://www.bibsonomy.org/bibtex/2a45d86137b7c3c88644f8c1a56772d88/dblp},
  booktitle =    {COLT},
  crossref =     {conf/colt/2009},
  ee =           {http://www.cs.mcgill.ca/~colt2009/papers/012.pdf#page=1},
  interhash =    {a9a35735aa8b056369cb8334f54a847a},
  intrahash =    {a45d86137b7c3c88644f8c1a56772d88},
  keywords =     {dblp},
  timestamp =    {2011-04-29T15:31:37.000+0200},
  title =        {Empirical Bernstein Bounds and Sample-Variance Penalization.},
  url =          {http://dblp.uni-trier.de/db/conf/colt/colt2009.html#MaurerP09},
  year =         2009
}

@InProceedings{wang-2019-batch-learn,
  author =       {Lequn Wang and Yiwei Bai and A. Bhalla and T. Joachims},
  title =        {Batch Learning from Bandit Feedback through Bias Corrected
                  Reward Imputation},
  booktitle =    {ICML Workshop on Real-World Sequential Decision Making},
  year =         2019
}

@article{brandfonbrener-2020-bandit-overf,
  author =       {Brandfonbrener, David and Whitney, William F. and Ranganath,
                  Rajesh and Bruna, Joan},
  title =        {Bandit Overfitting in Offline Policy Learning},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2006.15368v2},
  abstract =     {We study the offline policy learning problem in a contextual
                  bandit framework. Specifically, we focus on the issue of
                  overfitting which is especially important in a modern context
                  where we often use overparameterized models that can
                  interpolate the data. Our first contribution is to introduce a
                  regret decomposition into approximation, estimation, and
                  bandit errors that emphasizes the distinction between the
                  policy learning and supervised learning problems. The bandit
                  error measures the error from overfitting to the single action
                  observed at each context, which we call "bandit overfitting".
                  Our second contribution is to show both in theory and
                  experiments how bandit overfitting is different for
                  policy-based versus value-based algorithms when we use
                  overparameterized models. We find that bandit overfitting can
                  become a severe problem for policy-based algorithms, but
                  value-based algorithms effectively reduce the policy learning
                  problem to regression and thus avoid the worst problems of
                  bandit overfitting.},
  archivePrefix ={arXiv},
  eprint =       {2006.15368},
  primaryClass = {cs.LG},
}
@article{kuzborskij-2020-confid-off,
  author =       {Kuzborskij, Ilja and Vernade, Claire and Gy{\"o}rgy,
                  Andr{\'a}s and Szepesv{\'a}ri, Csaba},
  title =        {Confident Off-Policy Evaluation and Selection Through
                  Self-Normalized Importance Weighting},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2006.10460v2},
  abstract =     {We consider off-policy evaluation in the contextual bandit
                  setting for the purpose of obtaining a robust off-policy
                  selection strategy, where the selection strategy is evaluated
                  based on the value of the chosen policy in a set of proposal
                  (target) policies. We propose a new method to compute a lower
                  bound on the value of an arbitrary target policy given some
                  logged data in contextual bandits for a desired coverage. The
                  lower bound is built around the so-called Self-normalized
                  Importance Weighting (SN) estimator. It combines the use of a
                  semi-empirical Efron-Stein tail inequality to control the
                  concentration and Harris' inequality to control the bias. The
                  new approach is evaluated on a number of synthetic and real
                  datasets and is found to be superior to its main competitors,
                  both in terms of tightness of the confidence intervals and the
                  quality of the policies chosen.},
  archivePrefix ={arXiv},
  eprint =       {2006.10460},
  primaryClass = {cs.LG},
}

@book{blitzstein-2019-intro-prob,
  added-at =     {2019-03-01T20:01:29.000+0100},
  author =       {K. Blitzstein, Joseph and Hwang, Jessica},
  publisher =    {Chapman and Hall/CRC},
  keywords =     {book probability},
  title =        {Introduction to Probability Second Edition},
  edition =      {2nd},
  url =
                  {https://drive.google.com/file/d/1VmkAAGOYCTORq1wxSQqy255qLJjTNvBI/view},
  year =         2019,
  DATE_ADDED =   {Wed Dec 30 12:05:52 2020},
}

@misc{wiki-2020-conditional-expectation,
  DATE_ADDED =   {Fri Jan 1 09:39:16 2021},
  author =       "{Wikipedia contributors}",
  note =         "[Online; accessed 31-December-2020]",
  title =        "Conditional expectation --- {W}ikipedia{,} The Free
                  Encyclopedia",
  url =          "https://en.wikipedia.org/wiki/Conditional_expectation",
  year =         2020,
}

                  

@book{vaart-1998-asympt-stat,
  place =        {Cambridge},
  series =       {Cambridge Series in Statistical and Probabilistic Mathematics},
  title =        {Asymptotic Statistics},
  DOI =          {10.1017/CBO9780511802256},
  publisher =    {Cambridge University Press},
  author =       {Vaart, A. W. van der},
  year =         {1998},
  collection =   {Cambridge Series in Statistical and Probabilistic Mathematics}
}

@book{cover-2006-elem-info-theory,
  author =       {Cover, Thomas M. and Thomas, Joy A.},
  title =        {Elements of Information Theory (Wiley Series in
                  Telecommunications and Signal Processing)},
  year =         {2006},
  isbn =         {0471241954},
  publisher =    {Wiley-Interscience},
  address =      {USA}
}

@article{liu-2019-tripl-robus,
  author =       {Liu, Anqi and Liu, Hao and Anandkumar, Anima and Yue, Yisong},
  title =        {Triply Robust Off-Policy Evaluation},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1911.05811v2},
  DATE_ADDED =   {Wed Jan 6 17:35:11 2021},
  abstract =     {We propose a robust regression approach to off-policy
                  evaluation (OPE) for contextual bandits. We frame OPE as a
                  covariate-shift problem and leverage modern robust regression
                  tools. Ours is a general approach that can be used to augment
                  any existing OPE method that utilizes the direct method. When
                  augmenting doubly robust methods, we call the resulting method
                  Triply Robust. We prove upper bounds on the resulting bias and
                  variance, as well as derive novel minimax bounds based on
                  robust minimax analysis for covariate shift. Our robust
                  regression method is compatible with deep learning, and is
                  thus applicable to complex OPE settings that require powerful
                  function approximators. Finally, we demonstrate superior
                  empirical performance across the standard OPE benchmarks,
                  especially in the case where the logging policy is unknown and
                  must be estimated from data.},
  archivePrefix ={arXiv},
  eprint =       {1911.05811},
  primaryClass = {cs.LG},
}

@book{schervish-1995-theor-statis,
  author =       {Mark J. Schervish},
  title =        {Theory of Statistics},
  year =         1995,
  publisher =    {Springer New York},
  url =          {https://doi.org/10.1007/978-1-4612-4250-5},
  DATE_ADDED =   {Sat Jan 9 21:51:59 2021},
  doi =          {10.1007/978-1-4612-4250-5},
  pages =        {nil},
  series =       {Springer Series in Statistics},
}

@InProceedings{shalit-2017-estim,
  title =        {Estimating individual treatment effect: generalization bounds
                  and algorithms},
  author =       {Uri Shalit and Fredrik D. Johansson and David Sontag},
  booktitle =    {Proceedings of the 34th International Conference on Machine
                  Learning},
  pages =        {3076--3085},
  year =         2017,
  editor =       {Doina Precup and Yee Whye Teh},
  volume =       70,
  series =       {Proceedings of Machine Learning Research},
  address =      {International Convention Centre, Sydney, Australia},
  month =        {06--11 Aug},
  publisher =    {PMLR},
  pdf =          {http://proceedings.mlr.press/v70/shalit17a/shalit17a.pdf},
  url =          {http://proceedings.mlr.press/v70/shalit17a.html},
  abstract =     {There is intense interest in applying machine learning to
                  problems of causal inference in fields such as healthcare,
                  economics and education. In particular, individual-level
                  causal inference has important applications such as precision
                  medicine. We give a new theoretical analysis and family of
                  algorithms for predicting individual treatment effect (ITE)
                  from observational data, under the assumption known as strong
                  ignorability. The algorithms learn a
                  âbalancedâ representation such that the
                  induced treated and control distributions look similar, and we
                  give a novel and intuitive generalization-error bound showing
                  the expected ITE estimation error of a representation is
                  bounded by a sum of the standard generalization-error of that
                  representation and the distance between the treated and
                  control distributions induced by the representation. We use
                  Integral Probability Metrics to measure distances between
                  distributions, deriving explicit bounds for the Wasserstein
                  and Maximum Mean Discrepancy (MMD) distances. Experiments on
                  real and simulated data show the new algorithms match or
                  outperform the state-of-the-art.}
}

@article{freedman-2008-weigh-regres,
  author =       {David A. Freedman and Richard A. Berk},
  title =        {Weighting Regressions By Propensity Scores},
  journal =      {Evaluation Review},
  volume =       32,
  number =       4,
  pages =        {392-409},
  year =         2008,
  doi =          {10.1177/0193841x08317586},
  url =          {https://doi.org/10.1177/0193841x08317586},
  DATE_ADDED =   {Tue Jan 12 15:07:21 2021},
}

@article{wang-2020-shapl-flow,
  author =       {Wang, Jiaxuan and Wiens, Jenna and Lundberg, Scott},
  title =        {Shapley Flow: a Graph-Based Approach To Interpreting Model
                  Predictions},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2010.14592v2},
  abstract =     {Many existing approaches for estimating feature importance are
                  problematic because they ignore or hide dependencies among
                  features. A causal graph, which encodes the relationships
                  among input variables, can aid in assigning feature
                  importance. However, current approaches that assign credit to
                  nodes in the causal graph fail to explain the entire graph. In
                  light of these limitations, we propose Shapley Flow, a novel
                  approach to interpreting machine learning models. It considers
                  the entire causal graph, and assigns credit to \textit{edges}
                  instead of treating nodes as the fundamental unit of credit
                  assignment. Shapley Flow is the unique solution to a
                  generalization of the Shapley value axioms to directed acyclic
                  graphs. We demonstrate the benefit of using Shapley Flow to
                  reason about the impact of a model's input on its output. In
                  addition to maintaining insights from existing approaches,
                  Shapley Flow extends the flat, set-based, view prevalent in
                  game theory based explanation methods to a deeper,
                  \textit{graph-based}, view. This graph-based view enables
                  users to understand the flow of importance through a system,
                  and reason about potential interventions.},
  archivePrefix ={arXiv},
  eprint =       {2010.14592},
  primaryClass = {cs.LG},
}

@Book{lehmann-1998-theory-point-est,
  author =    {E.L. Lehmann and George Casella},
  title =        {Theory of point estimation},
  publisher =    {Springer},
  year =         1998,
  edition =   {2nd}}

@article{shimodaira-2000-improv-predic,
  author =       {Hidetoshi Shimodaira},
  title =        {Improving Predictive Inference Under Covariate Shift By
                  Weighting the Log-Likelihood Function},
  journal =      {Journal of Statistical Planning and Inference},
  volume =       90,
  number =       2,
  pages =        {227-244},
  year =         2000,
  doi =          {10.1016/s0378-3758(00)00115-4},
  url =          {https://doi.org/10.1016/s0378-3758(00)00115-4},
  DATE_ADDED =   {Sun Feb 7 12:52:26 2021},
}

@article{vansteelandt-2010-analy-incom,
  author =       {Stijn Vansteelandt and James Carpenter and Michael G. Kenward},
  title =        {Analysis of Incomplete Data Using Inverse Probability
                  Weighting and Doubly Robust Estimators},
  journal =      {Methodology},
  volume =       6,
  number =       1,
  pages =        {37-48},
  year =         2010,
  doi =          {10.1027/1614-2241/a000005},
  url =          {https://doi.org/10.1027/1614-2241/a000005},
  DATE_ADDED =   {Wed Feb 10 21:23:39 2021},
}

@article{byrd-2018-what-is,
  author =       {Byrd, Jonathon and Lipton, Zachary C.},
  title =        {What Is the Effect of Importance Weighting in Deep Learning?},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1812.03372v3},
  abstract =     {Importance-weighted risk minimization is a key ingredient in
                  many machine learning algorithms for causal inference, domain
                  adaptation, class imbalance, and off-policy reinforcement
                  learning. While the effect of importance weighting is
                  well-characterized for low-capacity misspecified models,
                  little is known about how it impacts over-parameterized, deep
                  neural networks. This work is inspired by recent theoretical
                  results showing that on (linearly) separable data, deep linear
                  networks optimized by SGD learn weight-agnostic solutions,
                  prompting us to ask, for realistic deep networks, for which
                  many practical datasets are separable, what is the effect of
                  importance weighting? We present the surprising finding that
                  while importance weighting impacts models early in training,
                  its effect diminishes over successive epochs. Moreover, while
                  L2 regularization and batch normalization (but not dropout),
                  restore some of the impact of importance weighting, they
                  express the effect via (seemingly) the wrong abstraction: why
                  should practitioners tweak the L2 regularization, and by how
                  much, to produce the correct weighting effect? Our experiments
                  confirm these findings across a range of architectures and
                  datasets.},
  archivePrefix ={arXiv},
  eprint =       {1812.03372},
  primaryClass = {cs.LG},
}

@inproceedings{cortes-2010-learn-bound,
  author =       {Cortes, Corinna and Mansour, Yishay and Mohri, Mehryar},
  title =        {Learning Bounds for Importance Weighting},
  year =         2010,
  publisher =    {Curran Associates Inc.},
  address =      {Red Hook, NY, USA},
  abstract =     {This paper presents an analysis of importance weighting for
                  learning from finite samples and gives a series of theoretical
                  and algorithmic results. We point out simple cases where
                  importance weighting can fail, which suggests the need for an
                  analysis of the properties of this technique. We then give
                  both upper and lower bounds for generalization with bounded
                  importance weights and, more significantly, give learning
                  guarantees for the more common case of unbounded importance
                  weights under the weak assumption that the second moment is
                  bounded, a condition related to the R\'{e}nyi divergence of
                  the traning and test distributions. These results are based on
                  a series of novel and general bounds we derive for unbounded
                  loss functions, which are of independent interest. We use
                  these bounds to guide the definition of an alternative
                  reweighting algorithm and report the results of experiments
                  demonstrating its benefits. Finally, we analyze the properties
                  of normalized importance weights which are also commonly
                  used.},
  booktitle =    {Proceedings of the 23rd International Conference on Neural
                  Information Processing Systems - Volume 1},
  pages =        {442-450},
  numpages =     9,
  location =     {Vancouver, British Columbia, Canada},
  series =       {NIPS'10}
}

@inproceedings{beygelzimer-2009-impor-weigh,
  author =       {Beygelzimer, Alina and Dasgupta, Sanjoy and Langford, John},
  title =        {Importance Weighted Active Learning},
  year =         2009,
  isbn =         9781605585161,
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi.org/10.1145/1553374.1553381},
  abstract =     {We present a practical and statistically consistent scheme for
                  actively learning binary classifiers under general loss
                  functions. Our algorithm uses importance weighting to correct
                  sampling bias, and by controlling the variance, we are able to
                  give rigorous label complexity bounds for the learning
                  process.},
  booktitle =    {Proceedings of the 26th Annual International Conference on
                  Machine Learning},
  pages =        {49-56},
  numpages =     8
}

@book{sugiyama-2012-densit-estim,
  DATE_ADDED =   {Thu Feb 11 10:16:13 2021},
  author =       {Masashi Sugiyama and Taiji Suzuki and Takafumi Kanamori},
  title =        {Density Ratio Estimation in Machine Learning},
  doi =          {10.1017/cbo9781139035613.005},
  publisher =    {Cambridge University Press},
  url =          {https://doi.org/10.1017/cbo9781139035613.005},
  year =         2012,
}

@article{buja-2019-model-approx-i,
  author =       "Buja, Andreas and Brown, Lawrence and Berk, Richard and
                  George, Edward and Pitkin, Emil and Traskin, Mikhail and
                  Zhang, Kai and Zhao, Linda",
  doi =          "10.1214/18-STS693",
  fjournal =     "Statistical Science",
  journal =      "Statist. Sci.",
  month =        11,
  number =       4,
  pages =        "523--544",
  publisher =    "The Institute of Mathematical Statistics",
  title =        "Models as Approximations I: Consequences Illustrated with
                  Linear Regression",
  url =          "https://doi.org/10.1214/18-STS693",
  volume =       34,
  year =         2019
}


@article{wager-2016-high-dimen,
  author =       {Stefan Wager and Wenfei Du and Jonathan Taylor and Robert J.
                  Tibshirani},
  title =        {High-Dimensional Regression Adjustments in Randomized
                  Experiments},
  journal =      {Proceedings of the National Academy of Sciences},
  volume =       113,
  number =       45,
  pages =        {12673-12678},
  year =         2016,
  doi =          {10.1073/pnas.1614732113},
  url =          {https://doi.org/10.1073/pnas.1614732113},
  DATE_ADDED =   {Sun Feb 14 09:59:06 2021},
}

@misc{wager-2020-causal-inference,
  author =       {Stefan Wager},
  title =        {STATS 361: Causal Inference (Lecture notes)},
  howpublished = "\url{https://web.stanford.edu/~swager/stats361.pdf}",
  year =         2020,
  note =         "[Online; accessed 14-February-2020]"
}

@article{cao-2009-improv-effic,
  author =       {Weihua Cao and Anastasios A. Tsiatis and Marie Davidian},
  title =        {Improving Efficiency and Robustness of the Doubly Robust
                  Estimator for a Population Mean With Incomplete Data},
  journal =      {Biometrika},
  volume =       96,
  number =       3,
  pages =        {723-734},
  year =         2009,
  doi =          {10.1093/biomet/asp033},
  url =          {https://doi.org/10.1093/biomet/asp033},
  DATE_ADDED =   {Wed Feb 17 15:10:27 2021},
}

@Book{rosenbaum-2017-obser,
  author =       {Paul R. Rosenbaum},
  title =        {Observation and experiment: an introduction to causal
                  inference},
  publisher =    {Harvard University Press},
  year =         2017
}

@book{rosenbaum-2002-obser-studies,
  author =       {Paul R. Rosenbaum},
  title =        {Observational Studies},
  year =         2002,
  publisher =    {Springer New York},
  url =          {https://doi.org/10.1007/978-1-4757-3692-2},
  DATE_ADDED =   {Thu Feb 18 21:05:44 2021},
  doi =          {10.1007/978-1-4757-3692-2},
  series =       {Springer Series in Statistics},
}

@inproceedings{reddi-2015-doubl-robus,
  author =       {Sashank Reddi and Barnabas Poczos and Alex Smola},
  title =        {Doubly Robust Covariate Shift Correction},
  booktitle =   {AAAI Conference on Artificial Intelligence},
  year =         2015,
  abstract =     {Covariate shift correction allows one to perform supervised
                  learning even when the distribution of the covariates on the
                  training set does not match that on the test set. This is
                  achieved by re-weighting observations. Such a strategy removes
                  bias, potentially at the expense of greatly increased
                  variance. We propose a simple strategy for removing bias while
                  retaining small variance. It uses a biased, low variance
                  estimate as a prior and corrects the final estimate relative
                  to the prior. We prove that this yields an efficient estimator
                  and demonstrate good experimental performance.},
  url =
                  {https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9498}
}

@article{murray-2015-youve-gone,
  author =       {Gregg R. Murray and Richard E. Matland},
  title =        {"You've Gone Too Far": Social Pressure Mobilization,
                  Reactance, and Individual Differences},
  journal =      {Journal of Political Marketing},
  volume =       14,
  number =       4,
  pages =        {333-351},
  year =         2015,
  doi =          {10.1080/15377857.2015.1086135},
  url =          {https://doi.org/10.1080/15377857.2015.1086135},
  DATE_ADDED =   {Tue Feb 23 15:14:26 2021},
}

@article{mann-2010-is-there ,
  author =       {Christopher B. Mann},
  title =        {Is There Backlash To Social Pressure? a Large-Scale Field
                  Experiment on Voter Mobilization},
  journal =      {Political Behavior},
  volume =       32,
  number =       3,
  pages =        {387-407},
  year =         2010,
  doi =          {10.1007/s11109-010-9124-y},
  url =          {https://doi.org/10.1007/s11109-010-9124-y},
  DATE_ADDED =   {Tue Feb 23 21:41:51 2021},
}

@article{scott-2010-moder-bayes,
  author =       {Steven L. Scott},
  title =        {A Modern Bayesian Look At the Multi-Armed Bandit},
  journal =      {Applied Stochastic Models in Business and Industry},
  volume =       26,
  number =       6,
  pages =        {639-658},
  year =         2010,
  doi =          {10.1002/asmb.874},
  url =          {https://doi.org/10.1002/asmb.874},
  DATE_ADDED =   {Thu Mar 4 09:17:52 2021},
}

                  
@book{hernan-2020-causal-infer,
  author =       {Miguel A. Hern{\'a}n and James M. Robins},
  title =        {Causal Inference: What If},
  publisher =    {Boca Raton: Chapman \& Hall/CRC},
  note =
                  {\url{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}},
  url =
                  {https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/},
  year =         2020
}
                  
@book{morgan-2015-count-causal-infer,
  DATE_ADDED =   {Sun Mar 7 13:28:58 2021},
  author =       {Stephen L. Morgan and Christopher Winship},
  title =        {Counterfactuals and Causal Inference},
  doi =          {10.1017/cbo9780511804564.001},
  publisher =    {Cambridge University Press},
  url =          {https://doi.org/10.1017/cbo9780511804564.001},
  year =         2015,
  edition =      2,
}


@inbook{tewari-2017-from-ads-inter,
  DATE_ADDED =   {Thu Mar 11 22:01:06 2021},
  author =       {Ambuj Tewari and Susan A. Murphy},
  booktitle =    {Mobile Health},
  doi =          {10.1007/978-3-319-51394-2_25},
  pages =        {495-517},
  publisher =    {Springer International Publishing},
  series =       {Mobile Health},
  title =        {From Ads to Interventions: Contextual Bandits in Mobile
                  Health},
  url =          {https://doi.org/10.1007/978-3-319-51394-2_25},
  year =         {2017},
}

@InProceedings{su-2019-cab,
  title =        {{CAB}: Continuous Adaptive Blending for Policy Evaluation and
                  Learning},
  author =       {Su, Yi and Wang, Lequn and Santacatterina, Michele and
                  Joachims, Thorsten},
  booktitle =    {Proceedings of the 36th International Conference on Machine
                  Learning},
  pages =        {6005--6014},
  year =         2019,
  editor =       {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume =       97,
  series =       {Proceedings of Machine Learning Research},
  month =        {09--15 Jun},
  publisher =    {PMLR},
  pdf =          {http://proceedings.mlr.press/v97/su19a/su19a.pdf},
  url =          { http://proceedings.mlr.press/v97/su19a.html },
}

@InProceedings{vlassis-2019-desig-estim,
  title =        {On the Design of Estimators for Bandit Off-Policy Evaluation},
  author =       {Vlassis, Nikos and Bibaut, Aurelien and Dimakopoulou, Maria
                  and Jebara, Tony},
  booktitle =    {Proceedings of the 36th International Conference on Machine
                  Learning},
  pages =        {6468--6476},
  year =         2019,
  editor =       {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume =       97,
  series =       {Proceedings of Machine Learning Research},
  month =        {09--15 Jun},
  publisher =    {PMLR},
  pdf =          {http://proceedings.mlr.press/v97/vlassis19a/vlassis19a.pdf},
  url =          { http://proceedings.mlr.press/v97/vlassis19a.html },
}

@InProceedings{su-2020-doubl,
  title =        {Doubly robust off-policy evaluation with shrinkage},
  author =       {Su, Yi and Dimakopoulou, Maria and Krishnamurthy, Akshay and
                  Dudik, Miroslav},
  booktitle =    {Proceedings of the 37th International Conference on Machine
                  Learning},
  pages =        {9167--9176},
  year =         2020,
  editor =       {Hal Daumé III and Aarti Singh},
  volume =       119,
  series =       {Proceedings of Machine Learning Research},
  month =        {13--18 Jul},
  publisher =    {PMLR},
  pdf =          {http://proceedings.mlr.press/v119/su20a/su20a.pdf},
  url =          { http://proceedings.mlr.press/v119/su20a.html },
}

@article{hesterberg-2015-what-teach,
  author =       {Tim C. Hesterberg},
  title =        {What Teachers Should Know About the Bootstrap: Resampling in
                  the Undergraduate Statistics Curriculum},
  journal =      {The American Statistician},
  volume =       69,
  number =       4,
  pages =        {371-386},
  year =         2015,
  doi =          {10.1080/00031305.2015.1089789},
  url =          {https://doi.org/10.1080/00031305.2015.1089789},
  DATE_ADDED =   {Sat Mar 13 19:52:51 2021},
}

@article{hesterberg-2014-what-teach,
  author =       {Hesterberg, Tim},
  title =        {What Teachers Should Know About the Bootstrap: Resampling in
                  the Undergraduate Statistics Curriculum},
  journal =      {CoRR},
  year =         2014,
  url =          {http://arxiv.org/abs/1411.5279v1},
  abstract =     {I have three goals in this article: (1) To show the enormous
                  potential of bootstrapping and permutation tests to help
                  students understand statistical concepts including sampling
                  distributions, standard errors, bias, confidence intervals,
                  null distributions, and P-values. (2) To dig deeper,
                  understand why these methods work and when they don't, things
                  to watch out for, and how to deal with these issues when
                  teaching. (3) To change statistical practice---by comparing
                  these methods to common t tests and intervals, we see how
                  inaccurate the latter are; we confirm this with asymptotics. n
                  >= 30 isn't enough---think n >= 5000. Resampling provides
                  diagnostics, and more accurate alternatives. Sadly, the common
                  bootstrap percentile interval badly under-covers in small
                  samples; there are better alternatives. The tone is informal,
                  with a few stories and jokes.},
  archivePrefix ={arXiv},
  eprint =       {1411.5279},
  primaryClass = {stat.OT},
}


@inproceedings{agarwal-2017-effec-evaluat,
  author =       {Aman Agarwal and Soumya Basu and Tobias Schnabel and Thorsten
                  Joachims},
  title =        {Effective Evaluation Using Logged Bandit Feedback from
                  Multiple Loggers},
  booktitle =    {Proceedings of the 23rd ACM SIGKDD International Conference on
                  Knowledge Discovery and Data Mining},
  year =         2017,
  pages =        {nil},
  doi =          {10.1145/3097983.3098155},
  url =          {https://doi.org/10.1145/3097983.3098155},
  DATE_ADDED =   {Wed Mar 17 07:21:48 2021},
  month =        8,
}

@inproceedings{rennie-2017-self-critic,
  author =       {Steven J. Rennie and Etienne Marcheret and Youssef Mroueh and
                  Jerret Ross and Vaibhava Goel},
  title =        {Self-Critical Sequence Training for Image Captioning},
  booktitle =    {2017 IEEE Conference on Computer Vision and Pattern
                  Recognition (CVPR)},
  year =         2017,
  pages =        {nil},
  doi =          {10.1109/cvpr.2017.131},
  url =          {https://doi.org/10.1109/cvpr.2017.131},
  DATE_ADDED =   {Wed Mar 24 15:56:40 2021},
  month =        7,
}

@article{williams-1992-simpl-statis,
  author =       {Ronald J. Williams},
  title =        {Simple Statistical Gradient-Following Algorithms for
                  Connectionist Reinforcement Learning},
  journal =      {Machine Learning},
  volume =       8,
  number =       {3-4},
  pages =        {229-256},
  year =         1992,
  doi =          {10.1007/bf00992696},
  url =          {https://doi.org/10.1007/bf00992696},
  DATE_ADDED =   {Wed Mar 31 07:41:54 2021},
}

@inproceedings{pasunuru-2021-dual-reinf,
  author =       {Ramakanth Pasunuru and David S. Rosenberg and Gideon Mann and
                  Mohit Bansal},
  editor =       {Amir Pouran Ben Veyseh and Franck Dernoncourt and Thien Huu
                  Nguyen and Walter Chang and Leo Anthony Celi},
  title =        {Dual Reinforcement-Based Specification Generation for Image
                  De-Rendering},
  booktitle =    {Proceedings of the Workshop on Scientific Document
                  Understanding co-located with 35th {AAAI} Conference on
                  Artificial Inteligence, SDU@AAAI 2021, Virtual Event, February
                  9, 2021},
  series =       {{CEUR} Workshop Proceedings},
  volume =       2831,
  publisher =    {CEUR-WS.org},
  year =         2021,
  url =          {http://ceur-ws.org/Vol-2831/paper12.pdf},
  timestamp =    {Mon, 29 Mar 2021 18:04:51 +0200},
  biburl =       {https://dblp.org/rec/conf/aaai/PasunuruRMB21.bib},
  bibsource =    {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{weaver-2001-optim-rewar,
  author =       {Weaver, Lex and Tao, Nigel},
  title =        {The Optimal Reward Baseline for Gradient-Based Reinforcement
                  Learning},
  year =         2001,
  isbn =         1558608001,
  publisher =    {Morgan Kaufmann Publishers Inc.},
  address =      {San Francisco, CA, USA},
  abstract =     {There exist a number of reinforcement learning algorithms
                  which learn by climbing the gradient of expected reward. Their
                  long-run convergence has been proved, even in partially
                  observable environments with non-deterministic actions, and
                  without the need for a system model. However, the variance of
                  the gradient estimator has been found to be a significant
                  practical problem. Recent approaches have discounted future
                  rewards, introducing a bias-variance trade-off into the
                  gradient estimate. We incorporate a reward baseline into the
                  learning system, and show that it affects variance without
                  introducing further bias. In particular, as we approach the
                  zerobias, high-variance parametedzation, the optimal (or
                  variance minimizing) constant reward baseline is equal to the
                  long-term average expected reward. Modified policy-gradient
                  algorithms are presented, and a number of experiments
                  demonstrate their improvement over previous work.},
  booktitle =    {Proceedings of the Seventeenth Conference on Uncertainty in
                  Artificial Intelligence},
  pages =        {538-545},
  numpages =     8,
  location =     {Seattle, Washington},
  series =       {UAI'01}
}

@article{peters-2008-reinf-learn,
  author =       {Jan Peters and Stefan Schaal},
  title =        {Reinforcement Learning of Motor Skills With Policy Gradients},
  journal =      {Neural Networks},
  volume =       21,
  number =       4,
  pages =        {682-697},
  year =         2008,
  doi =          {10.1016/j.neunet.2008.02.003},
  url =          {https://doi.org/10.1016/j.neunet.2008.02.003},
  DATE_ADDED =   {Mon Apr 5 12:36:13 2021},
}

@inproceedings{wu-2018-varian-reduc,
  author =       {Cathy Wu and Aravind Rajeswaran and Yan Duan and Vikash Kumar
                  and Alexandre M. Bayen and Sham M. Kakade and Igor Mordatch
                  and Pieter Abbeel},
  title =        {Variance Reduction for Policy Gradient with Action-Dependent
                  Factorized Baselines},
  booktitle =    {6th International Conference on Learning Representations,
                  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018,
                  Conference Track Proceedings},
  publisher =    {OpenReview.net},
  year =         2018,
  url =          {https://openreview.net/forum?id=H1tSsb-AW},
  timestamp =    {Tue, 23 Jul 2019 15:03:08 +0200},
  biburl =       {https://dblp.org/rec/conf/iclr/WuRDKBKMA18.bib},
  bibsource =    {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{zhao-2011-analy-improv,
 author = {Zhao, Tingting and Hachiya, Hirotaka and Niu, Gang and Sugiyama, Masashi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K. Q. Weinberger},
 publisher = {Curran Associates, Inc.},
 title = {Analysis and Improvement of Policy Gradient Estimation},
 url = {https://proceedings.neurips.cc/paper/2011/file/85d8ce590ad8981ca2c8286f79f59954-Paper.pdf},
 volume = 24,
 year = 2011
}

@article{zaremba-2015-reinf-learn,
  author =       {Zaremba, Wojciech and Sutskever, Ilya},
  title =        {Reinforcement Learning Neural Turing Machines - Revised},
  journal =      {CoRR},
  year =         2015,
  url =          {http://arxiv.org/abs/1505.00521v3},
  abstract =     {The Neural Turing Machine (NTM) is more expressive than all
                  previously considered models because of its external memory.
                  It can be viewed as a broader effort to use abstract external
                  Interfaces and to learn a parametric model that interacts with
                  them. The capabilities of a model can be extended by providing
                  it with proper Interfaces that interact with the world. These
                  external Interfaces include memory, a database, a search
                  engine, or a piece of software such as a theorem verifier.
                  Some of these Interfaces are provided by the developers of the
                  model. However, many important existing Interfaces, such as
                  databases and search engines, are discrete. We examine
                  feasibility of learning models to interact with discrete
                  Interfaces. We investigate the following discrete Interfaces:
                  a memory Tape, an input Tape, and an output Tape. We use a
                  Reinforcement Learning algorithm to train a neural network
                  that interacts with such Interfaces to solve simple
                  algorithmic tasks. Our Interfaces are expressive enough to
                  make our model Turing complete.},
  archivePrefix ={arXiv},
  eprint =       {1505.00521},
  primaryClass = {cs.LG},
}

@inproceedings{sutton-2000-polic-gradien,
  author =       {Sutton, Richard S and McAllester, David and Singh, Satinder
                  and Mansour, Yishay},
  booktitle =    {Advances in Neural Information Processing Systems},
  editor =       {S. Solla and T. Leen and K. M\"{u}ller},
  publisher =    {MIT Press},
  title =        {Policy Gradient Methods for Reinforcement Learning with
                  Function Approximation},
  url =
                  {https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf},
  volume =       12,
  year =         2000
}

@misc{weng-2018-polic-gradien-algor,
  title =        {Policy Gradient Algorithms},
  note =
                  {\url{https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html#proof-of-policy-gradient-theorem}},
  url =
                  {https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html#proof-of-policy-gradient-theorem},
  journal =      {Lil'Log},
  author =       {Weng, Lilian},
  year =         2018,
  month =        {Apr}
} 

@InProceedings{baxter-2000-reinf-learn,
  author =       "Jonathan Baxter and Peter L. Bartlett",
  title =        "Reinforcement Learning in {POMDP}'s via Direct Gradient
                  Ascent",
  booktitle =    "Proc. 17th International Conf. on Machine Learning",
  publisher =    "Morgan Kaufmann, San Francisco, CA",
  year =         2000,
  pages =        "41--48",
  DATE_ADDED =   {Wed Apr 7 07:30:49 2021},
}
@article{saito-2020-open-bandit,
  author =       {Saito, Yuta and Aihara, Shunsuke and Matsutani, Megumi and
                  Narita, Yusuke},
  title =        {Open Bandit Dataset and Pipeline: Towards Realistic and
                  Reproducible Off-Policy Evaluation},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2008.07146v3},
  abstract =     {Off-policy evaluation (OPE) aims to estimate the performance
                  of hypothetical policies using data generated by a different
                  policy. Because of its huge potential impact, there has been
                  growing research interest in OPE. There is, however, no
                  real-world public dataset that enables the evaluation of OPE,
                  making its experimental studies unrealistic and
                  irreproducible. With the goal of enabling realistic and
                  reproducible OPE research, we publicize the Open Bandit
                  Dataset collected on a large-scale fashion e-commerce
                  platform, ZOZOTOWN. Our dataset is unique in that it contains
                  a set of multiple logged bandit feedback datasets collected by
                  running different policies on the same platform. This enables
                  realistic and reproducible experimental comparisons of
                  different OPE estimators for the first time. We also develop
                  Python software called the Open Bandit Pipeline to streamline
                  and standardize the implementations of bandit algorithms and
                  OPE. Our open data and pipeline will contribute to the fair
                  and transparent OPE research and help the community identify
                  fruitful research directions. Finally, we provide extensive
                  benchmark experiments of existing OPE estimators using our
                  data and pipeline. Our experiments open up essential
                  challenges and new avenues for future OPE research. Our
                  pipeline and example data are available at
                  https://github.com/st-tech/zr-obp.},
  archivePrefix ={arXiv},
  eprint =       {2008.07146},
  primaryClass = {cs.LG},
}

@article{degroot-1983-compar-evaluat-forec,
  author =       {Morris H. DeGroot and Stephen E. Fienberg},
  title =        {The Comparison and Evaluation of Forecasters},
  journal =      {The Statistician},
  volume =       32,
  number =       {1/2},
  pages =        12,
  year =         1983,
  doi =          {10.2307/2987588},
  url =          {https://doi.org/10.2307/2987588},
  DATE_ADDED =   {Thu Apr 15 17:40:56 2021},
}

@article{gregorutti-2013-correl-variab,
  author =       {Gregorutti, Baptiste and Michel, Bertrand and Saint-Pierre,
                  Philippe},
  title =        {Correlation and Variable Importance in Random Forests},
  journal =      {CoRR},
  year =         2013,
  url =          {http://arxiv.org/abs/1310.5726v5},
  abstract =     {This paper is about variable selection with the random forests
                  algorithm in presence of correlated predictors. In
                  high-dimensional regression or classification frameworks,
                  variable selection is a difficult task, that becomes even more
                  challenging in the presence of highly correlated predictors.
                  Firstly we provide a theoretical study of the permutation
                  importance measure for an additive regression model. This
                  allows us to describe how the correlation between predictors
                  impacts the permutation importance. Our results motivate the
                  use of the Recursive Feature Elimination (RFE) algorithm for
                  variable selection in this context. This algorithm recursively
                  eliminates the variables using permutation importance measure
                  as a ranking criterion. Next various simulation experiments
                  illustrate the efficiency of the RFE algorithm for selecting a
                  small number of variables together with a good prediction
                  error. Finally, this selection algorithm is tested on the
                  Landsat Satellite data from the UCI Machine Learning
                  Repository.},
  archivePrefix ={arXiv},
  eprint =       {1310.5726},
  primaryClass = {stat.ME},
}

@article{hastie-1986-gams,
author = {Trevor Hastie and Robert Tibshirani},
title = {{Generalized Additive Models}},
volume = 1,
journal = {Statistical Science},
number = 3,
publisher = {Institute of Mathematical Statistics},
pages = {297 -- 310},
keywords = {generalized linear models, nonlinearity, Nonparametric regression, partial residuals, smoothing},
year = 1986,
doi = {10.1214/ss/1177013604},
URL = {https://doi.org/10.1214/ss/1177013604}
}

@book{hastie-2009-esl,
  author =       {Trevor Hastie and Robert Tibshirani and Jerome H. Friedman},
  title =        {The Elements of Statistical Learning: Data Mining, Inference,
                  and Prediction, 2nd Edition},
  series =       {Springer Series in Statistics},
  publisher =    {Springer},
  year =         2009,
  url =          {https://doi.org/10.1007/978-0-387-84858-7},
  doi =          {10.1007/978-0-387-84858-7},
  isbn =         9780387848570,
  timestamp =    {Fri, 17 Jul 2020 16:12:43 +0200},
  biburl =       {https://dblp.org/rec/books/lib/HastieTF09.bib},
  bibsource =    {dblp computer science bibliography, https://dblp.org}
}

@article{dudík-2014-doubl-robus,
  author =       {Miroslav Dudík and Dumitru Erhan and John Langford and Lihong
                  Li},
  title =        {{Doubly Robust Policy Evaluation and Optimization}},
  volume =       29,
  journal =      {Statistical Science},
  number =       4,
  publisher =    {Institute of Mathematical Statistics},
  pages =        {485 -- 511},
  keywords =     {Causal inference, Contextual bandits, doubly robust
                  estimators},
  year =         2014,
  doi =          {10.1214/14-STS500},
  URL =          {https://doi.org/10.1214/14-STS500}
}

@inproceedings{ribeiro-2016-why-shoul,
  author =       {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  title =        {"Why Should I Trust You?": Explaining the Predictions of Any
                  Classifier},
  year =         2016,
  isbn =         9781450342322,
  publisher =    {Association for Computing Machinery},
  address =      {New York, NY, USA},
  url =          {https://doi.org/10.1145/2939672.2939778},
  doi =          {10.1145/2939672.2939778},
  booktitle =    {Proceedings of the 22nd ACM SIGKDD International Conference on
                  Knowledge Discovery and Data Mining},
  pages =        {1135-1144},
  numpages =     10,
  keywords =     {interpretable machine learning, interpretability, explaining
                  machine learning, black box classifier},
  location =     {San Francisco, California, USA},
  series =       {KDD '16}
}

@misc{ribeiro-2016-local-inter,
  title =        {Local Interpretable Model-Agnostic Explanations (LIME): An
                  Introduction},
  url =
                  {https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/},
  note = {\url{https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/}},                 
  journal =      {O'Reilly},
  publisher =    {O'Reilly},
  author =       {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  year =         2016,
  month =        {Aug}
}

@book{thampi-2021-inter-ai,
  author =       {Ajay Thampi},
  title =        {Interpretable AI},
  subtitle =     {Building explainable machine learning systems},
  publisher =    {Manning Publications},
  year =         2021,
  note =         {\url{https://www.manning.com/books/interpretable-ai}}
}

@article{chen-2020-true-to,
  author =       {Chen, Hugh and Janizek, Joseph D. and Lundberg, Scott and Lee,
                  Su-In},
  title =        {True To the Model Or True To the Data?},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2006.16234v1},
  abstract =     {A variety of recent papers discuss the application of Shapley
                  values, a concept for explaining coalitional games, for
                  feature attribution in machine learning. However, the correct
                  way to connect a machine learning model to a coalitional game
                  has been a source of controversy. The two main approaches that
                  have been proposed differ in the way that they condition on
                  known features, using either (1) an interventional or (2) an
                  observational conditional expectation. While previous work has
                  argued that one of the two approaches is preferable in
                  general, we argue that the choice is application dependent.
                  Furthermore, we argue that the choice comes down to whether it
                  is desirable to be true to the model or true to the data. We
                  use linear models to investigate this choice. After deriving
                  an efficient method for calculating observational conditional
                  expectation Shapley values for linear models, we investigate
                  how correlation in simulated data impacts the convergence of
                  observational conditional expectation Shapley values. Finally,
                  we present two real data examples that we consider to be
                  representative of possible use cases for feature attribution
                  -- (1) credit risk modeling and (2) biological discovery. We
                  show how a different choice of value function performs better
                  in each scenario, and how possible attributions are impacted
                  by modeling choices.},
  archivePrefix ={arXiv},
  eprint =       {2006.16234},
  primaryClass = {cs.LG},
}
                  
@misc{wiki-2021-shapley-value,
  author =       "{Wikipedia contributors}",
  note =         "[\url{https://en.wikipedia.org/wiki/Shapley_value}; accessed 26-April-2021]",
  title =        "Shapley value --- {W}ikipedia{,} The Free
                  Encyclopedia",
  url =          https://en.wikipedia.org/wiki/Shapley_value,
  year =         2020,
}

@article{moretti-2008-trans-shapl-value,
  author =       {Stefano Moretti and Fioravante Patrone},
  title =        {Transversality of the Shapley Value},
  journal =      {TOP},
  volume =       16,
  number =       1,
  pages =        {1-41},
  year =         2008,
  doi =          {10.1007/s11750-008-0044-5},
  url =          {https://doi.org/10.1007/s11750-008-0044-5},
  DATE_ADDED =   {Mon Apr 26 21:28:06 2021},
}

@InProceedings{kumar-2020-probl-shapl,
  title =        {Problems with Shapley-value-based explanations as feature
                  importance measures},
  author =       {Kumar, I. Elizabeth and Venkatasubramanian, Suresh and
                  Scheidegger, Carlos and Friedler, Sorelle},
  booktitle =    {Proceedings of the 37th International Conference on Machine
                  Learning},
  pages =        {5491--5500},
  year =         2020,
  editor =       {Hal Daumé III and Aarti Singh},
  volume =       119,
  series =       {Proceedings of Machine Learning Research},
  month =        {13--18 Jul},
  publisher =    {PMLR},
  pdf =          {http://proceedings.mlr.press/v119/kumar20e/kumar20e.pdf},
  url =          { http://proceedings.mlr.press/v119/kumar20e.html },
  abstract =     {Game-theoretic formulations of feature importance have become
                  popular as a way to "explain" machine learning models. These
                  methods define a cooperative game between the features of a
                  model and distribute influence among these input elements
                  using some form of the game’s unique Shapley values.
                  Justification for these methods rests on two pillars: their
                  desirable mathematical properties, and their applicability to
                  specific motivations for explanations. We show that
                  mathematical problems arise when Shapley values are used for
                  feature importance and that the solutions to mitigate these
                  necessarily induce further complexity, such as the need for
                  causal reasoning. We also draw on additional literature to
                  argue that Shapley values do not provide explanations which
                  suit human-centric goals of explainability.}
}

@article{owen-2017-shapl-value,
  author =       {Art B. Owen and Cl{\'e}mentine Prieur},
  title =        {On Shapley Value for Measuring Importance of Dependent Inputs},
  journal =      {SIAM/ASA Journal on Uncertainty Quantification},
  volume =       5,
  number =       1,
  pages =        {986-1002},
  year =         2017,
  doi =          {10.1137/16m1097717},
  url =          {https://doi.org/10.1137/16m1097717},
  DATE_ADDED =   {Tue Apr 27 17:59:57 2021},
}

@article{song-2016-shapl-effec,
  author =       {Eunhye Song and Barry L. Nelson and Jeremy Staum},
  title =        {Shapley Effects for Global Sensitivity Analysis: Theory and
                  Computation},
  journal =      {SIAM/ASA Journal on Uncertainty Quantification},
  volume =       4,
  number =       1,
  pages =        {1060-1083},
  year =         2016,
  doi =          {10.1137/15m1048070},
  url =          {https://doi.org/10.1137/15m1048070},
  DATE_ADDED =   {Tue Apr 27 18:33:55 2021},
}

@article{owen-2014-sobol-indic,
  author =       {Art B. Owen},
  title =        {Sobol' Indices and Shapley Value},
  journal =      {SIAM/ASA Journal on Uncertainty Quantification},
  volume =       2,
  number =       1,
  pages =        {245-251},
  year =         2014,
  doi =          {10.1137/130936233},
  url =          {https://doi.org/10.1137/130936233},
  DATE_ADDED =   {Tue Apr 27 18:38:18 2021},
}

@article{kruskal-1987-relat-impor,
  author =       {William Kruskal},
  title =        {Relative Importance By Averaging Over Orderings},
  journal =      {The American Statistician},
  volume =       41,
  number =       1,
  pages =        {6-10},
  year =         1987,
  doi =          {10.1080/00031305.1987.10475432},
  url =          {https://doi.org/10.1080/00031305.1987.10475432},
  DATE_ADDED =   {Tue Apr 27 18:41:53 2021},
}

@article{cox-1985-new-measur,
  author =       {Louis A. Cox},
  title =        {A New Measure of Attributable Risk for Public Health
                  Applications},
  journal =      {Management Science},
  volume =       31,
  number =       7,
  pages =        {800-813},
  year =         1985,
  doi =          {10.1287/mnsc.31.7.800},
  url =          {https://doi.org/10.1287/mnsc.31.7.800},
  DATE_ADDED =   {Tue Apr 27 18:46:00 2021},
}

@article{aas-2021-explain-indiv,
  author =       {Kjersti Aas and Martin Jullum and Anders L{\o}land},
  title =        {Explaining Individual Predictions When Features Are Dependent:
                  More Accurate Approximations To Shapley Values},
  journal =      {Artificial Intelligence},
  volume =       298,
  pages =        103502,
  year =         2021,
  doi =          {10.1016/j.artint.2021.103502},
  url =          {https://doi.org/10.1016/j.artint.2021.103502},
  DATE_ADDED =   {Tue Apr 27 20:42:40 2021},
}

@article{covert-2020-under-global,
  author =       {Covert, Ian and Lundberg, Scott and Lee, Su-In},
  title =        {Understanding Global Feature Contributions With Additive
                  Importance Measures},
  journal =      {CoRR},
  year =         2020,
  url =          {http://arxiv.org/abs/2004.00668v2},
  abstract =     {Understanding the inner workings of complex machine learning
                  models is a long-standing problem and most recent research has
                  focused on local interpretability. To assess the role of
                  individual input features in a global sense, we explore the
                  perspective of defining feature importance through the
                  predictive power associated with each feature. We introduce
                  two notions of predictive power (model-based and universal)
                  and formalize this approach with a framework of additive
                  importance measures, which unifies numerous methods in the
                  literature. We then propose SAGE, a model-agnostic method that
                  quantifies predictive power while accounting for feature
                  interactions. Our experiments show that SAGE can be calculated
                  efficiently and that it assigns more accurate importance
                  values than other methods.},
  archivePrefix ={arXiv},
  eprint =       {2004.00668},
  primaryClass = {cs.LG},
}


@article{vstrumbelj-2009-explain-instan,
  author =       {E. {\V{S}}trumbelj and I. Kononenko and M. Robnik
                  {\V{S}}ikonja},
  title =        {Explaining Instance Classifications With Interactions of Subsets of Feature Values},
  journal =      {Data \& Knowledge Engineering},
  volume =       68,
  number =       10,
  pages =        {886-904},
  year =         2009,
  doi =          {10.1016/j.datak.2009.01.004},
  url =          {https://doi.org/10.1016/j.datak.2009.01.004},
  DATE_ADDED =   {Tue Apr 27 21:40:44 2021},
}

@article{vstrumbelj-2010-effic-explan,
  author =       {Erik {\V{S}}trumbelj and Igor Kononenko},
  title =        {An Efficient Explanation of Individual Classifications using
                  Game Theory},
  journal =      {Journal of Machine Learning Research},
  year =         2010,
  volume =       11,
  number =       1,
  pages =        {1-18},
  url =          {http://jmlr.org/papers/v11/strumbelj10a.html}
}

@article{fisher-2020-visual-commun,
  author =       {Aaron Fisher and Edward H. Kennedy},
  title =        {Visually Communicating and Teaching Intuition for Influence
                  Functions},
  journal =      {The American Statistician},
  volume =       {nil},
  number =       {nil},
  pages =        {1-11},
  year =         2020,
  doi =          {10.1080/00031305.2020.1717620},
  url =          {https://doi.org/10.1080/00031305.2020.1717620},
  DATE_ADDED =   {Thu Apr 29 08:05:14 2021},
}

@article{young-1985-monot-solut,
  author =       {H. P. Young},
  title =        {Monotonic Solutions of Cooperative Games},
  journal =      {International Journal of Game Theory},
  volume =       14,
  number =       2,
  pages =        {65-72},
  year =         1985,
  doi =          {10.1007/bf01769885},
  url =          {https://doi.org/10.1007/bf01769885},
  DATE_ADDED =   {Sun May 2 07:44:13 2021},
}

@Inbook{charnes-1988-extrem-princ,
  author =       "Charnes, A. and Golany, B. and Keane, M. and Rousseau, J.",
  editor =       "Sengupta, Jati K. and Kadekodi, Gopal K.",
  title =        "Extremal Principle Solutions of Games in Characteristic
                  Function Form: Core, Chebychev and Shapley Value
                  Generalizations",
  bookTitle =    "Econometrics of Planning and Efficiency",
  year =         "1988",
  publisher =    "Springer Netherlands",
  address =      "Dordrecht",
  pages =        "123--133",
  isbn =         "978-94-009-3677-5",
  doi =          "10.1007/978-94-009-3677-5_7",
  url =          "https://doi.org/10.1007/978-94-009-3677-5_7"
}

@InProceedings{shrikumar-2017-learn-impor,
  title =        {Learning Important Features Through Propagating Activation
                  Differences},
  author =       {Avanti Shrikumar and Peyton Greenside and Anshul Kundaje},
  booktitle =    {Proceedings of the 34th International Conference on Machine
                  Learning},
  pages =        {3145--3153},
  year =         2017,
  editor =       {Precup, Doina and Teh, Yee Whye},
  volume =       70,
  series =       {Proceedings of Machine Learning Research},
  month =        {06--11 Aug},
  publisher =    {PMLR},
  pdf =
                  {http://proceedings.mlr.press/v70/shrikumar17a/shrikumar17a.pdf},
  url =          { http://proceedings.mlr.press/v70/shrikumar17a.html },
  abstract =     {The purported “black box” nature of neural networks is a
                  barrier to adoption in applications where interpretability is
                  essential. Here we present DeepLIFT (Deep Learning Important
                  FeaTures), a method for decomposing the output prediction of a
                  neural network on a specific input by backpropagating the
                  contributions of all neurons in the network to every feature
                  of the input. DeepLIFT compares the activation of each neuron
                  to its `reference activation’ and assigns contribution scores
                  according to the difference. By optionally giving separate
                  consideration to positive and negative contributions, DeepLIFT
                  can also reveal dependencies which are missed by other
                  approaches. Scores can be computed efficiently in a single
                  backward pass. We apply DeepLIFT to models trained on MNIST
                  and simulated genomic data, and show significant advantages
                  over gradient-based methods. Video tutorial:
                  http://goo.gl/qKb7pL code: http://goo.gl/RM8jvH}
}

@InProceedings{koh-2017-under-black,
  title =        {Understanding Black-box Predictions via Influence Functions},
  author =       {Pang Wei Koh and Percy Liang},
  booktitle =    {Proceedings of the 34th International Conference on Machine
                  Learning},
  pages =        {1885--1894},
  year =         2017,
  editor =       {Precup, Doina and Teh, Yee Whye},
  volume =       70,
  series =       {Proceedings of Machine Learning Research},
  month =        {06--11 Aug},
  publisher =    {PMLR},
  pdf =          {http://proceedings.mlr.press/v70/koh17a/koh17a.pdf},
  url =          { http://proceedings.mlr.press/v70/koh17a.html },
}

@misc{kulma-2017-inter-ML,
  author =       {Kasia Kulma},
  note =         "[Online; accessed 15-June-2021]",
  title =        "Interpretable Machine Learning Using LIME Framework",
  url =
                  "https://www.slideshare.net/0xdata/interpretable-machine-learning-using-lime-framework-kasia-kulma-phd-data-scientist",
  howpublished =
                  {\url{https://www.slideshare.net/0xdata/interpretable-machine-learning-using-lime-framework-kasia-kulma-phd-data-scientist}},
  year =         2017
}
